/home/aakli/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
INFO:name:device: cuda:2, n_gpu: 1
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /Salesforce/codet5-base/resolve/main/config.json HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /Salesforce/codet5-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
INFO:name:Preparing the code search Dataset...

INFO:name:Preparing the code search Dataset...

INFO:name:Preparing the code search Dataset...

/home/aakli/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:name:***** Running training *****
INFO:name:  Num examples = 251820
INFO:name:  Num Epochs = 15
INFO:name:  Instantaneous batch size per GPU = 32
INFO:name:  Total train batch size  = 32
INFO:name:  Total optimization steps = 118050
INFO:name:epoch 0 step 100 loss 3.03003
INFO:name:epoch 0 step 200 loss 0.88272
INFO:name:epoch 0 step 300 loss 0.45565
INFO:name:epoch 0 step 400 loss 0.32484
INFO:name:epoch 0 step 500 loss 0.26804
INFO:name:epoch 0 step 600 loss 0.21259
INFO:name:epoch 0 step 700 loss 0.22316
INFO:name:epoch 0 step 800 loss 0.20993
INFO:name:epoch 0 step 900 loss 0.16652
INFO:name:epoch 0 step 1000 loss 0.18917
INFO:name:epoch 0 step 1100 loss 0.16963
INFO:name:epoch 0 step 1200 loss 0.17152
INFO:name:epoch 0 step 1300 loss 0.14429
INFO:name:epoch 0 step 1400 loss 0.1489
INFO:name:epoch 0 step 1500 loss 0.14772
INFO:name:epoch 0 step 1600 loss 0.14471
INFO:name:epoch 0 step 1700 loss 0.13207
INFO:name:epoch 0 step 1800 loss 0.13785
INFO:name:epoch 0 step 1900 loss 0.15036
INFO:name:epoch 0 step 2000 loss 0.12533
INFO:name:epoch 0 step 2100 loss 0.12697
INFO:name:epoch 0 step 2200 loss 0.13115
INFO:name:epoch 0 step 2300 loss 0.12178
INFO:name:epoch 0 step 2400 loss 0.13018
INFO:name:epoch 0 step 2500 loss 0.10799
INFO:name:epoch 0 step 2600 loss 0.11473
INFO:name:epoch 0 step 2700 loss 0.13585
INFO:name:epoch 0 step 2800 loss 0.10247
INFO:name:epoch 0 step 2900 loss 0.11813
INFO:name:epoch 0 step 3000 loss 0.10646
INFO:name:epoch 0 step 3100 loss 0.10752
INFO:name:epoch 0 step 3200 loss 0.10834
INFO:name:epoch 0 step 3300 loss 0.12843
INFO:name:epoch 0 step 3400 loss 0.10938
INFO:name:epoch 0 step 3500 loss 0.10356
INFO:name:epoch 0 step 3600 loss 0.1055
INFO:name:epoch 0 step 3700 loss 0.1276
INFO:name:epoch 0 step 3800 loss 0.10718
INFO:name:epoch 0 step 3900 loss 0.09251
INFO:name:epoch 0 step 4000 loss 0.10521
INFO:name:epoch 0 step 4100 loss 0.09746
INFO:name:epoch 0 step 4200 loss 0.09537
INFO:name:epoch 0 step 4300 loss 0.11922
INFO:name:epoch 0 step 4400 loss 0.09369
INFO:name:epoch 0 step 4500 loss 0.10903
INFO:name:epoch 0 step 4600 loss 0.10087
INFO:name:epoch 0 step 4700 loss 0.08392
INFO:name:epoch 0 step 4800 loss 0.09069
INFO:name:epoch 0 step 4900 loss 0.09678
INFO:name:epoch 0 step 5000 loss 0.09405
INFO:name:epoch 0 step 5100 loss 0.09493
INFO:name:epoch 0 step 5200 loss 0.09471
INFO:name:epoch 0 step 5300 loss 0.09504
INFO:name:epoch 0 step 5400 loss 0.09182
INFO:name:epoch 0 step 5500 loss 0.09863
INFO:name:epoch 0 step 5600 loss 0.11431
INFO:name:epoch 0 step 5700 loss 0.09075
INFO:name:epoch 0 step 5800 loss 0.09312
INFO:name:epoch 0 step 5900 loss 0.08788
INFO:name:epoch 0 step 6000 loss 0.09294
INFO:name:epoch 0 step 6100 loss 0.1033
INFO:name:epoch 0 step 6200 loss 0.09291
INFO:name:epoch 0 step 6300 loss 0.08917
INFO:name:epoch 0 step 6400 loss 0.11156
INFO:name:epoch 0 step 6500 loss 0.09088
INFO:name:epoch 0 step 6600 loss 0.10097
INFO:name:epoch 0 step 6700 loss 0.09285
INFO:name:epoch 0 step 6800 loss 0.09323
INFO:name:epoch 0 step 6900 loss 0.07511
INFO:name:epoch 0 step 7000 loss 0.09964
INFO:name:epoch 0 step 7100 loss 0.07847
INFO:name:epoch 0 step 7200 loss 0.08596
INFO:name:epoch 0 step 7300 loss 0.0994
INFO:name:epoch 0 step 7400 loss 0.09472
INFO:name:epoch 0 step 7500 loss 0.10339
INFO:name:epoch 0 step 7600 loss 0.08678
INFO:name:epoch 0 step 7700 loss 0.08868
INFO:name:epoch 0 step 7800 loss 0.09601
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3268
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3268
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.2688
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 1 step 100 loss 0.06668
INFO:name:epoch 1 step 200 loss 0.04944
INFO:name:epoch 1 step 300 loss 0.04506
INFO:name:epoch 1 step 400 loss 0.04452
INFO:name:epoch 1 step 500 loss 0.05074
INFO:name:epoch 1 step 600 loss 0.05185
INFO:name:epoch 1 step 700 loss 0.0468
INFO:name:epoch 1 step 800 loss 0.04297
INFO:name:epoch 1 step 900 loss 0.0548
INFO:name:epoch 1 step 1000 loss 0.05141
INFO:name:epoch 1 step 1100 loss 0.03904
INFO:name:epoch 1 step 1200 loss 0.04506
INFO:name:epoch 1 step 1300 loss 0.04317
INFO:name:epoch 1 step 1400 loss 0.04011
INFO:name:epoch 1 step 1500 loss 0.04576
INFO:name:epoch 1 step 1600 loss 0.0416
INFO:name:epoch 1 step 1700 loss 0.04958
INFO:name:epoch 1 step 1800 loss 0.05495
INFO:name:epoch 1 step 1900 loss 0.05322
INFO:name:epoch 1 step 2000 loss 0.05606
INFO:name:epoch 1 step 2100 loss 0.04174
INFO:name:epoch 1 step 2200 loss 0.04626
INFO:name:epoch 1 step 2300 loss 0.04408
INFO:name:epoch 1 step 2400 loss 0.05519
INFO:name:epoch 1 step 2500 loss 0.04293
INFO:name:epoch 1 step 2600 loss 0.04022
INFO:name:epoch 1 step 2700 loss 0.03964
INFO:name:epoch 1 step 2800 loss 0.03892
INFO:name:epoch 1 step 2900 loss 0.04399
INFO:name:epoch 1 step 3000 loss 0.0456
INFO:name:epoch 1 step 3100 loss 0.04397
INFO:name:epoch 1 step 3200 loss 0.06008
INFO:name:epoch 1 step 3300 loss 0.0552
INFO:name:epoch 1 step 3400 loss 0.04816
INFO:name:epoch 1 step 3500 loss 0.05265
INFO:name:epoch 1 step 3600 loss 0.05887
INFO:name:epoch 1 step 3700 loss 0.05625
INFO:name:epoch 1 step 3800 loss 0.05722
INFO:name:epoch 1 step 3900 loss 0.04166
INFO:name:epoch 1 step 4000 loss 0.04587
INFO:name:epoch 1 step 4100 loss 0.05457
INFO:name:epoch 1 step 4200 loss 0.04052
INFO:name:epoch 1 step 4300 loss 0.06468
INFO:name:epoch 1 step 4400 loss 0.04512
INFO:name:epoch 1 step 4500 loss 0.04816
INFO:name:epoch 1 step 4600 loss 0.04704
INFO:name:epoch 1 step 4700 loss 0.05549
INFO:name:epoch 1 step 4800 loss 0.04675
INFO:name:epoch 1 step 4900 loss 0.04619
INFO:name:epoch 1 step 5000 loss 0.059
INFO:name:epoch 1 step 5100 loss 0.04023
INFO:name:epoch 1 step 5200 loss 0.04892
INFO:name:epoch 1 step 5300 loss 0.05371
INFO:name:epoch 1 step 5400 loss 0.04552
INFO:name:epoch 1 step 5500 loss 0.04527
INFO:name:epoch 1 step 5600 loss 0.04882
INFO:name:epoch 1 step 5700 loss 0.04691
INFO:name:epoch 1 step 5800 loss 0.04535
INFO:name:epoch 1 step 5900 loss 0.04543
INFO:name:epoch 1 step 6000 loss 0.05295
INFO:name:epoch 1 step 6100 loss 0.05718
INFO:name:epoch 1 step 6200 loss 0.0524
INFO:name:epoch 1 step 6300 loss 0.04925
INFO:name:epoch 1 step 6400 loss 0.04532
INFO:name:epoch 1 step 6500 loss 0.04904
INFO:name:epoch 1 step 6600 loss 0.04334
INFO:name:epoch 1 step 6700 loss 0.04993
INFO:name:epoch 1 step 6800 loss 0.04972
INFO:name:epoch 1 step 6900 loss 0.03556
INFO:name:epoch 1 step 7000 loss 0.04482
INFO:name:epoch 1 step 7100 loss 0.04623
INFO:name:epoch 1 step 7200 loss 0.04102
INFO:name:epoch 1 step 7300 loss 0.0398
INFO:name:epoch 1 step 7400 loss 0.05131
INFO:name:epoch 1 step 7500 loss 0.03457
INFO:name:epoch 1 step 7600 loss 0.04271
INFO:name:epoch 1 step 7700 loss 0.04097
INFO:name:epoch 1 step 7800 loss 0.04454
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3839
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3839
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3245
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 2 step 100 loss 0.02981
INFO:name:epoch 2 step 200 loss 0.02475
INFO:name:epoch 2 step 300 loss 0.02426
INFO:name:epoch 2 step 400 loss 0.02122
INFO:name:epoch 2 step 500 loss 0.02166
INFO:name:epoch 2 step 600 loss 0.02553
INFO:name:epoch 2 step 700 loss 0.02095
INFO:name:epoch 2 step 800 loss 0.02249
INFO:name:epoch 2 step 900 loss 0.02272
INFO:name:epoch 2 step 1000 loss 0.02192
INFO:name:epoch 2 step 1100 loss 0.0293
INFO:name:epoch 2 step 1200 loss 0.02611
INFO:name:epoch 2 step 1300 loss 0.02504
INFO:name:epoch 2 step 1400 loss 0.01856
INFO:name:epoch 2 step 1500 loss 0.02626
INFO:name:epoch 2 step 1600 loss 0.02481
INFO:name:epoch 2 step 1700 loss 0.02106
INFO:name:epoch 2 step 1800 loss 0.02247
INFO:name:epoch 2 step 1900 loss 0.02216
INFO:name:epoch 2 step 2000 loss 0.02381
INFO:name:epoch 2 step 2100 loss 0.02446
INFO:name:epoch 2 step 2200 loss 0.02436
INFO:name:epoch 2 step 2300 loss 0.0247
INFO:name:epoch 2 step 2400 loss 0.02752
INFO:name:epoch 2 step 2500 loss 0.02191
INFO:name:epoch 2 step 2600 loss 0.0193
INFO:name:epoch 2 step 2700 loss 0.02568
INFO:name:epoch 2 step 2800 loss 0.02399
INFO:name:epoch 2 step 2900 loss 0.02193
INFO:name:epoch 2 step 3000 loss 0.02488
INFO:name:epoch 2 step 3100 loss 0.02241
INFO:name:epoch 2 step 3200 loss 0.03065
INFO:name:epoch 2 step 3300 loss 0.02907
INFO:name:epoch 2 step 3400 loss 0.02966
INFO:name:epoch 2 step 3500 loss 0.02615
INFO:name:epoch 2 step 3600 loss 0.02124
INFO:name:epoch 2 step 3700 loss 0.02613
INFO:name:epoch 2 step 3800 loss 0.02802
INFO:name:epoch 2 step 3900 loss 0.0236
INFO:name:epoch 2 step 4000 loss 0.02376
INFO:name:epoch 2 step 4100 loss 0.01658
INFO:name:epoch 2 step 4200 loss 0.01981
INFO:name:epoch 2 step 4300 loss 0.02203
INFO:name:epoch 2 step 4400 loss 0.02365
INFO:name:epoch 2 step 4500 loss 0.0238
INFO:name:epoch 2 step 4600 loss 0.02467
INFO:name:epoch 2 step 4700 loss 0.02043
INFO:name:epoch 2 step 4800 loss 0.0262
INFO:name:epoch 2 step 4900 loss 0.02533
INFO:name:epoch 2 step 5000 loss 0.02845
INFO:name:epoch 2 step 5100 loss 0.02687
INFO:name:epoch 2 step 5200 loss 0.02082
INFO:name:epoch 2 step 5300 loss 0.02095
INFO:name:epoch 2 step 5400 loss 0.02289
INFO:name:epoch 2 step 5500 loss 0.0282
INFO:name:epoch 2 step 5600 loss 0.02127
INFO:name:epoch 2 step 5700 loss 0.02716
INFO:name:epoch 2 step 5800 loss 0.02103
INFO:name:epoch 2 step 5900 loss 0.03156
INFO:name:epoch 2 step 6000 loss 0.02628
INFO:name:epoch 2 step 6100 loss 0.0273
INFO:name:epoch 2 step 6200 loss 0.02383
INFO:name:epoch 2 step 6300 loss 0.02491
INFO:name:epoch 2 step 6400 loss 0.02562
INFO:name:epoch 2 step 6500 loss 0.02677
INFO:name:epoch 2 step 6600 loss 0.02874
INFO:name:epoch 2 step 6700 loss 0.02448
INFO:name:epoch 2 step 6800 loss 0.02115
INFO:name:epoch 2 step 6900 loss 0.02572
INFO:name:epoch 2 step 7000 loss 0.02699
INFO:name:epoch 2 step 7100 loss 0.02455
INFO:name:epoch 2 step 7200 loss 0.02423
INFO:name:epoch 2 step 7300 loss 0.02361
INFO:name:epoch 2 step 7400 loss 0.02436
INFO:name:epoch 2 step 7500 loss 0.02422
INFO:name:epoch 2 step 7600 loss 0.02384
INFO:name:epoch 2 step 7700 loss 0.02772
INFO:name:epoch 2 step 7800 loss 0.01739
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.378
INFO:name:epoch 3 step 100 loss 0.01757
INFO:name:epoch 3 step 200 loss 0.01427
INFO:name:epoch 3 step 300 loss 0.01409
INFO:name:epoch 3 step 400 loss 0.01264
INFO:name:epoch 3 step 500 loss 0.01504
INFO:name:epoch 3 step 600 loss 0.01357
INFO:name:epoch 3 step 700 loss 0.01371
INFO:name:epoch 3 step 800 loss 0.01275
INFO:name:epoch 3 step 900 loss 0.01216
INFO:name:epoch 3 step 1000 loss 0.01369
INFO:name:epoch 3 step 1100 loss 0.01645
INFO:name:epoch 3 step 1200 loss 0.01552
INFO:name:epoch 3 step 1300 loss 0.01618
INFO:name:epoch 3 step 1400 loss 0.01132
INFO:name:epoch 3 step 1500 loss 0.01348
INFO:name:epoch 3 step 1600 loss 0.0149
INFO:name:epoch 3 step 1700 loss 0.0119
INFO:name:epoch 3 step 1800 loss 0.01311
INFO:name:epoch 3 step 1900 loss 0.01412
INFO:name:epoch 3 step 2000 loss 0.01914
INFO:name:epoch 3 step 2100 loss 0.013
INFO:name:epoch 3 step 2200 loss 0.01271
INFO:name:epoch 3 step 2300 loss 0.01735
INFO:name:epoch 3 step 2400 loss 0.01473
INFO:name:epoch 3 step 2500 loss 0.0132
INFO:name:epoch 3 step 2600 loss 0.01467
INFO:name:epoch 3 step 2700 loss 0.01281
INFO:name:epoch 3 step 2800 loss 0.0158
INFO:name:epoch 3 step 2900 loss 0.01407
INFO:name:epoch 3 step 3000 loss 0.01164
INFO:name:epoch 3 step 3100 loss 0.01594
INFO:name:epoch 3 step 3200 loss 0.01304
INFO:name:epoch 3 step 3300 loss 0.0181
INFO:name:epoch 3 step 3400 loss 0.01647
INFO:name:epoch 3 step 3500 loss 0.01547
INFO:name:epoch 3 step 3600 loss 0.01408
INFO:name:epoch 3 step 3700 loss 0.02045
INFO:name:epoch 3 step 3800 loss 0.0144
INFO:name:epoch 3 step 3900 loss 0.01495
INFO:name:epoch 3 step 4000 loss 0.01437
INFO:name:epoch 3 step 4100 loss 0.01345
INFO:name:epoch 3 step 4200 loss 0.01439
INFO:name:epoch 3 step 4300 loss 0.01357
INFO:name:epoch 3 step 4400 loss 0.01451
INFO:name:epoch 3 step 4500 loss 0.01659
INFO:name:epoch 3 step 4600 loss 0.01437
INFO:name:epoch 3 step 4700 loss 0.02008
INFO:name:epoch 3 step 4800 loss 0.01895
INFO:name:epoch 3 step 4900 loss 0.01335
INFO:name:epoch 3 step 5000 loss 0.01484
INFO:name:epoch 3 step 5100 loss 0.01781
INFO:name:epoch 3 step 5200 loss 0.01633
INFO:name:epoch 3 step 5300 loss 0.01494
INFO:name:epoch 3 step 5400 loss 0.01472
INFO:name:epoch 3 step 5500 loss 0.01636
INFO:name:epoch 3 step 5600 loss 0.01577
INFO:name:epoch 3 step 5700 loss 0.01303
INFO:name:epoch 3 step 5800 loss 0.015
INFO:name:epoch 3 step 5900 loss 0.01513
INFO:name:epoch 3 step 6000 loss 0.01227
INFO:name:epoch 3 step 6100 loss 0.0129
INFO:name:epoch 3 step 6200 loss 0.0145
INFO:name:epoch 3 step 6300 loss 0.01467
INFO:name:epoch 3 step 6400 loss 0.01319
INFO:name:epoch 3 step 6500 loss 0.01213
INFO:name:epoch 3 step 6600 loss 0.01607
INFO:name:epoch 3 step 6700 loss 0.01254
INFO:name:epoch 3 step 6800 loss 0.01584
INFO:name:epoch 3 step 6900 loss 0.01751
INFO:name:epoch 3 step 7000 loss 0.01448
INFO:name:epoch 3 step 7100 loss 0.01769
INFO:name:epoch 3 step 7200 loss 0.01247
INFO:name:epoch 3 step 7300 loss 0.01348
INFO:name:epoch 3 step 7400 loss 0.01617
INFO:name:epoch 3 step 7500 loss 0.0162
INFO:name:epoch 3 step 7600 loss 0.01463
INFO:name:epoch 3 step 7700 loss 0.01733
INFO:name:epoch 3 step 7800 loss 0.01679
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3778
INFO:name:epoch 4 step 100 loss 0.01277
INFO:name:epoch 4 step 200 loss 0.01165
INFO:name:epoch 4 step 300 loss 0.01199
INFO:name:epoch 4 step 400 loss 0.01081
INFO:name:epoch 4 step 500 loss 0.01069
INFO:name:epoch 4 step 600 loss 0.01298
INFO:name:epoch 4 step 700 loss 0.01024
INFO:name:epoch 4 step 800 loss 0.01017
INFO:name:epoch 4 step 900 loss 0.01296
INFO:name:epoch 4 step 1000 loss 0.01014
INFO:name:epoch 4 step 1100 loss 0.01026
INFO:name:epoch 4 step 1200 loss 0.00961
INFO:name:epoch 4 step 1300 loss 0.01117
INFO:name:epoch 4 step 1400 loss 0.00894
INFO:name:epoch 4 step 1500 loss 0.01347
INFO:name:epoch 4 step 1600 loss 0.01137
INFO:name:epoch 4 step 1700 loss 0.01148
INFO:name:epoch 4 step 1800 loss 0.01306
INFO:name:epoch 4 step 1900 loss 0.01083
INFO:name:epoch 4 step 2000 loss 0.01044
INFO:name:epoch 4 step 2100 loss 0.00921
INFO:name:epoch 4 step 2200 loss 0.01152
INFO:name:epoch 4 step 2300 loss 0.01159
INFO:name:epoch 4 step 2400 loss 0.00866
INFO:name:epoch 4 step 2500 loss 0.01092
INFO:name:epoch 4 step 2600 loss 0.00862
INFO:name:epoch 4 step 2700 loss 0.01037
INFO:name:epoch 4 step 2800 loss 0.01147
INFO:name:epoch 4 step 2900 loss 0.00988
INFO:name:epoch 4 step 3000 loss 0.00887
INFO:name:epoch 4 step 3100 loss 0.01179
INFO:name:epoch 4 step 3200 loss 0.01471
INFO:name:epoch 4 step 3300 loss 0.01109
INFO:name:epoch 4 step 3400 loss 0.01061
INFO:name:epoch 4 step 3500 loss 0.01079
INFO:name:epoch 4 step 3600 loss 0.00982
INFO:name:epoch 4 step 3700 loss 0.01105
INFO:name:epoch 4 step 3800 loss 0.0101
INFO:name:epoch 4 step 3900 loss 0.01333
INFO:name:epoch 4 step 4000 loss 0.01165
INFO:name:epoch 4 step 4100 loss 0.00975
INFO:name:epoch 4 step 4200 loss 0.01177
INFO:name:epoch 4 step 4300 loss 0.01193
INFO:name:epoch 4 step 4400 loss 0.01082
INFO:name:epoch 4 step 4500 loss 0.0118
INFO:name:epoch 4 step 4600 loss 0.01357
INFO:name:epoch 4 step 4700 loss 0.01164
INFO:name:epoch 4 step 4800 loss 0.01469
INFO:name:epoch 4 step 4900 loss 0.01276
INFO:name:epoch 4 step 5000 loss 0.01433
INFO:name:epoch 4 step 5100 loss 0.01072
INFO:name:epoch 4 step 5200 loss 0.01218
INFO:name:epoch 4 step 5300 loss 0.01453
INFO:name:epoch 4 step 5400 loss 0.01054
INFO:name:epoch 4 step 5500 loss 0.01009
INFO:name:epoch 4 step 5600 loss 0.01004
INFO:name:epoch 4 step 5700 loss 0.01161
INFO:name:epoch 4 step 5800 loss 0.01096
INFO:name:epoch 4 step 5900 loss 0.01173
INFO:name:epoch 4 step 6000 loss 0.00916
INFO:name:epoch 4 step 6100 loss 0.01184
INFO:name:epoch 4 step 6200 loss 0.00968
INFO:name:epoch 4 step 6300 loss 0.01133
INFO:name:epoch 4 step 6400 loss 0.01067
INFO:name:epoch 4 step 6500 loss 0.00944
INFO:name:epoch 4 step 6600 loss 0.01212
INFO:name:epoch 4 step 6700 loss 0.01069
INFO:name:epoch 4 step 6800 loss 0.01079
INFO:name:epoch 4 step 6900 loss 0.01348
INFO:name:epoch 4 step 7000 loss 0.01
INFO:name:epoch 4 step 7100 loss 0.01177
INFO:name:epoch 4 step 7200 loss 0.0106
INFO:name:epoch 4 step 7300 loss 0.01139
INFO:name:epoch 4 step 7400 loss 0.00828
INFO:name:epoch 4 step 7500 loss 0.01013
INFO:name:epoch 4 step 7600 loss 0.01014
INFO:name:epoch 4 step 7700 loss 0.01022
INFO:name:epoch 4 step 7800 loss 0.00984
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4011
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4011
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.339
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 5 step 100 loss 0.00962
INFO:name:epoch 5 step 200 loss 0.007
INFO:name:epoch 5 step 300 loss 0.00823
INFO:name:epoch 5 step 400 loss 0.01024
INFO:name:epoch 5 step 500 loss 0.00908
INFO:name:epoch 5 step 600 loss 0.00737
INFO:name:epoch 5 step 700 loss 0.00838
INFO:name:epoch 5 step 800 loss 0.01382
INFO:name:epoch 5 step 900 loss 0.00866
INFO:name:epoch 5 step 1000 loss 0.00987
INFO:name:epoch 5 step 1100 loss 0.00863
INFO:name:epoch 5 step 1200 loss 0.00801
INFO:name:epoch 5 step 1300 loss 0.01107
INFO:name:epoch 5 step 1400 loss 0.00813
INFO:name:epoch 5 step 1500 loss 0.00939
INFO:name:epoch 5 step 1600 loss 0.0093
INFO:name:epoch 5 step 1700 loss 0.00754
INFO:name:epoch 5 step 1800 loss 0.008
INFO:name:epoch 5 step 1900 loss 0.00748
INFO:name:epoch 5 step 2000 loss 0.00705
INFO:name:epoch 5 step 2100 loss 0.01145
INFO:name:epoch 5 step 2200 loss 0.00881
INFO:name:epoch 5 step 2300 loss 0.00944
INFO:name:epoch 5 step 2400 loss 0.00825
INFO:name:epoch 5 step 2500 loss 0.0084
INFO:name:epoch 5 step 2600 loss 0.01177
INFO:name:epoch 5 step 2700 loss 0.00791
INFO:name:epoch 5 step 2800 loss 0.00955
INFO:name:epoch 5 step 2900 loss 0.00839
INFO:name:epoch 5 step 3000 loss 0.00933
INFO:name:epoch 5 step 3100 loss 0.00641
INFO:name:epoch 5 step 3200 loss 0.00819
INFO:name:epoch 5 step 3300 loss 0.01066
INFO:name:epoch 5 step 3400 loss 0.01048
INFO:name:epoch 5 step 3500 loss 0.00796
INFO:name:epoch 5 step 3600 loss 0.00775
INFO:name:epoch 5 step 3700 loss 0.0103
INFO:name:epoch 5 step 3800 loss 0.00819
INFO:name:epoch 5 step 3900 loss 0.00836
INFO:name:epoch 5 step 4000 loss 0.00933
INFO:name:epoch 5 step 4100 loss 0.00883
INFO:name:epoch 5 step 4200 loss 0.00737
INFO:name:epoch 5 step 4300 loss 0.00899
INFO:name:epoch 5 step 4400 loss 0.0123
INFO:name:epoch 5 step 4500 loss 0.00841
INFO:name:epoch 5 step 4600 loss 0.00675
INFO:name:epoch 5 step 4700 loss 0.00857
INFO:name:epoch 5 step 4800 loss 0.00754
INFO:name:epoch 5 step 4900 loss 0.00862
INFO:name:epoch 5 step 5000 loss 0.00867
INFO:name:epoch 5 step 5100 loss 0.00856
INFO:name:epoch 5 step 5200 loss 0.00675
INFO:name:epoch 5 step 5300 loss 0.00974
INFO:name:epoch 5 step 5400 loss 0.00833
INFO:name:epoch 5 step 5500 loss 0.00935
INFO:name:epoch 5 step 5600 loss 0.01293
INFO:name:epoch 5 step 5700 loss 0.00831
INFO:name:epoch 5 step 5800 loss 0.00918
INFO:name:epoch 5 step 5900 loss 0.00947
INFO:name:epoch 5 step 6000 loss 0.00862
INFO:name:epoch 5 step 6100 loss 0.00906
INFO:name:epoch 5 step 6200 loss 0.00911
INFO:name:epoch 5 step 6300 loss 0.00868
INFO:name:epoch 5 step 6400 loss 0.0069
INFO:name:epoch 5 step 6500 loss 0.01169
INFO:name:epoch 5 step 6600 loss 0.00929
INFO:name:epoch 5 step 6700 loss 0.00925
INFO:name:epoch 5 step 6800 loss 0.00849
INFO:name:epoch 5 step 6900 loss 0.00955
INFO:name:epoch 5 step 7000 loss 0.00982
INFO:name:epoch 5 step 7100 loss 0.01018
INFO:name:epoch 5 step 7200 loss 0.0101
INFO:name:epoch 5 step 7300 loss 0.0088
INFO:name:epoch 5 step 7400 loss 0.00773
INFO:name:epoch 5 step 7500 loss 0.00847
INFO:name:epoch 5 step 7600 loss 0.01012
INFO:name:epoch 5 step 7700 loss 0.01159
INFO:name:epoch 5 step 7800 loss 0.0096
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3899
INFO:name:epoch 6 step 100 loss 0.00873
INFO:name:epoch 6 step 200 loss 0.00734
INFO:name:epoch 6 step 300 loss 0.008
INFO:name:epoch 6 step 400 loss 0.0058
INFO:name:epoch 6 step 500 loss 0.00789
INFO:name:epoch 6 step 600 loss 0.01044
INFO:name:epoch 6 step 700 loss 0.00677
INFO:name:epoch 6 step 800 loss 0.00723
INFO:name:epoch 6 step 900 loss 0.00869
INFO:name:epoch 6 step 1000 loss 0.00705
INFO:name:epoch 6 step 1100 loss 0.00762
INFO:name:epoch 6 step 1200 loss 0.00663
INFO:name:epoch 6 step 1300 loss 0.00843
INFO:name:epoch 6 step 1400 loss 0.00741
INFO:name:epoch 6 step 1500 loss 0.00839
INFO:name:epoch 6 step 1600 loss 0.00745
INFO:name:epoch 6 step 1700 loss 0.00747
INFO:name:epoch 6 step 1800 loss 0.0064
INFO:name:epoch 6 step 1900 loss 0.00834
INFO:name:epoch 6 step 2000 loss 0.00728
INFO:name:epoch 6 step 2100 loss 0.00586
INFO:name:epoch 6 step 2200 loss 0.00963
INFO:name:epoch 6 step 2300 loss 0.00632
INFO:name:epoch 6 step 2400 loss 0.00724
INFO:name:epoch 6 step 2500 loss 0.00924
INFO:name:epoch 6 step 2600 loss 0.00866
INFO:name:epoch 6 step 2700 loss 0.00757
INFO:name:epoch 6 step 2800 loss 0.00735
INFO:name:epoch 6 step 2900 loss 0.00823
INFO:name:epoch 6 step 3000 loss 0.00897
INFO:name:epoch 6 step 3100 loss 0.00896
INFO:name:epoch 6 step 3200 loss 0.00596
INFO:name:epoch 6 step 3300 loss 0.00919
INFO:name:epoch 6 step 3400 loss 0.00716
INFO:name:epoch 6 step 3500 loss 0.00693
INFO:name:epoch 6 step 3600 loss 0.00558
INFO:name:epoch 6 step 3700 loss 0.00755
INFO:name:epoch 6 step 3800 loss 0.00726
INFO:name:epoch 6 step 3900 loss 0.00984
INFO:name:epoch 6 step 4000 loss 0.00649
INFO:name:epoch 6 step 4100 loss 0.00867
INFO:name:epoch 6 step 4200 loss 0.00831
INFO:name:epoch 6 step 4300 loss 0.00554
INFO:name:epoch 6 step 4400 loss 0.00728
INFO:name:epoch 6 step 4500 loss 0.00716
INFO:name:epoch 6 step 4600 loss 0.00852
INFO:name:epoch 6 step 4700 loss 0.00626
INFO:name:epoch 6 step 4800 loss 0.00746
INFO:name:epoch 6 step 4900 loss 0.00597
INFO:name:epoch 6 step 5000 loss 0.00637
INFO:name:epoch 6 step 5100 loss 0.0102
INFO:name:epoch 6 step 5200 loss 0.00708
INFO:name:epoch 6 step 5300 loss 0.00543
INFO:name:epoch 6 step 5400 loss 0.0069
INFO:name:epoch 6 step 5500 loss 0.0061
INFO:name:epoch 6 step 5600 loss 0.00685
INFO:name:epoch 6 step 5700 loss 0.00978
INFO:name:epoch 6 step 5800 loss 0.00855
INFO:name:epoch 6 step 5900 loss 0.00709
INFO:name:epoch 6 step 6000 loss 0.00644
INFO:name:epoch 6 step 6100 loss 0.00585
INFO:name:epoch 6 step 6200 loss 0.00753
INFO:name:epoch 6 step 6300 loss 0.00777
INFO:name:epoch 6 step 6400 loss 0.01048
INFO:name:epoch 6 step 6500 loss 0.00762
INFO:name:epoch 6 step 6600 loss 0.00797
INFO:name:epoch 6 step 6700 loss 0.00856
INFO:name:epoch 6 step 6800 loss 0.00842
INFO:name:epoch 6 step 6900 loss 0.00679
INFO:name:epoch 6 step 7000 loss 0.0075
INFO:name:epoch 6 step 7100 loss 0.00811
INFO:name:epoch 6 step 7200 loss 0.00807
INFO:name:epoch 6 step 7300 loss 0.00548
INFO:name:epoch 6 step 7400 loss 0.00647
INFO:name:epoch 6 step 7500 loss 0.00817
INFO:name:epoch 6 step 7600 loss 0.00775
INFO:name:epoch 6 step 7700 loss 0.00761
INFO:name:epoch 6 step 7800 loss 0.00877
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3857
INFO:name:epoch 7 step 100 loss 0.00697
INFO:name:epoch 7 step 200 loss 0.0062
INFO:name:epoch 7 step 300 loss 0.00687
INFO:name:epoch 7 step 400 loss 0.00655
INFO:name:epoch 7 step 500 loss 0.0082
INFO:name:epoch 7 step 600 loss 0.00679
INFO:name:epoch 7 step 700 loss 0.00634
INFO:name:epoch 7 step 800 loss 0.0068
INFO:name:epoch 7 step 900 loss 0.00765
INFO:name:epoch 7 step 1000 loss 0.00811
INFO:name:epoch 7 step 1100 loss 0.00567
INFO:name:epoch 7 step 1200 loss 0.00565
INFO:name:epoch 7 step 1300 loss 0.00537
INFO:name:epoch 7 step 1400 loss 0.00667
INFO:name:epoch 7 step 1500 loss 0.00762
INFO:name:epoch 7 step 1600 loss 0.00721
INFO:name:epoch 7 step 1700 loss 0.00661
INFO:name:epoch 7 step 1800 loss 0.00658
INFO:name:epoch 7 step 1900 loss 0.00668
INFO:name:epoch 7 step 2000 loss 0.00691
INFO:name:epoch 7 step 2100 loss 0.00661
INFO:name:epoch 7 step 2200 loss 0.00542
INFO:name:epoch 7 step 2300 loss 0.00668
INFO:name:epoch 7 step 2400 loss 0.00601
INFO:name:epoch 7 step 2500 loss 0.00485
INFO:name:epoch 7 step 2600 loss 0.00573
INFO:name:epoch 7 step 2700 loss 0.0058
INFO:name:epoch 7 step 2800 loss 0.00666
INFO:name:epoch 7 step 2900 loss 0.00509
INFO:name:epoch 7 step 3000 loss 0.00548
INFO:name:epoch 7 step 3100 loss 0.00714
INFO:name:epoch 7 step 3200 loss 0.00725
INFO:name:epoch 7 step 3300 loss 0.00589
INFO:name:epoch 7 step 3400 loss 0.00518
INFO:name:epoch 7 step 3500 loss 0.00623
INFO:name:epoch 7 step 3600 loss 0.00752
INFO:name:epoch 7 step 3700 loss 0.00786
INFO:name:epoch 7 step 3800 loss 0.00671
INFO:name:epoch 7 step 3900 loss 0.00747
INFO:name:epoch 7 step 4000 loss 0.00591
INFO:name:epoch 7 step 4100 loss 0.00557
INFO:name:epoch 7 step 4200 loss 0.00688
INFO:name:epoch 7 step 4300 loss 0.00642
INFO:name:epoch 7 step 4400 loss 0.00523
INFO:name:epoch 7 step 4500 loss 0.00585
INFO:name:epoch 7 step 4600 loss 0.00563
INFO:name:epoch 7 step 4700 loss 0.00765
INFO:name:epoch 7 step 4800 loss 0.00625
INFO:name:epoch 7 step 4900 loss 0.00838
INFO:name:epoch 7 step 5000 loss 0.0066
INFO:name:epoch 7 step 5100 loss 0.00507
INFO:name:epoch 7 step 5200 loss 0.00745
INFO:name:epoch 7 step 5300 loss 0.00561
INFO:name:epoch 7 step 5400 loss 0.0069
INFO:name:epoch 7 step 5500 loss 0.00709
INFO:name:epoch 7 step 5600 loss 0.0078
INFO:name:epoch 7 step 5700 loss 0.00695
INFO:name:epoch 7 step 5800 loss 0.00689
INFO:name:epoch 7 step 5900 loss 0.00537
INFO:name:epoch 7 step 6000 loss 0.0057
INFO:name:epoch 7 step 6100 loss 0.00684
INFO:name:epoch 7 step 6200 loss 0.00621
INFO:name:epoch 7 step 6300 loss 0.00585
INFO:name:epoch 7 step 6400 loss 0.006
INFO:name:epoch 7 step 6500 loss 0.0054
INFO:name:epoch 7 step 6600 loss 0.0056
INFO:name:epoch 7 step 6700 loss 0.00644
INFO:name:epoch 7 step 6800 loss 0.00693
INFO:name:epoch 7 step 6900 loss 0.00435
INFO:name:epoch 7 step 7000 loss 0.00822
INFO:name:epoch 7 step 7100 loss 0.00684
INFO:name:epoch 7 step 7200 loss 0.00789
INFO:name:epoch 7 step 7300 loss 0.00688
INFO:name:epoch 7 step 7400 loss 0.00634
INFO:name:epoch 7 step 7500 loss 0.00736
INFO:name:epoch 7 step 7600 loss 0.00766
INFO:name:epoch 7 step 7700 loss 0.00459
INFO:name:epoch 7 step 7800 loss 0.00536
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3874
INFO:name:epoch 8 step 100 loss 0.00617
INFO:name:epoch 8 step 200 loss 0.00675
INFO:name:epoch 8 step 300 loss 0.00626
INFO:name:epoch 8 step 400 loss 0.00431
INFO:name:epoch 8 step 500 loss 0.00477
INFO:name:epoch 8 step 600 loss 0.00595
INFO:name:epoch 8 step 700 loss 0.00516
INFO:name:epoch 8 step 800 loss 0.00745
INFO:name:epoch 8 step 900 loss 0.00689
INFO:name:epoch 8 step 1000 loss 0.00492
INFO:name:epoch 8 step 1100 loss 0.00608
INFO:name:epoch 8 step 1200 loss 0.00496
INFO:name:epoch 8 step 1300 loss 0.00588
INFO:name:epoch 8 step 1400 loss 0.00603
INFO:name:epoch 8 step 1500 loss 0.00415
INFO:name:epoch 8 step 1600 loss 0.00389
INFO:name:epoch 8 step 1700 loss 0.00588
INFO:name:epoch 8 step 1800 loss 0.00585
INFO:name:epoch 8 step 1900 loss 0.00612
INFO:name:epoch 8 step 2000 loss 0.00659
INFO:name:epoch 8 step 2100 loss 0.00539
INFO:name:epoch 8 step 2200 loss 0.00714
INFO:name:epoch 8 step 2300 loss 0.00699
INFO:name:epoch 8 step 2400 loss 0.00557
INFO:name:epoch 8 step 2500 loss 0.00401
INFO:name:epoch 8 step 2600 loss 0.00545
INFO:name:epoch 8 step 2700 loss 0.00536
INFO:name:epoch 8 step 2800 loss 0.00634
INFO:name:epoch 8 step 2900 loss 0.00665
INFO:name:epoch 8 step 3000 loss 0.00502
INFO:name:epoch 8 step 3100 loss 0.00531
INFO:name:epoch 8 step 3200 loss 0.00619
INFO:name:epoch 8 step 3300 loss 0.00639
INFO:name:epoch 8 step 3400 loss 0.00785
INFO:name:epoch 8 step 3500 loss 0.00488
INFO:name:epoch 8 step 3600 loss 0.00533
INFO:name:epoch 8 step 3700 loss 0.00632
INFO:name:epoch 8 step 3800 loss 0.00553
INFO:name:epoch 8 step 3900 loss 0.00649
INFO:name:epoch 8 step 4000 loss 0.00545
INFO:name:epoch 8 step 4100 loss 0.00534
INFO:name:epoch 8 step 4200 loss 0.00687
INFO:name:epoch 8 step 4300 loss 0.00536
INFO:name:epoch 8 step 4400 loss 0.00707
INFO:name:epoch 8 step 4500 loss 0.00593
INFO:name:epoch 8 step 4600 loss 0.00751
INFO:name:epoch 8 step 4700 loss 0.00506
INFO:name:epoch 8 step 4800 loss 0.0053
INFO:name:epoch 8 step 4900 loss 0.00443
INFO:name:epoch 8 step 5000 loss 0.00518
INFO:name:epoch 8 step 5100 loss 0.0056
INFO:name:epoch 8 step 5200 loss 0.00527
INFO:name:epoch 8 step 5300 loss 0.00454
INFO:name:epoch 8 step 5400 loss 0.00519
INFO:name:epoch 8 step 5500 loss 0.00448
INFO:name:epoch 8 step 5600 loss 0.00582
INFO:name:epoch 8 step 5700 loss 0.00571
INFO:name:epoch 8 step 5800 loss 0.00611
INFO:name:epoch 8 step 5900 loss 0.00608
INFO:name:epoch 8 step 6000 loss 0.00636
INFO:name:epoch 8 step 6100 loss 0.00501
INFO:name:epoch 8 step 6200 loss 0.00492
INFO:name:epoch 8 step 6300 loss 0.00506
INFO:name:epoch 8 step 6400 loss 0.00581
INFO:name:epoch 8 step 6500 loss 0.00829
INFO:name:epoch 8 step 6600 loss 0.00598
INFO:name:epoch 8 step 6700 loss 0.00648
INFO:name:epoch 8 step 6800 loss 0.00714
INFO:name:epoch 8 step 6900 loss 0.00629
INFO:name:epoch 8 step 7000 loss 0.00605
INFO:name:epoch 8 step 7100 loss 0.00493
INFO:name:epoch 8 step 7200 loss 0.00485
INFO:name:epoch 8 step 7300 loss 0.00541
INFO:name:epoch 8 step 7400 loss 0.00432
INFO:name:epoch 8 step 7500 loss 0.00628
INFO:name:epoch 8 step 7600 loss 0.0049
INFO:name:epoch 8 step 7700 loss 0.0068
INFO:name:epoch 8 step 7800 loss 0.00674
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3983
INFO:name:epoch 9 step 100 loss 0.00582
INFO:name:epoch 9 step 200 loss 0.00557
INFO:name:epoch 9 step 300 loss 0.00402
INFO:name:epoch 9 step 400 loss 0.00513
INFO:name:epoch 9 step 500 loss 0.00463
INFO:name:epoch 9 step 600 loss 0.00421
INFO:name:epoch 9 step 700 loss 0.00554
INFO:name:epoch 9 step 800 loss 0.00525
INFO:name:epoch 9 step 900 loss 0.00464
INFO:name:epoch 9 step 1000 loss 0.00608
INFO:name:epoch 9 step 1100 loss 0.00567
INFO:name:epoch 9 step 1200 loss 0.00433
INFO:name:epoch 9 step 1300 loss 0.00576
INFO:name:epoch 9 step 1400 loss 0.0055
INFO:name:epoch 9 step 1500 loss 0.0044
INFO:name:epoch 9 step 1600 loss 0.00493
INFO:name:epoch 9 step 1700 loss 0.00567
INFO:name:epoch 9 step 1800 loss 0.00443
INFO:name:epoch 9 step 1900 loss 0.0058
INFO:name:epoch 9 step 2000 loss 0.00467
INFO:name:epoch 9 step 2100 loss 0.00402
INFO:name:epoch 9 step 2200 loss 0.00503
INFO:name:epoch 9 step 2300 loss 0.00453
INFO:name:epoch 9 step 2400 loss 0.0058
INFO:name:epoch 9 step 2500 loss 0.00548
INFO:name:epoch 9 step 2600 loss 0.00424
INFO:name:epoch 9 step 2700 loss 0.0067
INFO:name:epoch 9 step 2800 loss 0.00578
INFO:name:epoch 9 step 2900 loss 0.00656
INFO:name:epoch 9 step 3000 loss 0.00738
INFO:name:epoch 9 step 3100 loss 0.00547
INFO:name:epoch 9 step 3200 loss 0.00623
INFO:name:epoch 9 step 3300 loss 0.00423
INFO:name:epoch 9 step 3400 loss 0.00401
INFO:name:epoch 9 step 3500 loss 0.00443
INFO:name:epoch 9 step 3600 loss 0.00538
INFO:name:epoch 9 step 3700 loss 0.00484
INFO:name:epoch 9 step 3800 loss 0.00498
INFO:name:epoch 9 step 3900 loss 0.00452
INFO:name:epoch 9 step 4000 loss 0.00484
INFO:name:epoch 9 step 4100 loss 0.00449
INFO:name:epoch 9 step 4200 loss 0.00477
INFO:name:epoch 9 step 4300 loss 0.00579
INFO:name:epoch 9 step 4400 loss 0.00578
INFO:name:epoch 9 step 4500 loss 0.0045
INFO:name:epoch 9 step 4600 loss 0.00433
INFO:name:epoch 9 step 4700 loss 0.00615
INFO:name:epoch 9 step 4800 loss 0.00659
INFO:name:epoch 9 step 4900 loss 0.00577
INFO:name:epoch 9 step 5000 loss 0.00467
INFO:name:epoch 9 step 5100 loss 0.00523
INFO:name:epoch 9 step 5200 loss 0.00609
INFO:name:epoch 9 step 5300 loss 0.00359
INFO:name:epoch 9 step 5400 loss 0.00413
INFO:name:epoch 9 step 5500 loss 0.00489
