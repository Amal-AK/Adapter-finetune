/opt/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
INFO:name:device: cuda:0, n_gpu: 1
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /microsoft/unixcoder-base/resolve/main/config.json HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /microsoft/unixcoder-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
INFO:name:Preparing the code search Dataset...

INFO:name:Preparing the code search Dataset...

INFO:name:Preparing the code search Dataset...

INFO:name:[{'insert_modules': ('attention.output',), 'bottleneck_dim': (32,), 'non_linearity': 'relu', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('intermediate', 'output', 'attention.self'), 'bottleneck_dim': (64, 256, 32), 'non_linearity': 'relu', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}, 0, {'insert_modules': ('attention.output', 'output'), 'bottleneck_dim': (32, 256), 'non_linearity': 'silu', 'dropout_rate': 0.2, 'normalization': None, 'skip_connection': True}, 0, 0, 0, 0, 0, 0, {'insert_modules': ('attention.self', 'intermediate', 'output'), 'bottleneck_dim': (32, 128, 128), 'non_linearity': 'silu', 'dropout_rate': 0.3, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.self',), 'bottleneck_dim': (32,), 'non_linearity': 'swish', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}]
[INFO|(OpenDelta)basemodel:700]2025-01-06 16:36:45,293 >> Trainable Ratio: 2421728/128351456=1.886794%
[INFO|(OpenDelta)basemodel:702]2025-01-06 16:36:45,293 >> Delta Parameter Ratio: 2421728/128351456=1.886794%
[INFO|(OpenDelta)basemodel:704]2025-01-06 16:36:45,293 >> Static Memory 0.00 GB, Max Memory 0.00 GB
INFO:name:2.77
/opt/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:name:***** Running training *****
INFO:name:  Num examples = 251820
INFO:name:  Num Epochs = 15
INFO:name:  Instantaneous batch size per GPU = 32
INFO:name:  Total train batch size  = 32
INFO:name:  Total optimization steps = 118050
INFO:name:epoch 0 step 100 loss 0.32266
INFO:name:epoch 0 step 200 loss 0.17043
INFO:name:epoch 0 step 300 loss 0.14073
INFO:name:epoch 0 step 400 loss 0.11613
INFO:name:epoch 0 step 500 loss 0.1198
INFO:name:epoch 0 step 600 loss 0.10943
INFO:name:epoch 0 step 700 loss 0.11032
INFO:name:epoch 0 step 800 loss 0.10635
INFO:name:epoch 0 step 900 loss 0.10418
INFO:name:epoch 0 step 1000 loss 0.09659
INFO:name:epoch 0 step 1100 loss 0.09353
INFO:name:epoch 0 step 1200 loss 0.09841
INFO:name:epoch 0 step 1300 loss 0.08628
INFO:name:epoch 0 step 1400 loss 0.10877
INFO:name:epoch 0 step 1500 loss 0.09389
INFO:name:epoch 0 step 1600 loss 0.08203
INFO:name:epoch 0 step 1700 loss 0.09733
INFO:name:epoch 0 step 1800 loss 0.0997
INFO:name:epoch 0 step 1900 loss 0.08799
INFO:name:epoch 0 step 2000 loss 0.0933
INFO:name:epoch 0 step 2100 loss 0.09165
INFO:name:epoch 0 step 2200 loss 0.07667
INFO:name:epoch 0 step 2300 loss 0.10178
INFO:name:epoch 0 step 2400 loss 0.0984
INFO:name:epoch 0 step 2500 loss 0.07956
INFO:name:epoch 0 step 2600 loss 0.08517
INFO:name:epoch 0 step 2700 loss 0.08625
INFO:name:epoch 0 step 2800 loss 0.09291
INFO:name:epoch 0 step 2900 loss 0.10214
INFO:name:epoch 0 step 3000 loss 0.08155
INFO:name:epoch 0 step 3100 loss 0.07804
INFO:name:epoch 0 step 3200 loss 0.08086
INFO:name:epoch 0 step 3300 loss 0.07862
INFO:name:epoch 0 step 3400 loss 0.07755
INFO:name:epoch 0 step 3500 loss 0.0708
INFO:name:epoch 0 step 3600 loss 0.08772
INFO:name:epoch 0 step 3700 loss 0.08654
INFO:name:epoch 0 step 3800 loss 0.08633
INFO:name:epoch 0 step 3900 loss 0.08027
INFO:name:epoch 0 step 4000 loss 0.09151
INFO:name:epoch 0 step 4100 loss 0.08628
INFO:name:epoch 0 step 4200 loss 0.08565
INFO:name:epoch 0 step 4300 loss 0.09096
INFO:name:epoch 0 step 4400 loss 0.07798
INFO:name:epoch 0 step 4500 loss 0.08674
INFO:name:epoch 0 step 4600 loss 0.07334
INFO:name:epoch 0 step 4700 loss 0.07771
INFO:name:epoch 0 step 4800 loss 0.07324
INFO:name:epoch 0 step 4900 loss 0.06991
INFO:name:epoch 0 step 5000 loss 0.07294
INFO:name:epoch 0 step 5100 loss 0.09265
INFO:name:epoch 0 step 5200 loss 0.07499
INFO:name:epoch 0 step 5300 loss 0.07758
INFO:name:epoch 0 step 5400 loss 0.07537
INFO:name:epoch 0 step 5500 loss 0.07613
INFO:name:epoch 0 step 5600 loss 0.07742
INFO:name:epoch 0 step 5700 loss 0.0778
INFO:name:epoch 0 step 5800 loss 0.08572
INFO:name:epoch 0 step 5900 loss 0.07657
INFO:name:epoch 0 step 6000 loss 0.07264
INFO:name:epoch 0 step 6100 loss 0.06822
INFO:name:epoch 0 step 6200 loss 0.06211
INFO:name:epoch 0 step 6300 loss 0.08884
INFO:name:epoch 0 step 6400 loss 0.08025
INFO:name:epoch 0 step 6500 loss 0.07252
INFO:name:epoch 0 step 6600 loss 0.07929
INFO:name:epoch 0 step 6700 loss 0.08005
INFO:name:epoch 0 step 6800 loss 0.07466
INFO:name:epoch 0 step 6900 loss 0.07597
INFO:name:epoch 0 step 7000 loss 0.08001
INFO:name:epoch 0 step 7100 loss 0.08317
INFO:name:epoch 0 step 7200 loss 0.06732
INFO:name:epoch 0 step 7300 loss 0.07353
INFO:name:epoch 0 step 7400 loss 0.06713
INFO:name:epoch 0 step 7500 loss 0.07357
INFO:name:epoch 0 step 7600 loss 0.07304
INFO:name:epoch 0 step 7700 loss 0.07377
INFO:name:epoch 0 step 7800 loss 0.07171
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4468
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4468
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3789
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 1 step 100 loss 0.05961
INFO:name:epoch 1 step 200 loss 0.03995
INFO:name:epoch 1 step 300 loss 0.03605
INFO:name:epoch 1 step 400 loss 0.03546
INFO:name:epoch 1 step 500 loss 0.04355
INFO:name:epoch 1 step 600 loss 0.04193
INFO:name:epoch 1 step 700 loss 0.0413
INFO:name:epoch 1 step 800 loss 0.04279
INFO:name:epoch 1 step 900 loss 0.04198
INFO:name:epoch 1 step 1000 loss 0.04147
INFO:name:epoch 1 step 1100 loss 0.04158
INFO:name:epoch 1 step 1200 loss 0.05875
INFO:name:epoch 1 step 1300 loss 0.04755
INFO:name:epoch 1 step 1400 loss 0.03539
INFO:name:epoch 1 step 1500 loss 0.04269
INFO:name:epoch 1 step 1600 loss 0.05526
INFO:name:epoch 1 step 1700 loss 0.0434
INFO:name:epoch 1 step 1800 loss 0.04724
INFO:name:epoch 1 step 1900 loss 0.04168
INFO:name:epoch 1 step 2000 loss 0.04958
INFO:name:epoch 1 step 2100 loss 0.03965
INFO:name:epoch 1 step 2200 loss 0.05115
INFO:name:epoch 1 step 2300 loss 0.05009
INFO:name:epoch 1 step 2400 loss 0.04696
INFO:name:epoch 1 step 2500 loss 0.04238
INFO:name:epoch 1 step 2600 loss 0.03833
INFO:name:epoch 1 step 2700 loss 0.0441
INFO:name:epoch 1 step 2800 loss 0.04728
INFO:name:epoch 1 step 2900 loss 0.04494
INFO:name:epoch 1 step 3000 loss 0.04513
INFO:name:epoch 1 step 3100 loss 0.05369
INFO:name:epoch 1 step 3200 loss 0.05115
INFO:name:epoch 1 step 3300 loss 0.04584
INFO:name:epoch 1 step 3400 loss 0.04008
INFO:name:epoch 1 step 3500 loss 0.04456
INFO:name:epoch 1 step 3600 loss 0.0436
INFO:name:epoch 1 step 3700 loss 0.04412
INFO:name:epoch 1 step 3800 loss 0.04393
INFO:name:epoch 1 step 3900 loss 0.04029
INFO:name:epoch 1 step 4000 loss 0.04466
INFO:name:epoch 1 step 4100 loss 0.05481
INFO:name:epoch 1 step 4200 loss 0.04519
INFO:name:epoch 1 step 4300 loss 0.04784
INFO:name:epoch 1 step 4400 loss 0.03662
INFO:name:epoch 1 step 4500 loss 0.04485
INFO:name:epoch 1 step 4600 loss 0.03978
INFO:name:epoch 1 step 4700 loss 0.04308
INFO:name:epoch 1 step 4800 loss 0.03274
INFO:name:epoch 1 step 4900 loss 0.04588
INFO:name:epoch 1 step 5000 loss 0.03886
INFO:name:epoch 1 step 5100 loss 0.03313
INFO:name:epoch 1 step 5200 loss 0.05786
INFO:name:epoch 1 step 5300 loss 0.04075
INFO:name:epoch 1 step 5400 loss 0.04186
INFO:name:epoch 1 step 5500 loss 0.04088
INFO:name:epoch 1 step 5600 loss 0.03598
INFO:name:epoch 1 step 5700 loss 0.04947
INFO:name:epoch 1 step 5800 loss 0.037
INFO:name:epoch 1 step 5900 loss 0.03875
INFO:name:epoch 1 step 6000 loss 0.0473
INFO:name:epoch 1 step 6100 loss 0.04499
INFO:name:epoch 1 step 6200 loss 0.04625
INFO:name:epoch 1 step 6300 loss 0.04516
INFO:name:epoch 1 step 6400 loss 0.04958
INFO:name:epoch 1 step 6500 loss 0.04697
INFO:name:epoch 1 step 6600 loss 0.04871
INFO:name:epoch 1 step 6700 loss 0.04364
INFO:name:epoch 1 step 6800 loss 0.0473
INFO:name:epoch 1 step 6900 loss 0.04119
INFO:name:epoch 1 step 7000 loss 0.04788
INFO:name:epoch 1 step 7100 loss 0.04209
INFO:name:epoch 1 step 7200 loss 0.03886
INFO:name:epoch 1 step 7300 loss 0.05378
INFO:name:epoch 1 step 7400 loss 0.0451
INFO:name:epoch 1 step 7500 loss 0.04093
INFO:name:epoch 1 step 7600 loss 0.04273
INFO:name:epoch 1 step 7700 loss 0.04615
INFO:name:epoch 1 step 7800 loss 0.04683
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.467
INFO:name:  ********************
INFO:name:  Best eval mrr:0.467
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3984
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 2 step 100 loss 0.03775
INFO:name:epoch 2 step 200 loss 0.03565
INFO:name:epoch 2 step 300 loss 0.03374
INFO:name:epoch 2 step 400 loss 0.03347
INFO:name:epoch 2 step 500 loss 0.03725
INFO:name:epoch 2 step 600 loss 0.03566
INFO:name:epoch 2 step 700 loss 0.03832
INFO:name:epoch 2 step 800 loss 0.03492
INFO:name:epoch 2 step 900 loss 0.03728
INFO:name:epoch 2 step 1000 loss 0.03669
INFO:name:epoch 2 step 1100 loss 0.03879
INFO:name:epoch 2 step 1200 loss 0.03659
INFO:name:epoch 2 step 1300 loss 0.03201
INFO:name:epoch 2 step 1400 loss 0.03824
INFO:name:epoch 2 step 1500 loss 0.02948
INFO:name:epoch 2 step 1600 loss 0.03599
INFO:name:epoch 2 step 1700 loss 0.02876
INFO:name:epoch 2 step 1800 loss 0.03524
INFO:name:epoch 2 step 1900 loss 0.04403
INFO:name:epoch 2 step 2000 loss 0.02627
INFO:name:epoch 2 step 2100 loss 0.03072
INFO:name:epoch 2 step 2200 loss 0.0352
INFO:name:epoch 2 step 2300 loss 0.03237
INFO:name:epoch 2 step 2400 loss 0.03694
INFO:name:epoch 2 step 2500 loss 0.03205
INFO:name:epoch 2 step 2600 loss 0.02972
INFO:name:epoch 2 step 2700 loss 0.03137
INFO:name:epoch 2 step 2800 loss 0.03848
INFO:name:epoch 2 step 2900 loss 0.03205
INFO:name:epoch 2 step 3000 loss 0.02755
INFO:name:epoch 2 step 3100 loss 0.03485
INFO:name:epoch 2 step 3200 loss 0.03143
INFO:name:epoch 2 step 3300 loss 0.02962
INFO:name:epoch 2 step 3400 loss 0.04179
INFO:name:epoch 2 step 3500 loss 0.03242
INFO:name:epoch 2 step 3600 loss 0.02878
INFO:name:epoch 2 step 3700 loss 0.03098
INFO:name:epoch 2 step 3800 loss 0.03465
INFO:name:epoch 2 step 3900 loss 0.03473
INFO:name:epoch 2 step 4000 loss 0.03836
INFO:name:epoch 2 step 4100 loss 0.03614
INFO:name:epoch 2 step 4200 loss 0.03954
INFO:name:epoch 2 step 4300 loss 0.03487
INFO:name:epoch 2 step 4400 loss 0.03533
INFO:name:epoch 2 step 4500 loss 0.03366
INFO:name:epoch 2 step 4600 loss 0.0325
INFO:name:epoch 2 step 4700 loss 0.03445
INFO:name:epoch 2 step 4800 loss 0.02793
INFO:name:epoch 2 step 4900 loss 0.02767
INFO:name:epoch 2 step 5000 loss 0.0434
INFO:name:epoch 2 step 5100 loss 0.03455
INFO:name:epoch 2 step 5200 loss 0.03594
INFO:name:epoch 2 step 5300 loss 0.03501
INFO:name:epoch 2 step 5400 loss 0.0363
INFO:name:epoch 2 step 5500 loss 0.03711
INFO:name:epoch 2 step 5600 loss 0.02985
INFO:name:epoch 2 step 5700 loss 0.03489
INFO:name:epoch 2 step 5800 loss 0.03687
INFO:name:epoch 2 step 5900 loss 0.0365
INFO:name:epoch 2 step 6000 loss 0.03726
INFO:name:epoch 2 step 6100 loss 0.03017
INFO:name:epoch 2 step 6200 loss 0.03342
INFO:name:epoch 2 step 6300 loss 0.0345
INFO:name:epoch 2 step 6400 loss 0.03268
INFO:name:epoch 2 step 6500 loss 0.02982
INFO:name:epoch 2 step 6600 loss 0.03415
INFO:name:epoch 2 step 6700 loss 0.03508
INFO:name:epoch 2 step 6800 loss 0.03422
INFO:name:epoch 2 step 6900 loss 0.03939
INFO:name:epoch 2 step 7000 loss 0.02886
INFO:name:epoch 2 step 7100 loss 0.03405
INFO:name:epoch 2 step 7200 loss 0.02859
INFO:name:epoch 2 step 7300 loss 0.03145
INFO:name:epoch 2 step 7400 loss 0.03821
INFO:name:epoch 2 step 7500 loss 0.03866
INFO:name:epoch 2 step 7600 loss 0.0295
INFO:name:epoch 2 step 7700 loss 0.03855
INFO:name:epoch 2 step 7800 loss 0.02808
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4717
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4717
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4049
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 3 step 100 loss 0.02736
INFO:name:epoch 3 step 200 loss 0.02617
INFO:name:epoch 3 step 300 loss 0.02621
INFO:name:epoch 3 step 400 loss 0.024
INFO:name:epoch 3 step 500 loss 0.0301
INFO:name:epoch 3 step 600 loss 0.02444
INFO:name:epoch 3 step 700 loss 0.02482
INFO:name:epoch 3 step 800 loss 0.03625
INFO:name:epoch 3 step 900 loss 0.02555
INFO:name:epoch 3 step 1000 loss 0.02403
INFO:name:epoch 3 step 1100 loss 0.02723
INFO:name:epoch 3 step 1200 loss 0.02956
INFO:name:epoch 3 step 1300 loss 0.02229
INFO:name:epoch 3 step 1400 loss 0.02529
INFO:name:epoch 3 step 1500 loss 0.02474
INFO:name:epoch 3 step 1600 loss 0.02475
INFO:name:epoch 3 step 1700 loss 0.02477
INFO:name:epoch 3 step 1800 loss 0.02366
INFO:name:epoch 3 step 1900 loss 0.02308
INFO:name:epoch 3 step 2000 loss 0.02623
INFO:name:epoch 3 step 2100 loss 0.03154
INFO:name:epoch 3 step 2200 loss 0.02045
INFO:name:epoch 3 step 2300 loss 0.02562
INFO:name:epoch 3 step 2400 loss 0.02961
INFO:name:epoch 3 step 2500 loss 0.02814
INFO:name:epoch 3 step 2600 loss 0.02599
INFO:name:epoch 3 step 2700 loss 0.03376
INFO:name:epoch 3 step 2800 loss 0.02945
INFO:name:epoch 3 step 2900 loss 0.02969
INFO:name:epoch 3 step 3000 loss 0.03027
INFO:name:epoch 3 step 3100 loss 0.01924
INFO:name:epoch 3 step 3200 loss 0.0213
INFO:name:epoch 3 step 3300 loss 0.02632
INFO:name:epoch 3 step 3400 loss 0.02606
INFO:name:epoch 3 step 3500 loss 0.02518
INFO:name:epoch 3 step 3600 loss 0.02243
INFO:name:epoch 3 step 3700 loss 0.02719
INFO:name:epoch 3 step 3800 loss 0.02309
INFO:name:epoch 3 step 3900 loss 0.02648
INFO:name:epoch 3 step 4000 loss 0.02789
INFO:name:epoch 3 step 4100 loss 0.02564
INFO:name:epoch 3 step 4200 loss 0.02559
INFO:name:epoch 3 step 4300 loss 0.02484
INFO:name:epoch 3 step 4400 loss 0.02755
INFO:name:epoch 3 step 4500 loss 0.02016
INFO:name:epoch 3 step 4600 loss 0.0276
INFO:name:epoch 3 step 4700 loss 0.03026
INFO:name:epoch 3 step 4800 loss 0.02645
INFO:name:epoch 3 step 4900 loss 0.02909
INFO:name:epoch 3 step 5000 loss 0.03085
INFO:name:epoch 3 step 5100 loss 0.02728
INFO:name:epoch 3 step 5200 loss 0.02365
INFO:name:epoch 3 step 5300 loss 0.02483
INFO:name:epoch 3 step 5400 loss 0.02138
INFO:name:epoch 3 step 5500 loss 0.02779
INFO:name:epoch 3 step 5600 loss 0.02453
INFO:name:epoch 3 step 5700 loss 0.02309
INFO:name:epoch 3 step 5800 loss 0.02894
INFO:name:epoch 3 step 5900 loss 0.027
INFO:name:epoch 3 step 6000 loss 0.03204
INFO:name:epoch 3 step 6100 loss 0.03301
INFO:name:epoch 3 step 6200 loss 0.02677
INFO:name:epoch 3 step 6300 loss 0.02898
INFO:name:epoch 3 step 6400 loss 0.02779
INFO:name:epoch 3 step 6500 loss 0.02627
INFO:name:epoch 3 step 6600 loss 0.02256
INFO:name:epoch 3 step 6700 loss 0.03297
INFO:name:epoch 3 step 6800 loss 0.02366
INFO:name:epoch 3 step 6900 loss 0.02562
INFO:name:epoch 3 step 7000 loss 0.02838
INFO:name:epoch 3 step 7100 loss 0.02703
INFO:name:epoch 3 step 7200 loss 0.03387
INFO:name:epoch 3 step 7300 loss 0.03031
INFO:name:epoch 3 step 7400 loss 0.02755
INFO:name:epoch 3 step 7500 loss 0.03025
INFO:name:epoch 3 step 7600 loss 0.03259
INFO:name:epoch 3 step 7700 loss 0.02974
INFO:name:epoch 3 step 7800 loss 0.03012
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4666
INFO:name:epoch 4 step 100 loss 0.02246
INFO:name:epoch 4 step 200 loss 0.01851
INFO:name:epoch 4 step 300 loss 0.01804
INFO:name:epoch 4 step 400 loss 0.01645
INFO:name:epoch 4 step 500 loss 0.01866
INFO:name:epoch 4 step 600 loss 0.01785
INFO:name:epoch 4 step 700 loss 0.0203
INFO:name:epoch 4 step 800 loss 0.01727
INFO:name:epoch 4 step 900 loss 0.01802
INFO:name:epoch 4 step 1000 loss 0.02239
INFO:name:epoch 4 step 1100 loss 0.0217
INFO:name:epoch 4 step 1200 loss 0.01902
INFO:name:epoch 4 step 1300 loss 0.01723
INFO:name:epoch 4 step 1400 loss 0.01894
INFO:name:epoch 4 step 1500 loss 0.01864
INFO:name:epoch 4 step 1600 loss 0.0225
INFO:name:epoch 4 step 1700 loss 0.0202
INFO:name:epoch 4 step 1800 loss 0.01987
INFO:name:epoch 4 step 1900 loss 0.02422
INFO:name:epoch 4 step 2000 loss 0.01679
INFO:name:epoch 4 step 2100 loss 0.01997
INFO:name:epoch 4 step 2200 loss 0.02051
INFO:name:epoch 4 step 2300 loss 0.01954
INFO:name:epoch 4 step 2400 loss 0.02062
INFO:name:epoch 4 step 2500 loss 0.02322
INFO:name:epoch 4 step 2600 loss 0.01824
INFO:name:epoch 4 step 2700 loss 0.02464
INFO:name:epoch 4 step 2800 loss 0.01931
INFO:name:epoch 4 step 2900 loss 0.02466
INFO:name:epoch 4 step 3000 loss 0.0195
INFO:name:epoch 4 step 3100 loss 0.01867
INFO:name:epoch 4 step 3200 loss 0.018
INFO:name:epoch 4 step 3300 loss 0.02217
INFO:name:epoch 4 step 3400 loss 0.01859
INFO:name:epoch 4 step 3500 loss 0.02282
INFO:name:epoch 4 step 3600 loss 0.0222
INFO:name:epoch 4 step 3700 loss 0.02041
INFO:name:epoch 4 step 3800 loss 0.02037
INFO:name:epoch 4 step 3900 loss 0.01713
INFO:name:epoch 4 step 4000 loss 0.02018
INFO:name:epoch 4 step 4100 loss 0.02562
INFO:name:epoch 4 step 4200 loss 0.02509
INFO:name:epoch 4 step 4300 loss 0.02254
INFO:name:epoch 4 step 4400 loss 0.02164
INFO:name:epoch 4 step 4500 loss 0.02449
INFO:name:epoch 4 step 4600 loss 0.01739
INFO:name:epoch 4 step 4700 loss 0.0199
INFO:name:epoch 4 step 4800 loss 0.01606
INFO:name:epoch 4 step 4900 loss 0.0232
INFO:name:epoch 4 step 5000 loss 0.02059
INFO:name:epoch 4 step 5100 loss 0.02191
INFO:name:epoch 4 step 5200 loss 0.02492
INFO:name:epoch 4 step 5300 loss 0.0203
INFO:name:epoch 4 step 5400 loss 0.02189
INFO:name:epoch 4 step 5500 loss 0.02388
INFO:name:epoch 4 step 5600 loss 0.01651
INFO:name:epoch 4 step 5700 loss 0.02486
INFO:name:epoch 4 step 5800 loss 0.02278
INFO:name:epoch 4 step 5900 loss 0.02592
INFO:name:epoch 4 step 6000 loss 0.01898
INFO:name:epoch 4 step 6100 loss 0.01844
INFO:name:epoch 4 step 6200 loss 0.02436
INFO:name:epoch 4 step 6300 loss 0.02221
INFO:name:epoch 4 step 6400 loss 0.02024
INFO:name:epoch 4 step 6500 loss 0.02473
INFO:name:epoch 4 step 6600 loss 0.02733
INFO:name:epoch 4 step 6700 loss 0.02335
INFO:name:epoch 4 step 6800 loss 0.02877
INFO:name:epoch 4 step 6900 loss 0.02052
INFO:name:epoch 4 step 7000 loss 0.02501
INFO:name:epoch 4 step 7100 loss 0.01972
INFO:name:epoch 4 step 7200 loss 0.0226
INFO:name:epoch 4 step 7300 loss 0.02089
INFO:name:epoch 4 step 7400 loss 0.01896
INFO:name:epoch 4 step 7500 loss 0.02217
INFO:name:epoch 4 step 7600 loss 0.02255
INFO:name:epoch 4 step 7700 loss 0.02466
INFO:name:epoch 4 step 7800 loss 0.02218
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4763
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4763
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4058
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 5 step 100 loss 0.01662
INFO:name:epoch 5 step 200 loss 0.01884
INFO:name:epoch 5 step 300 loss 0.0185
INFO:name:epoch 5 step 400 loss 0.01549
INFO:name:epoch 5 step 500 loss 0.01627
INFO:name:epoch 5 step 600 loss 0.01778
INFO:name:epoch 5 step 700 loss 0.01997
INFO:name:epoch 5 step 800 loss 0.01913
INFO:name:epoch 5 step 900 loss 0.015
INFO:name:epoch 5 step 1000 loss 0.01502
INFO:name:epoch 5 step 1100 loss 0.01282
INFO:name:epoch 5 step 1200 loss 0.01456
INFO:name:epoch 5 step 1300 loss 0.01271
INFO:name:epoch 5 step 1400 loss 0.01553
INFO:name:epoch 5 step 1500 loss 0.01827
INFO:name:epoch 5 step 1600 loss 0.01988
INFO:name:epoch 5 step 1700 loss 0.02029
INFO:name:epoch 5 step 1800 loss 0.01545
INFO:name:epoch 5 step 1900 loss 0.01257
INFO:name:epoch 5 step 2000 loss 0.02208
INFO:name:epoch 5 step 2100 loss 0.01615
INFO:name:epoch 5 step 2200 loss 0.01284
INFO:name:epoch 5 step 2300 loss 0.01783
INFO:name:epoch 5 step 2400 loss 0.01832
INFO:name:epoch 5 step 2500 loss 0.01767
INFO:name:epoch 5 step 2600 loss 0.01577
INFO:name:epoch 5 step 2700 loss 0.01356
INFO:name:epoch 5 step 2800 loss 0.01432
INFO:name:epoch 5 step 2900 loss 0.01785
INFO:name:epoch 5 step 3000 loss 0.01743
INFO:name:epoch 5 step 3100 loss 0.02116
INFO:name:epoch 5 step 3200 loss 0.01609
INFO:name:epoch 5 step 3300 loss 0.01663
INFO:name:epoch 5 step 3400 loss 0.02201
INFO:name:epoch 5 step 3500 loss 0.01831
INFO:name:epoch 5 step 3600 loss 0.01976
INFO:name:epoch 5 step 3700 loss 0.01447
INFO:name:epoch 5 step 3800 loss 0.01913
INFO:name:epoch 5 step 3900 loss 0.01725
INFO:name:epoch 5 step 4000 loss 0.0158
INFO:name:epoch 5 step 4100 loss 0.0223
INFO:name:epoch 5 step 4200 loss 0.01684
INFO:name:epoch 5 step 4300 loss 0.01656
INFO:name:epoch 5 step 4400 loss 0.01732
INFO:name:epoch 5 step 4500 loss 0.01476
INFO:name:epoch 5 step 4600 loss 0.01983
INFO:name:epoch 5 step 4700 loss 0.01687
INFO:name:epoch 5 step 4800 loss 0.01803
INFO:name:epoch 5 step 4900 loss 0.0234
INFO:name:epoch 5 step 5000 loss 0.02076
INFO:name:epoch 5 step 5100 loss 0.01626
INFO:name:epoch 5 step 5200 loss 0.01619
INFO:name:epoch 5 step 5300 loss 0.01452
INFO:name:epoch 5 step 5400 loss 0.01705
INFO:name:epoch 5 step 5500 loss 0.01755
INFO:name:epoch 5 step 5600 loss 0.01535
INFO:name:epoch 5 step 5700 loss 0.02107
INFO:name:epoch 5 step 5800 loss 0.02217
INFO:name:epoch 5 step 5900 loss 0.01634
INFO:name:epoch 5 step 6000 loss 0.01642
INFO:name:epoch 5 step 6100 loss 0.01744
INFO:name:epoch 5 step 6200 loss 0.01778
INFO:name:epoch 5 step 6300 loss 0.01537
INFO:name:epoch 5 step 6400 loss 0.02089
INFO:name:epoch 5 step 6500 loss 0.02162
INFO:name:epoch 5 step 6600 loss 0.01708
INFO:name:epoch 5 step 6700 loss 0.01771
INFO:name:epoch 5 step 6800 loss 0.01617
INFO:name:epoch 5 step 6900 loss 0.01907
INFO:name:epoch 5 step 7000 loss 0.01824
INFO:name:epoch 5 step 7100 loss 0.01609
INFO:name:epoch 5 step 7200 loss 0.01768
INFO:name:epoch 5 step 7300 loss 0.0185
INFO:name:epoch 5 step 7400 loss 0.01818
INFO:name:epoch 5 step 7500 loss 0.01601
INFO:name:epoch 5 step 7600 loss 0.01567
INFO:name:epoch 5 step 7700 loss 0.01687
INFO:name:epoch 5 step 7800 loss 0.01674
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4603
INFO:name:epoch 6 step 100 loss 0.01458
INFO:name:epoch 6 step 200 loss 0.01528
INFO:name:epoch 6 step 300 loss 0.01754
INFO:name:epoch 6 step 400 loss 0.0137
INFO:name:epoch 6 step 500 loss 0.01357
INFO:name:epoch 6 step 600 loss 0.01709
INFO:name:epoch 6 step 700 loss 0.0148
INFO:name:epoch 6 step 800 loss 0.01494
INFO:name:epoch 6 step 900 loss 0.01554
INFO:name:epoch 6 step 1000 loss 0.0192
INFO:name:epoch 6 step 1100 loss 0.01172
INFO:name:epoch 6 step 1200 loss 0.0151
INFO:name:epoch 6 step 1300 loss 0.01278
INFO:name:epoch 6 step 1400 loss 0.0141
INFO:name:epoch 6 step 1500 loss 0.01491
INFO:name:epoch 6 step 1600 loss 0.01277
INFO:name:epoch 6 step 1700 loss 0.01187
INFO:name:epoch 6 step 1800 loss 0.01326
INFO:name:epoch 6 step 1900 loss 0.01728
INFO:name:epoch 6 step 2000 loss 0.01279
INFO:name:epoch 6 step 2100 loss 0.01713
INFO:name:epoch 6 step 2200 loss 0.01216
INFO:name:epoch 6 step 2300 loss 0.014
INFO:name:epoch 6 step 2400 loss 0.01566
INFO:name:epoch 6 step 2500 loss 0.0161
INFO:name:epoch 6 step 2600 loss 0.01317
INFO:name:epoch 6 step 2700 loss 0.01435
INFO:name:epoch 6 step 2800 loss 0.01719
INFO:name:epoch 6 step 2900 loss 0.01275
INFO:name:epoch 6 step 3000 loss 0.01231
INFO:name:epoch 6 step 3100 loss 0.01384
INFO:name:epoch 6 step 3200 loss 0.01508
INFO:name:epoch 6 step 3300 loss 0.01599
INFO:name:epoch 6 step 3400 loss 0.01764
INFO:name:epoch 6 step 3500 loss 0.01539
INFO:name:epoch 6 step 3600 loss 0.01382
INFO:name:epoch 6 step 3700 loss 0.01317
INFO:name:epoch 6 step 3800 loss 0.01586
INFO:name:epoch 6 step 3900 loss 0.01333
INFO:name:epoch 6 step 4000 loss 0.01548
INFO:name:epoch 6 step 4100 loss 0.01922
INFO:name:epoch 6 step 4200 loss 0.01717
INFO:name:epoch 6 step 4300 loss 0.01359
INFO:name:epoch 6 step 4400 loss 0.01519
INFO:name:epoch 6 step 4500 loss 0.01647
INFO:name:epoch 6 step 4600 loss 0.01609
INFO:name:epoch 6 step 4700 loss 0.01416
INFO:name:epoch 6 step 4800 loss 0.01313
INFO:name:epoch 6 step 4900 loss 0.01692
INFO:name:epoch 6 step 5000 loss 0.0168
INFO:name:epoch 6 step 5100 loss 0.01695
INFO:name:epoch 6 step 5200 loss 0.01054
INFO:name:epoch 6 step 5300 loss 0.01363
INFO:name:epoch 6 step 5400 loss 0.01199
INFO:name:epoch 6 step 5500 loss 0.0186
INFO:name:epoch 6 step 5600 loss 0.01461
INFO:name:epoch 6 step 5700 loss 0.01654
INFO:name:epoch 6 step 5800 loss 0.01312
INFO:name:epoch 6 step 5900 loss 0.0129
INFO:name:epoch 6 step 6000 loss 0.02044
INFO:name:epoch 6 step 6100 loss 0.01354
INFO:name:epoch 6 step 6200 loss 0.01695
INFO:name:epoch 6 step 6300 loss 0.01736
INFO:name:epoch 6 step 6400 loss 0.01361
INFO:name:epoch 6 step 6500 loss 0.01345
INFO:name:epoch 6 step 6600 loss 0.01322
INFO:name:epoch 6 step 6700 loss 0.01487
INFO:name:epoch 6 step 6800 loss 0.0155
INFO:name:epoch 6 step 6900 loss 0.01603
INFO:name:epoch 6 step 7000 loss 0.01726
INFO:name:epoch 6 step 7100 loss 0.0141
INFO:name:epoch 6 step 7200 loss 0.01653
INFO:name:epoch 6 step 7300 loss 0.01717
INFO:name:epoch 6 step 7400 loss 0.0138
INFO:name:epoch 6 step 7500 loss 0.01575
INFO:name:epoch 6 step 7600 loss 0.01265
INFO:name:epoch 6 step 7700 loss 0.01605
INFO:name:epoch 6 step 7800 loss 0.01721
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.458
INFO:name:epoch 7 step 100 loss 0.01347
INFO:name:epoch 7 step 200 loss 0.01398
INFO:name:epoch 7 step 300 loss 0.01143
INFO:name:epoch 7 step 400 loss 0.01216
INFO:name:epoch 7 step 500 loss 0.01495
INFO:name:epoch 7 step 600 loss 0.01166
INFO:name:epoch 7 step 700 loss 0.01406
INFO:name:epoch 7 step 800 loss 0.0144
INFO:name:epoch 7 step 900 loss 0.01331
INFO:name:epoch 7 step 1000 loss 0.01214
INFO:name:epoch 7 step 1100 loss 0.01395
INFO:name:epoch 7 step 1200 loss 0.01201
INFO:name:epoch 7 step 1300 loss 0.01236
INFO:name:epoch 7 step 1400 loss 0.01387
INFO:name:epoch 7 step 1500 loss 0.00915
INFO:name:epoch 7 step 1600 loss 0.00997
INFO:name:epoch 7 step 1700 loss 0.01367
INFO:name:epoch 7 step 1800 loss 0.01768
INFO:name:epoch 7 step 1900 loss 0.01223
INFO:name:epoch 7 step 2000 loss 0.01311
INFO:name:epoch 7 step 2100 loss 0.01214
INFO:name:epoch 7 step 2200 loss 0.01662
INFO:name:epoch 7 step 2300 loss 0.01604
INFO:name:epoch 7 step 2400 loss 0.01213
INFO:name:epoch 7 step 2500 loss 0.01339
INFO:name:epoch 7 step 2600 loss 0.01424
INFO:name:epoch 7 step 2700 loss 0.01276
INFO:name:epoch 7 step 2800 loss 0.01091
INFO:name:epoch 7 step 2900 loss 0.01399
INFO:name:epoch 7 step 3000 loss 0.01194
INFO:name:epoch 7 step 3100 loss 0.01315
INFO:name:epoch 7 step 3200 loss 0.01112
INFO:name:epoch 7 step 3300 loss 0.01368
INFO:name:epoch 7 step 3400 loss 0.01357
INFO:name:epoch 7 step 3500 loss 0.0141
INFO:name:epoch 7 step 3600 loss 0.01231
INFO:name:epoch 7 step 3700 loss 0.01468
INFO:name:epoch 7 step 3800 loss 0.01403
INFO:name:epoch 7 step 3900 loss 0.01224
INFO:name:epoch 7 step 4000 loss 0.01458
INFO:name:epoch 7 step 4100 loss 0.01376
INFO:name:epoch 7 step 4200 loss 0.01463
INFO:name:epoch 7 step 4300 loss 0.01386
INFO:name:epoch 7 step 4400 loss 0.01292
INFO:name:epoch 7 step 4500 loss 0.01121
INFO:name:epoch 7 step 4600 loss 0.01247
INFO:name:epoch 7 step 4700 loss 0.01225
INFO:name:epoch 7 step 4800 loss 0.013
INFO:name:epoch 7 step 4900 loss 0.01279
INFO:name:epoch 7 step 5000 loss 0.01459
INFO:name:epoch 7 step 5100 loss 0.01428
INFO:name:epoch 7 step 5200 loss 0.01115
INFO:name:epoch 7 step 5300 loss 0.01447
INFO:name:epoch 7 step 5400 loss 0.01289
INFO:name:epoch 7 step 5500 loss 0.01378
INFO:name:epoch 7 step 5600 loss 0.01092
INFO:name:epoch 7 step 5700 loss 0.01237
INFO:name:epoch 7 step 5800 loss 0.01102
INFO:name:epoch 7 step 5900 loss 0.013
INFO:name:epoch 7 step 6000 loss 0.01312
INFO:name:epoch 7 step 6100 loss 0.01185
INFO:name:epoch 7 step 6200 loss 0.0151
INFO:name:epoch 7 step 6300 loss 0.01451
INFO:name:epoch 7 step 6400 loss 0.01151
INFO:name:epoch 7 step 6500 loss 0.01118
INFO:name:epoch 7 step 6600 loss 0.01263
INFO:name:epoch 7 step 6700 loss 0.01759
INFO:name:epoch 7 step 6800 loss 0.01161
INFO:name:epoch 7 step 6900 loss 0.01855
INFO:name:epoch 7 step 7000 loss 0.01301
INFO:name:epoch 7 step 7100 loss 0.01184
INFO:name:epoch 7 step 7200 loss 0.01329
INFO:name:epoch 7 step 7300 loss 0.01128
INFO:name:epoch 7 step 7400 loss 0.01323
INFO:name:epoch 7 step 7500 loss 0.01213
INFO:name:epoch 7 step 7600 loss 0.01326
INFO:name:epoch 7 step 7700 loss 0.01558
INFO:name:epoch 7 step 7800 loss 0.01148
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4629
INFO:name:epoch 8 step 100 loss 0.0124
INFO:name:epoch 8 step 200 loss 0.01273
INFO:name:epoch 8 step 300 loss 0.01133
INFO:name:epoch 8 step 400 loss 0.01021
INFO:name:epoch 8 step 500 loss 0.01255
INFO:name:epoch 8 step 600 loss 0.01388
INFO:name:epoch 8 step 700 loss 0.01331
INFO:name:epoch 8 step 800 loss 0.01493
INFO:name:epoch 8 step 900 loss 0.01233
INFO:name:epoch 8 step 1000 loss 0.01153
INFO:name:epoch 8 step 1100 loss 0.01251
INFO:name:epoch 8 step 1200 loss 0.01201
INFO:name:epoch 8 step 1300 loss 0.0104
INFO:name:epoch 8 step 1400 loss 0.01038
INFO:name:epoch 8 step 1500 loss 0.01333
INFO:name:epoch 8 step 1600 loss 0.01215
INFO:name:epoch 8 step 1700 loss 0.01012
INFO:name:epoch 8 step 1800 loss 0.0118
INFO:name:epoch 8 step 1900 loss 0.0091
INFO:name:epoch 8 step 2000 loss 0.01231
INFO:name:epoch 8 step 2100 loss 0.00927
INFO:name:epoch 8 step 2200 loss 0.01326
INFO:name:epoch 8 step 2300 loss 0.01568
INFO:name:epoch 8 step 2400 loss 0.0118
INFO:name:epoch 8 step 2500 loss 0.01064
INFO:name:epoch 8 step 2600 loss 0.01299
INFO:name:epoch 8 step 2700 loss 0.01176
INFO:name:epoch 8 step 2800 loss 0.01162
INFO:name:epoch 8 step 2900 loss 0.01213
INFO:name:epoch 8 step 3000 loss 0.00877
INFO:name:epoch 8 step 3100 loss 0.01322
INFO:name:epoch 8 step 3200 loss 0.01189
INFO:name:epoch 8 step 3300 loss 0.01138
INFO:name:epoch 8 step 3400 loss 0.0115
INFO:name:epoch 8 step 3500 loss 0.01099
INFO:name:epoch 8 step 3600 loss 0.01178
INFO:name:epoch 8 step 3700 loss 0.00982
INFO:name:epoch 8 step 3800 loss 0.01244
INFO:name:epoch 8 step 3900 loss 0.01194
INFO:name:epoch 8 step 4000 loss 0.01296
INFO:name:epoch 8 step 4100 loss 0.01154
INFO:name:epoch 8 step 4200 loss 0.01337
INFO:name:epoch 8 step 4300 loss 0.0108
INFO:name:epoch 8 step 4400 loss 0.00955
INFO:name:epoch 8 step 4500 loss 0.01089
INFO:name:epoch 8 step 4600 loss 0.01392
INFO:name:epoch 8 step 4700 loss 0.01034
INFO:name:epoch 8 step 4800 loss 0.01131
INFO:name:epoch 8 step 4900 loss 0.01069
INFO:name:epoch 8 step 5000 loss 0.01276
INFO:name:epoch 8 step 5100 loss 0.01589
INFO:name:epoch 8 step 5200 loss 0.0114
INFO:name:epoch 8 step 5300 loss 0.01482
INFO:name:epoch 8 step 5400 loss 0.01057
INFO:name:epoch 8 step 5500 loss 0.01413
INFO:name:epoch 8 step 5600 loss 0.01146
INFO:name:epoch 8 step 5700 loss 0.01319
INFO:name:epoch 8 step 5800 loss 0.01528
INFO:name:epoch 8 step 5900 loss 0.01117
INFO:name:epoch 8 step 6000 loss 0.01036
INFO:name:epoch 8 step 6100 loss 0.01869
INFO:name:epoch 8 step 6200 loss 0.01047
INFO:name:epoch 8 step 6300 loss 0.0137
INFO:name:epoch 8 step 6400 loss 0.01118
INFO:name:epoch 8 step 6500 loss 0.01133
INFO:name:epoch 8 step 6600 loss 0.01256
INFO:name:epoch 8 step 6700 loss 0.00962
INFO:name:epoch 8 step 6800 loss 0.01298
INFO:name:epoch 8 step 6900 loss 0.0116
INFO:name:epoch 8 step 7000 loss 0.00993
INFO:name:epoch 8 step 7100 loss 0.0108
INFO:name:epoch 8 step 7200 loss 0.01055
INFO:name:epoch 8 step 7300 loss 0.01401
INFO:name:epoch 8 step 7400 loss 0.01125
INFO:name:epoch 8 step 7500 loss 0.01313
INFO:name:epoch 8 step 7600 loss 0.01206
INFO:name:epoch 8 step 7700 loss 0.01098
INFO:name:epoch 8 step 7800 loss 0.01099
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4524
INFO:name:epoch 9 step 100 loss 0.01007
INFO:name:epoch 9 step 200 loss 0.01246
INFO:name:epoch 9 step 300 loss 0.0082
INFO:name:epoch 9 step 400 loss 0.01142
INFO:name:epoch 9 step 500 loss 0.01122
INFO:name:epoch 9 step 600 loss 0.01
INFO:name:epoch 9 step 700 loss 0.00985
INFO:name:epoch 9 step 800 loss 0.00997
INFO:name:epoch 9 step 900 loss 0.01169
INFO:name:epoch 9 step 1000 loss 0.00934
INFO:name:epoch 9 step 1100 loss 0.01259
INFO:name:epoch 9 step 1200 loss 0.01094
INFO:name:epoch 9 step 1300 loss 0.00987
INFO:name:epoch 9 step 1400 loss 0.01376
INFO:name:epoch 9 step 1500 loss 0.0103
INFO:name:epoch 9 step 1600 loss 0.01241
INFO:name:epoch 9 step 1700 loss 0.00923
INFO:name:epoch 9 step 1800 loss 0.0099
INFO:name:epoch 9 step 1900 loss 0.0094
INFO:name:epoch 9 step 2000 loss 0.01157
INFO:name:epoch 9 step 2100 loss 0.01454
INFO:name:epoch 9 step 2200 loss 0.01297
INFO:name:epoch 9 step 2300 loss 0.0099
INFO:name:epoch 9 step 2400 loss 0.00987
INFO:name:epoch 9 step 2500 loss 0.0099
INFO:name:epoch 9 step 2600 loss 0.01291
INFO:name:epoch 9 step 2700 loss 0.01103
INFO:name:epoch 9 step 2800 loss 0.00801
INFO:name:epoch 9 step 2900 loss 0.01117
INFO:name:epoch 9 step 3000 loss 0.01137
INFO:name:epoch 9 step 3100 loss 0.01171
INFO:name:epoch 9 step 3200 loss 0.0089
INFO:name:epoch 9 step 3300 loss 0.01154
INFO:name:epoch 9 step 3400 loss 0.00987
INFO:name:epoch 9 step 3500 loss 0.01239
INFO:name:epoch 9 step 3600 loss 0.01224
INFO:name:epoch 9 step 3700 loss 0.01265
INFO:name:epoch 9 step 3800 loss 0.00945
INFO:name:epoch 9 step 3900 loss 0.00919
INFO:name:epoch 9 step 4000 loss 0.00981
INFO:name:epoch 9 step 4100 loss 0.01223
INFO:name:epoch 9 step 4200 loss 0.01372
INFO:name:epoch 9 step 4300 loss 0.00932
INFO:name:epoch 9 step 4400 loss 0.01183
INFO:name:epoch 9 step 4500 loss 0.0143
INFO:name:epoch 9 step 4600 loss 0.0085
INFO:name:epoch 9 step 4700 loss 0.01101
INFO:name:epoch 9 step 4800 loss 0.00927
INFO:name:epoch 9 step 4900 loss 0.01171
INFO:name:epoch 9 step 5000 loss 0.01253
INFO:name:epoch 9 step 5100 loss 0.00999
INFO:name:epoch 9 step 5200 loss 0.00889
INFO:name:epoch 9 step 5300 loss 0.00832
INFO:name:epoch 9 step 5400 loss 0.01134
INFO:name:epoch 9 step 5500 loss 0.01165
INFO:name:epoch 9 step 5600 loss 0.01185
INFO:name:epoch 9 step 5700 loss 0.00974
INFO:name:epoch 9 step 5800 loss 0.01007
INFO:name:epoch 9 step 5900 loss 0.01114
INFO:name:epoch 9 step 6000 loss 0.00989
INFO:name:epoch 9 step 6100 loss 0.00941
INFO:name:epoch 9 step 6200 loss 0.01001
INFO:name:epoch 9 step 6300 loss 0.00939
INFO:name:epoch 9 step 6400 loss 0.01124
INFO:name:epoch 9 step 6500 loss 0.01145
INFO:name:epoch 9 step 6600 loss 0.00996
INFO:name:epoch 9 step 6700 loss 0.01066
INFO:name:epoch 9 step 6800 loss 0.00842
INFO:name:epoch 9 step 6900 loss 0.01242
INFO:name:epoch 9 step 7000 loss 0.01115
INFO:name:epoch 9 step 7100 loss 0.00956
INFO:name:epoch 9 step 7200 loss 0.01012
INFO:name:epoch 9 step 7300 loss 0.00829
INFO:name:epoch 9 step 7400 loss 0.0108
INFO:name:epoch 9 step 7500 loss 0.00983
INFO:name:epoch 9 step 7600 loss 0.01089
INFO:name:epoch 9 step 7700 loss 0.0127
INFO:name:epoch 9 step 7800 loss 0.01235
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4548
INFO:name:epoch 10 step 100 loss 0.01044
INFO:name:epoch 10 step 200 loss 0.01073
INFO:name:epoch 10 step 300 loss 0.00909
INFO:name:epoch 10 step 400 loss 0.00843
INFO:name:epoch 10 step 500 loss 0.00754
INFO:name:epoch 10 step 600 loss 0.00775
INFO:name:epoch 10 step 700 loss 0.01081
INFO:name:epoch 10 step 800 loss 0.00926
INFO:name:epoch 10 step 900 loss 0.00827
INFO:name:epoch 10 step 1000 loss 0.00874
INFO:name:epoch 10 step 1100 loss 0.00902
INFO:name:epoch 10 step 1200 loss 0.00811
INFO:name:epoch 10 step 1300 loss 0.00862
INFO:name:epoch 10 step 1400 loss 0.00847
INFO:name:epoch 10 step 1500 loss 0.00983
INFO:name:epoch 10 step 1600 loss 0.00926
INFO:name:epoch 10 step 1700 loss 0.01099
INFO:name:epoch 10 step 1800 loss 0.01028
INFO:name:epoch 10 step 1900 loss 0.00775
INFO:name:epoch 10 step 2000 loss 0.01033
INFO:name:epoch 10 step 2100 loss 0.00983
INFO:name:epoch 10 step 2200 loss 0.00883
INFO:name:epoch 10 step 2300 loss 0.0103
INFO:name:epoch 10 step 2400 loss 0.00946
INFO:name:epoch 10 step 2500 loss 0.01036
INFO:name:epoch 10 step 2600 loss 0.00845
INFO:name:epoch 10 step 2700 loss 0.01014
INFO:name:epoch 10 step 2800 loss 0.01113
INFO:name:epoch 10 step 2900 loss 0.0085
INFO:name:epoch 10 step 3000 loss 0.00771
INFO:name:epoch 10 step 3100 loss 0.00763
INFO:name:epoch 10 step 3200 loss 0.00819
INFO:name:epoch 10 step 3300 loss 0.01082
INFO:name:epoch 10 step 3400 loss 0.01137
INFO:name:epoch 10 step 3500 loss 0.01024
INFO:name:epoch 10 step 3600 loss 0.01148
INFO:name:epoch 10 step 3700 loss 0.00835
INFO:name:epoch 10 step 3800 loss 0.0094
INFO:name:epoch 10 step 3900 loss 0.01
INFO:name:epoch 10 step 4000 loss 0.01137
INFO:name:epoch 10 step 4100 loss 0.01006
INFO:name:epoch 10 step 4200 loss 0.00647
INFO:name:epoch 10 step 4300 loss 0.00914
INFO:name:epoch 10 step 4400 loss 0.00969
INFO:name:epoch 10 step 4500 loss 0.00993
INFO:name:epoch 10 step 4600 loss 0.0077
INFO:name:epoch 10 step 4700 loss 0.00919
INFO:name:epoch 10 step 4800 loss 0.01223
INFO:name:epoch 10 step 4900 loss 0.0114
INFO:name:epoch 10 step 5000 loss 0.00735
INFO:name:epoch 10 step 5100 loss 0.01086
INFO:name:epoch 10 step 5200 loss 0.00875
INFO:name:epoch 10 step 5300 loss 0.00892
INFO:name:epoch 10 step 5400 loss 0.01043
INFO:name:epoch 10 step 5500 loss 0.00869
INFO:name:epoch 10 step 5600 loss 0.01156
INFO:name:epoch 10 step 5700 loss 0.00999
INFO:name:epoch 10 step 5800 loss 0.00877
INFO:name:epoch 10 step 5900 loss 0.01092
INFO:name:epoch 10 step 6000 loss 0.00807
INFO:name:epoch 10 step 6100 loss 0.01004
INFO:name:epoch 10 step 6200 loss 0.00887
INFO:name:epoch 10 step 6300 loss 0.00938
INFO:name:epoch 10 step 6400 loss 0.0089
INFO:name:epoch 10 step 6500 loss 0.01062
INFO:name:epoch 10 step 6600 loss 0.00952
INFO:name:epoch 10 step 6700 loss 0.0084
INFO:name:epoch 10 step 6800 loss 0.009
INFO:name:epoch 10 step 6900 loss 0.01052
INFO:name:epoch 10 step 7000 loss 0.00802
INFO:name:epoch 10 step 7100 loss 0.00962
INFO:name:epoch 10 step 7200 loss 0.0105
INFO:name:epoch 10 step 7300 loss 0.01056
INFO:name:epoch 10 step 7400 loss 0.01137
INFO:name:epoch 10 step 7500 loss 0.01054
INFO:name:epoch 10 step 7600 loss 0.00879
INFO:name:epoch 10 step 7700 loss 0.00845
INFO:name:epoch 10 step 7800 loss 0.0075
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4611
INFO:name:epoch 11 step 100 loss 0.00863
INFO:name:epoch 11 step 200 loss 0.00662
INFO:name:epoch 11 step 300 loss 0.00954
INFO:name:epoch 11 step 400 loss 0.00902
INFO:name:epoch 11 step 500 loss 0.01067
INFO:name:epoch 11 step 600 loss 0.01067
INFO:name:epoch 11 step 700 loss 0.00943
INFO:name:epoch 11 step 800 loss 0.00888
INFO:name:epoch 11 step 900 loss 0.01194
INFO:name:epoch 11 step 1000 loss 0.00827
INFO:name:epoch 11 step 1100 loss 0.00686
INFO:name:epoch 11 step 1200 loss 0.00973
INFO:name:epoch 11 step 1300 loss 0.01066
INFO:name:epoch 11 step 1400 loss 0.00813
INFO:name:epoch 11 step 1500 loss 0.00975
INFO:name:epoch 11 step 1600 loss 0.00747
INFO:name:epoch 11 step 1700 loss 0.00962
INFO:name:epoch 11 step 1800 loss 0.0066
INFO:name:epoch 11 step 1900 loss 0.00716
INFO:name:epoch 11 step 2000 loss 0.00693
INFO:name:epoch 11 step 2100 loss 0.00959
INFO:name:epoch 11 step 2200 loss 0.00963
INFO:name:epoch 11 step 2300 loss 0.00663
INFO:name:epoch 11 step 2400 loss 0.01402
INFO:name:epoch 11 step 2500 loss 0.00972
INFO:name:epoch 11 step 2600 loss 0.00698
INFO:name:epoch 11 step 2700 loss 0.00857
INFO:name:epoch 11 step 2800 loss 0.00895
INFO:name:epoch 11 step 2900 loss 0.00925
INFO:name:epoch 11 step 3000 loss 0.00908
INFO:name:epoch 11 step 3100 loss 0.00856
INFO:name:epoch 11 step 3200 loss 0.00854
INFO:name:epoch 11 step 3300 loss 0.01048
INFO:name:epoch 11 step 3400 loss 0.00883
INFO:name:epoch 11 step 3500 loss 0.00853
INFO:name:epoch 11 step 3600 loss 0.00844
INFO:name:epoch 11 step 3700 loss 0.00746
INFO:name:epoch 11 step 3800 loss 0.00707
INFO:name:epoch 11 step 3900 loss 0.01141
INFO:name:epoch 11 step 4000 loss 0.00826
INFO:name:epoch 11 step 4100 loss 0.00907
INFO:name:epoch 11 step 4200 loss 0.00833
INFO:name:epoch 11 step 4300 loss 0.00894
INFO:name:epoch 11 step 4400 loss 0.00771
INFO:name:epoch 11 step 4500 loss 0.00743
INFO:name:epoch 11 step 4600 loss 0.01008
INFO:name:epoch 11 step 4700 loss 0.01029
INFO:name:epoch 11 step 4800 loss 0.00894
INFO:name:epoch 11 step 4900 loss 0.0103
INFO:name:epoch 11 step 5000 loss 0.00755
INFO:name:epoch 11 step 5100 loss 0.00776
INFO:name:epoch 11 step 5200 loss 0.00729
INFO:name:epoch 11 step 5300 loss 0.00899
INFO:name:epoch 11 step 5400 loss 0.00856
INFO:name:epoch 11 step 5500 loss 0.0087
INFO:name:epoch 11 step 5600 loss 0.0073
INFO:name:epoch 11 step 5700 loss 0.01097
INFO:name:epoch 11 step 5800 loss 0.00767
INFO:name:epoch 11 step 5900 loss 0.01097
INFO:name:epoch 11 step 6000 loss 0.00876
INFO:name:epoch 11 step 6100 loss 0.0083
INFO:name:epoch 11 step 6200 loss 0.00895
INFO:name:epoch 11 step 6300 loss 0.00934
INFO:name:epoch 11 step 6400 loss 0.00901
INFO:name:epoch 11 step 6500 loss 0.0081
INFO:name:epoch 11 step 6600 loss 0.00772
INFO:name:epoch 11 step 6700 loss 0.0108
INFO:name:epoch 11 step 6800 loss 0.01054
INFO:name:epoch 11 step 6900 loss 0.01018
INFO:name:epoch 11 step 7000 loss 0.01048
INFO:name:epoch 11 step 7100 loss 0.00898
INFO:name:epoch 11 step 7200 loss 0.01158
INFO:name:epoch 11 step 7300 loss 0.00859
INFO:name:epoch 11 step 7400 loss 0.00835
INFO:name:epoch 11 step 7500 loss 0.01235
INFO:name:epoch 11 step 7600 loss 0.00811
INFO:name:epoch 11 step 7700 loss 0.0092
INFO:name:epoch 11 step 7800 loss 0.0111
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4656
INFO:name:epoch 12 step 100 loss 0.00966
INFO:name:epoch 12 step 200 loss 0.00714
INFO:name:epoch 12 step 300 loss 0.00843
INFO:name:epoch 12 step 400 loss 0.00792
INFO:name:epoch 12 step 500 loss 0.00951
INFO:name:epoch 12 step 600 loss 0.00811
INFO:name:epoch 12 step 700 loss 0.00928
INFO:name:epoch 12 step 800 loss 0.00927
INFO:name:epoch 12 step 900 loss 0.00809
INFO:name:epoch 12 step 1000 loss 0.00928
INFO:name:epoch 12 step 1100 loss 0.01026
INFO:name:epoch 12 step 1200 loss 0.00973
INFO:name:epoch 12 step 1300 loss 0.0089
INFO:name:epoch 12 step 1400 loss 0.00692
INFO:name:epoch 12 step 1500 loss 0.00784
INFO:name:epoch 12 step 1600 loss 0.00759
INFO:name:epoch 12 step 1700 loss 0.00829
INFO:name:epoch 12 step 1800 loss 0.00565
INFO:name:epoch 12 step 1900 loss 0.0083
INFO:name:epoch 12 step 2000 loss 0.0088
INFO:name:epoch 12 step 2100 loss 0.00729
INFO:name:epoch 12 step 2200 loss 0.00934
INFO:name:epoch 12 step 2300 loss 0.00678
INFO:name:epoch 12 step 2400 loss 0.01038
INFO:name:epoch 12 step 2500 loss 0.00968
INFO:name:epoch 12 step 2600 loss 0.00865
INFO:name:epoch 12 step 2700 loss 0.01075
INFO:name:epoch 12 step 2800 loss 0.00792
INFO:name:epoch 12 step 2900 loss 0.00804
INFO:name:epoch 12 step 3000 loss 0.00812
INFO:name:epoch 12 step 3100 loss 0.00837
INFO:name:epoch 12 step 3200 loss 0.00872
INFO:name:epoch 12 step 3300 loss 0.00665
INFO:name:epoch 12 step 3400 loss 0.00887
INFO:name:epoch 12 step 3500 loss 0.00922
INFO:name:epoch 12 step 3600 loss 0.0091
INFO:name:epoch 12 step 3700 loss 0.01107
INFO:name:epoch 12 step 3800 loss 0.0099
INFO:name:epoch 12 step 3900 loss 0.00718
INFO:name:epoch 12 step 4000 loss 0.01058
INFO:name:epoch 12 step 4100 loss 0.00706
INFO:name:epoch 12 step 4200 loss 0.0078
INFO:name:epoch 12 step 4300 loss 0.00725
INFO:name:epoch 12 step 4400 loss 0.0101
INFO:name:epoch 12 step 4500 loss 0.0069
INFO:name:epoch 12 step 4600 loss 0.00681
INFO:name:epoch 12 step 4700 loss 0.00869
INFO:name:epoch 12 step 4800 loss 0.01
INFO:name:epoch 12 step 4900 loss 0.00765
INFO:name:epoch 12 step 5000 loss 0.00796
INFO:name:epoch 12 step 5100 loss 0.0098
INFO:name:epoch 12 step 5200 loss 0.00883
INFO:name:epoch 12 step 5300 loss 0.00817
INFO:name:epoch 12 step 5400 loss 0.00813
INFO:name:epoch 12 step 5500 loss 0.00697
INFO:name:epoch 12 step 5600 loss 0.00923
INFO:name:epoch 12 step 5700 loss 0.00613
INFO:name:epoch 12 step 5800 loss 0.00815
INFO:name:epoch 12 step 5900 loss 0.0072
INFO:name:epoch 12 step 6000 loss 0.01004
INFO:name:epoch 12 step 6100 loss 0.00889
INFO:name:epoch 12 step 6200 loss 0.00914
INFO:name:epoch 12 step 6300 loss 0.00743
INFO:name:epoch 12 step 6400 loss 0.0085
INFO:name:epoch 12 step 6500 loss 0.01021
INFO:name:epoch 12 step 6600 loss 0.00891
INFO:name:epoch 12 step 6700 loss 0.00779
INFO:name:epoch 12 step 6800 loss 0.00886
INFO:name:epoch 12 step 6900 loss 0.00804
INFO:name:epoch 12 step 7000 loss 0.00877
INFO:name:epoch 12 step 7100 loss 0.0083
INFO:name:epoch 12 step 7200 loss 0.00679
INFO:name:epoch 12 step 7300 loss 0.00832
INFO:name:epoch 12 step 7400 loss 0.00819
INFO:name:epoch 12 step 7500 loss 0.00761
INFO:name:epoch 12 step 7600 loss 0.00917
INFO:name:epoch 12 step 7700 loss 0.00623
INFO:name:epoch 12 step 7800 loss 0.00934
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4565
INFO:name:epoch 13 step 100 loss 0.00727
INFO:name:epoch 13 step 200 loss 0.00708
INFO:name:epoch 13 step 300 loss 0.0067
INFO:name:epoch 13 step 400 loss 0.01053
INFO:name:epoch 13 step 500 loss 0.00807
INFO:name:epoch 13 step 600 loss 0.00869
INFO:name:epoch 13 step 700 loss 0.00913
INFO:name:epoch 13 step 800 loss 0.00887
INFO:name:epoch 13 step 900 loss 0.00881
INFO:name:epoch 13 step 1000 loss 0.00809
INFO:name:epoch 13 step 1100 loss 0.00766
INFO:name:epoch 13 step 1200 loss 0.00659
INFO:name:epoch 13 step 1300 loss 0.00826
INFO:name:epoch 13 step 1400 loss 0.00713
INFO:name:epoch 13 step 1500 loss 0.00775
INFO:name:epoch 13 step 1600 loss 0.00808
INFO:name:epoch 13 step 1700 loss 0.0058
INFO:name:epoch 13 step 1800 loss 0.00656
INFO:name:epoch 13 step 1900 loss 0.00945
INFO:name:epoch 13 step 2000 loss 0.01001
INFO:name:epoch 13 step 2100 loss 0.00757
INFO:name:epoch 13 step 2200 loss 0.00608
INFO:name:epoch 13 step 2300 loss 0.00659
INFO:name:epoch 13 step 2400 loss 0.00737
INFO:name:epoch 13 step 2500 loss 0.00688
INFO:name:epoch 13 step 2600 loss 0.00789
INFO:name:epoch 13 step 2700 loss 0.00878
INFO:name:epoch 13 step 2800 loss 0.00782
INFO:name:epoch 13 step 2900 loss 0.00712
INFO:name:epoch 13 step 3000 loss 0.00894
INFO:name:epoch 13 step 3100 loss 0.00704
INFO:name:epoch 13 step 3200 loss 0.00604
INFO:name:epoch 13 step 3300 loss 0.00723
INFO:name:epoch 13 step 3400 loss 0.00838
INFO:name:epoch 13 step 3500 loss 0.01007
INFO:name:epoch 13 step 3600 loss 0.00832
INFO:name:epoch 13 step 3700 loss 0.00788
INFO:name:epoch 13 step 3800 loss 0.00816
INFO:name:epoch 13 step 3900 loss 0.00867
INFO:name:epoch 13 step 4000 loss 0.00693
INFO:name:epoch 13 step 4100 loss 0.00764
INFO:name:epoch 13 step 4200 loss 0.00718
INFO:name:epoch 13 step 4300 loss 0.00866
INFO:name:epoch 13 step 4400 loss 0.00871
INFO:name:epoch 13 step 4500 loss 0.0086
INFO:name:epoch 13 step 4600 loss 0.00809
INFO:name:epoch 13 step 4700 loss 0.01063
INFO:name:epoch 13 step 4800 loss 0.00772
INFO:name:epoch 13 step 4900 loss 0.00866
INFO:name:epoch 13 step 5000 loss 0.01061
INFO:name:epoch 13 step 5100 loss 0.00818
INFO:name:epoch 13 step 5200 loss 0.00572
INFO:name:epoch 13 step 5300 loss 0.01009
INFO:name:epoch 13 step 5400 loss 0.00773
INFO:name:epoch 13 step 5500 loss 0.00951
INFO:name:epoch 13 step 5600 loss 0.00781
INFO:name:epoch 13 step 5700 loss 0.01021
INFO:name:epoch 13 step 5800 loss 0.00887
INFO:name:epoch 13 step 5900 loss 0.00901
INFO:name:epoch 13 step 6000 loss 0.00833
INFO:name:epoch 13 step 6100 loss 0.00871
INFO:name:epoch 13 step 6200 loss 0.008
INFO:name:epoch 13 step 6300 loss 0.00797
INFO:name:epoch 13 step 6400 loss 0.00765
INFO:name:epoch 13 step 6500 loss 0.0068
INFO:name:epoch 13 step 6600 loss 0.0088
INFO:name:epoch 13 step 6700 loss 0.0075
INFO:name:epoch 13 step 6800 loss 0.00622
INFO:name:epoch 13 step 6900 loss 0.00948
INFO:name:epoch 13 step 7000 loss 0.00893
INFO:name:epoch 13 step 7100 loss 0.00766
INFO:name:epoch 13 step 7200 loss 0.00747
INFO:name:epoch 13 step 7300 loss 0.00955
INFO:name:epoch 13 step 7400 loss 0.00657
INFO:name:epoch 13 step 7500 loss 0.00931
INFO:name:epoch 13 step 7600 loss 0.00699
INFO:name:epoch 13 step 7700 loss 0.00791
INFO:name:epoch 13 step 7800 loss 0.0079
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4545
INFO:name:epoch 14 step 100 loss 0.00727
INFO:name:epoch 14 step 200 loss 0.00846
INFO:name:epoch 14 step 300 loss 0.00517
INFO:name:epoch 14 step 400 loss 0.00891
INFO:name:epoch 14 step 500 loss 0.00759
INFO:name:epoch 14 step 600 loss 0.00766
INFO:name:epoch 14 step 700 loss 0.00667
INFO:name:epoch 14 step 800 loss 0.00762
INFO:name:epoch 14 step 900 loss 0.00775
INFO:name:epoch 14 step 1000 loss 0.00736
INFO:name:epoch 14 step 1100 loss 0.00822
INFO:name:epoch 14 step 1200 loss 0.00836
INFO:name:epoch 14 step 1300 loss 0.00893
INFO:name:epoch 14 step 1400 loss 0.00705
INFO:name:epoch 14 step 1500 loss 0.00702
INFO:name:epoch 14 step 1600 loss 0.00887
INFO:name:epoch 14 step 1700 loss 0.00581
INFO:name:epoch 14 step 1800 loss 0.00809
INFO:name:epoch 14 step 1900 loss 0.00953
INFO:name:epoch 14 step 2000 loss 0.00723
INFO:name:epoch 14 step 2100 loss 0.00717
INFO:name:epoch 14 step 2200 loss 0.0067
INFO:name:epoch 14 step 2300 loss 0.00675
INFO:name:epoch 14 step 2400 loss 0.00797
INFO:name:epoch 14 step 2500 loss 0.0077
INFO:name:epoch 14 step 2600 loss 0.00735
INFO:name:epoch 14 step 2700 loss 0.00637
INFO:name:epoch 14 step 2800 loss 0.01024
INFO:name:epoch 14 step 2900 loss 0.00696
INFO:name:epoch 14 step 3000 loss 0.00987
INFO:name:epoch 14 step 3100 loss 0.0055
INFO:name:epoch 14 step 3200 loss 0.00783
INFO:name:epoch 14 step 3300 loss 0.00824
INFO:name:epoch 14 step 3400 loss 0.00918
INFO:name:epoch 14 step 3500 loss 0.00683
INFO:name:epoch 14 step 3600 loss 0.00725
INFO:name:epoch 14 step 3700 loss 0.00693
INFO:name:epoch 14 step 3800 loss 0.00689
INFO:name:epoch 14 step 3900 loss 0.00681
INFO:name:epoch 14 step 4000 loss 0.00775
INFO:name:epoch 14 step 4100 loss 0.00839
INFO:name:epoch 14 step 4200 loss 0.00656
INFO:name:epoch 14 step 4300 loss 0.0087
INFO:name:epoch 14 step 4400 loss 0.00839
INFO:name:epoch 14 step 4500 loss 0.00841
INFO:name:epoch 14 step 4600 loss 0.00682
INFO:name:epoch 14 step 4700 loss 0.00635
INFO:name:epoch 14 step 4800 loss 0.00596
INFO:name:epoch 14 step 4900 loss 0.00681
INFO:name:epoch 14 step 5000 loss 0.00646
INFO:name:epoch 14 step 5100 loss 0.00737
INFO:name:epoch 14 step 5200 loss 0.00921
INFO:name:epoch 14 step 5300 loss 0.00732
INFO:name:epoch 14 step 5400 loss 0.00746
INFO:name:epoch 14 step 5500 loss 0.0075
INFO:name:epoch 14 step 5600 loss 0.00681
INFO:name:epoch 14 step 5700 loss 0.00861
INFO:name:epoch 14 step 5800 loss 0.00779
INFO:name:epoch 14 step 5900 loss 0.00818
INFO:name:epoch 14 step 6000 loss 0.0069
INFO:name:epoch 14 step 6100 loss 0.00727
INFO:name:epoch 14 step 6200 loss 0.00914
INFO:name:epoch 14 step 6300 loss 0.00795
INFO:name:epoch 14 step 6400 loss 0.00821
INFO:name:epoch 14 step 6500 loss 0.00629
INFO:name:epoch 14 step 6600 loss 0.00813
INFO:name:epoch 14 step 6700 loss 0.00731
INFO:name:epoch 14 step 6800 loss 0.00967
INFO:name:epoch 14 step 6900 loss 0.00858
INFO:name:epoch 14 step 7000 loss 0.0067
INFO:name:epoch 14 step 7100 loss 0.00629
INFO:name:epoch 14 step 7200 loss 0.00907
INFO:name:epoch 14 step 7300 loss 0.00691
INFO:name:epoch 14 step 7400 loss 0.00682
INFO:name:epoch 14 step 7500 loss 0.00969
INFO:name:epoch 14 step 7600 loss 0.00638
INFO:name:epoch 14 step 7700 loss 0.00653
INFO:name:epoch 14 step 7800 loss 0.00636
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4554
INFO:name:Saving model checkpoint to ./models/final_model_codeSearch/model.bin
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:[{'insert_modules': ('attention.output',), 'bottleneck_dim': (32,), 'non_linearity': 'relu', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('intermediate', 'output', 'attention.self'), 'bottleneck_dim': (64, 256, 32), 'non_linearity': 'relu', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}, 0, 0, 0, {'insert_modules': ('attention.output', 'output'), 'bottleneck_dim': (32, 256), 'non_linearity': 'silu', 'dropout_rate': 0.2, 'normalization': None, 'skip_connection': True}, 0, {'insert_modules': ('attention.self',), 'bottleneck_dim': (32,), 'non_linearity': 'swish', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}, 0, 0, {'insert_modules': ('output', 'intermediate'), 'bottleneck_dim': (128, 64), 'non_linearity': 'tanh', 'dropout_rate': 0.25, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.self', 'output'), 'bottleneck_dim': (16, 128), 'non_linearity': 'gelu', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}]
[INFO|(OpenDelta)basemodel:700]2025-01-07 04:23:14,213 >> Trainable Ratio: 2201360/128131088=1.718053%
[INFO|(OpenDelta)basemodel:702]2025-01-07 04:23:14,213 >> Delta Parameter Ratio: 2201360/128131088=1.718053%
[INFO|(OpenDelta)basemodel:704]2025-01-07 04:23:14,213 >> Static Memory 0.50 GB, Max Memory 8.03 GB
INFO:name:2.52
/opt/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:name:***** Running training *****
INFO:name:  Num examples = 251820
INFO:name:  Num Epochs = 15
INFO:name:  Instantaneous batch size per GPU = 32
INFO:name:  Total train batch size  = 32
INFO:name:  Total optimization steps = 118050
INFO:name:epoch 0 step 100 loss 0.30809
INFO:name:epoch 0 step 200 loss 0.15433
INFO:name:epoch 0 step 300 loss 0.13342
INFO:name:epoch 0 step 400 loss 0.11081
INFO:name:epoch 0 step 500 loss 0.11215
INFO:name:epoch 0 step 600 loss 0.11963
INFO:name:epoch 0 step 700 loss 0.10368
INFO:name:epoch 0 step 800 loss 0.10744
INFO:name:epoch 0 step 900 loss 0.10447
INFO:name:epoch 0 step 1000 loss 0.11184
INFO:name:epoch 0 step 1100 loss 0.08873
INFO:name:epoch 0 step 1200 loss 0.08764
INFO:name:epoch 0 step 1300 loss 0.09008
INFO:name:epoch 0 step 1400 loss 0.0982
INFO:name:epoch 0 step 1500 loss 0.09383
INFO:name:epoch 0 step 1600 loss 0.08438
INFO:name:epoch 0 step 1700 loss 0.09141
INFO:name:epoch 0 step 1800 loss 0.07755
INFO:name:epoch 0 step 1900 loss 0.08971
INFO:name:epoch 0 step 2000 loss 0.08079
INFO:name:epoch 0 step 2100 loss 0.07609
INFO:name:epoch 0 step 2200 loss 0.07736
INFO:name:epoch 0 step 2300 loss 0.09035
INFO:name:epoch 0 step 2400 loss 0.08857
INFO:name:epoch 0 step 2500 loss 0.07894
INFO:name:epoch 0 step 2600 loss 0.07827
INFO:name:epoch 0 step 2700 loss 0.07286
INFO:name:epoch 0 step 2800 loss 0.08392
INFO:name:epoch 0 step 2900 loss 0.0699
INFO:name:epoch 0 step 3000 loss 0.09022
INFO:name:epoch 0 step 3100 loss 0.07241
INFO:name:epoch 0 step 3200 loss 0.07595
INFO:name:epoch 0 step 3300 loss 0.07204
INFO:name:epoch 0 step 3400 loss 0.0722
INFO:name:epoch 0 step 3500 loss 0.08447
INFO:name:epoch 0 step 3600 loss 0.05979
INFO:name:epoch 0 step 3700 loss 0.07492
INFO:name:epoch 0 step 3800 loss 0.07791
INFO:name:epoch 0 step 3900 loss 0.06773
INFO:name:epoch 0 step 4000 loss 0.06765
INFO:name:epoch 0 step 4100 loss 0.07349
INFO:name:epoch 0 step 4200 loss 0.08531
INFO:name:epoch 0 step 4300 loss 0.07486
INFO:name:epoch 0 step 4400 loss 0.07422
INFO:name:epoch 0 step 4500 loss 0.06533
INFO:name:epoch 0 step 4600 loss 0.08469
INFO:name:epoch 0 step 4700 loss 0.07792
INFO:name:epoch 0 step 4800 loss 0.0692
INFO:name:epoch 0 step 4900 loss 0.07898
INFO:name:epoch 0 step 5000 loss 0.07368
INFO:name:epoch 0 step 5100 loss 0.07106
INFO:name:epoch 0 step 5200 loss 0.07686
INFO:name:epoch 0 step 5300 loss 0.06536
INFO:name:epoch 0 step 5400 loss 0.07428
INFO:name:epoch 0 step 5500 loss 0.06919
INFO:name:epoch 0 step 5600 loss 0.07538
INFO:name:epoch 0 step 5700 loss 0.07883
INFO:name:epoch 0 step 5800 loss 0.06262
INFO:name:epoch 0 step 5900 loss 0.06273
INFO:name:epoch 0 step 6000 loss 0.06131
INFO:name:epoch 0 step 6100 loss 0.06907
INFO:name:epoch 0 step 6200 loss 0.06816
INFO:name:epoch 0 step 6300 loss 0.07425
INFO:name:epoch 0 step 6400 loss 0.06006
INFO:name:epoch 0 step 6500 loss 0.06839
INFO:name:epoch 0 step 6600 loss 0.06783
INFO:name:epoch 0 step 6700 loss 0.07422
INFO:name:epoch 0 step 6800 loss 0.08157
INFO:name:epoch 0 step 6900 loss 0.0679
INFO:name:epoch 0 step 7000 loss 0.06543
INFO:name:epoch 0 step 7100 loss 0.07607
INFO:name:epoch 0 step 7200 loss 0.06703
INFO:name:epoch 0 step 7300 loss 0.06739
INFO:name:epoch 0 step 7400 loss 0.05677
INFO:name:epoch 0 step 7500 loss 0.06979
INFO:name:epoch 0 step 7600 loss 0.06579
INFO:name:epoch 0 step 7700 loss 0.07212
INFO:name:epoch 0 step 7800 loss 0.07664
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4498
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4498
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3845
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 1 step 100 loss 0.04983
INFO:name:epoch 1 step 200 loss 0.0427
INFO:name:epoch 1 step 300 loss 0.03799
INFO:name:epoch 1 step 400 loss 0.05116
INFO:name:epoch 1 step 500 loss 0.03355
INFO:name:epoch 1 step 600 loss 0.03374
INFO:name:epoch 1 step 700 loss 0.04127
INFO:name:epoch 1 step 800 loss 0.03668
INFO:name:epoch 1 step 900 loss 0.04258
INFO:name:epoch 1 step 1000 loss 0.03988
INFO:name:epoch 1 step 1100 loss 0.0421
INFO:name:epoch 1 step 1200 loss 0.03875
INFO:name:epoch 1 step 1300 loss 0.04102
INFO:name:epoch 1 step 1400 loss 0.04172
INFO:name:epoch 1 step 1500 loss 0.03716
INFO:name:epoch 1 step 1600 loss 0.03911
INFO:name:epoch 1 step 1700 loss 0.03039
INFO:name:epoch 1 step 1800 loss 0.03559
INFO:name:epoch 1 step 1900 loss 0.03735
INFO:name:epoch 1 step 2000 loss 0.04009
INFO:name:epoch 1 step 2100 loss 0.04471
INFO:name:epoch 1 step 2200 loss 0.04341
INFO:name:epoch 1 step 2300 loss 0.04286
INFO:name:epoch 1 step 2400 loss 0.04353
INFO:name:epoch 1 step 2500 loss 0.03028
INFO:name:epoch 1 step 2600 loss 0.04501
INFO:name:epoch 1 step 2700 loss 0.03427
INFO:name:epoch 1 step 2800 loss 0.04572
INFO:name:epoch 1 step 2900 loss 0.03163
INFO:name:epoch 1 step 3000 loss 0.05212
INFO:name:epoch 1 step 3100 loss 0.03452
INFO:name:epoch 1 step 3200 loss 0.03534
INFO:name:epoch 1 step 3300 loss 0.04962
INFO:name:epoch 1 step 3400 loss 0.04686
INFO:name:epoch 1 step 3500 loss 0.04623
INFO:name:epoch 1 step 3600 loss 0.05138
INFO:name:epoch 1 step 3700 loss 0.03839
INFO:name:epoch 1 step 3800 loss 0.04061
INFO:name:epoch 1 step 3900 loss 0.03962
INFO:name:epoch 1 step 4000 loss 0.04765
INFO:name:epoch 1 step 4100 loss 0.05372
INFO:name:epoch 1 step 4200 loss 0.03555
INFO:name:epoch 1 step 4300 loss 0.04327
INFO:name:epoch 1 step 4400 loss 0.04733
INFO:name:epoch 1 step 4500 loss 0.0397
INFO:name:epoch 1 step 4600 loss 0.03921
INFO:name:epoch 1 step 4700 loss 0.04244
INFO:name:epoch 1 step 4800 loss 0.04675
INFO:name:epoch 1 step 4900 loss 0.03773
INFO:name:epoch 1 step 5000 loss 0.04771
INFO:name:epoch 1 step 5100 loss 0.05059
INFO:name:epoch 1 step 5200 loss 0.05201
INFO:name:epoch 1 step 5300 loss 0.03958
INFO:name:epoch 1 step 5400 loss 0.03025
INFO:name:epoch 1 step 5500 loss 0.04082
INFO:name:epoch 1 step 5600 loss 0.04387
INFO:name:epoch 1 step 5700 loss 0.04047
INFO:name:epoch 1 step 5800 loss 0.04977
INFO:name:epoch 1 step 5900 loss 0.04354
INFO:name:epoch 1 step 6000 loss 0.0444
INFO:name:epoch 1 step 6100 loss 0.04078
INFO:name:epoch 1 step 6200 loss 0.04642
INFO:name:epoch 1 step 6300 loss 0.04202
INFO:name:epoch 1 step 6400 loss 0.04583
INFO:name:epoch 1 step 6500 loss 0.03407
INFO:name:epoch 1 step 6600 loss 0.05617
INFO:name:epoch 1 step 6700 loss 0.03612
INFO:name:epoch 1 step 6800 loss 0.04348
INFO:name:epoch 1 step 6900 loss 0.04969
INFO:name:epoch 1 step 7000 loss 0.04233
INFO:name:epoch 1 step 7100 loss 0.04009
INFO:name:epoch 1 step 7200 loss 0.04049
INFO:name:epoch 1 step 7300 loss 0.04145
INFO:name:epoch 1 step 7400 loss 0.0376
INFO:name:epoch 1 step 7500 loss 0.03863
INFO:name:epoch 1 step 7600 loss 0.03997
INFO:name:epoch 1 step 7700 loss 0.04559
INFO:name:epoch 1 step 7800 loss 0.04595
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4555
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4555
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3868
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 2 step 100 loss 0.03182
INFO:name:epoch 2 step 200 loss 0.03119
INFO:name:epoch 2 step 300 loss 0.02723
INFO:name:epoch 2 step 400 loss 0.0376
INFO:name:epoch 2 step 500 loss 0.0362
INFO:name:epoch 2 step 600 loss 0.03872
INFO:name:epoch 2 step 700 loss 0.04157
INFO:name:epoch 2 step 800 loss 0.03834
INFO:name:epoch 2 step 900 loss 0.02876
INFO:name:epoch 2 step 1000 loss 0.03564
INFO:name:epoch 2 step 1100 loss 0.02698
INFO:name:epoch 2 step 1200 loss 0.02921
INFO:name:epoch 2 step 1300 loss 0.02535
INFO:name:epoch 2 step 1400 loss 0.03662
INFO:name:epoch 2 step 1500 loss 0.03647
INFO:name:epoch 2 step 1600 loss 0.03209
INFO:name:epoch 2 step 1700 loss 0.03223
INFO:name:epoch 2 step 1800 loss 0.03438
INFO:name:epoch 2 step 1900 loss 0.0328
INFO:name:epoch 2 step 2000 loss 0.03783
INFO:name:epoch 2 step 2100 loss 0.03807
INFO:name:epoch 2 step 2200 loss 0.03174
INFO:name:epoch 2 step 2300 loss 0.03804
INFO:name:epoch 2 step 2400 loss 0.02865
INFO:name:epoch 2 step 2500 loss 0.02977
INFO:name:epoch 2 step 2600 loss 0.0312
INFO:name:epoch 2 step 2700 loss 0.03101
INFO:name:epoch 2 step 2800 loss 0.0302
INFO:name:epoch 2 step 2900 loss 0.02802
INFO:name:epoch 2 step 3000 loss 0.0288
INFO:name:epoch 2 step 3100 loss 0.03932
INFO:name:epoch 2 step 3200 loss 0.0329
INFO:name:epoch 2 step 3300 loss 0.02675
INFO:name:epoch 2 step 3400 loss 0.02917
INFO:name:epoch 2 step 3500 loss 0.03418
INFO:name:epoch 2 step 3600 loss 0.03485
INFO:name:epoch 2 step 3700 loss 0.02605
INFO:name:epoch 2 step 3800 loss 0.02898
INFO:name:epoch 2 step 3900 loss 0.03078
INFO:name:epoch 2 step 4000 loss 0.02705
INFO:name:epoch 2 step 4100 loss 0.03803
INFO:name:epoch 2 step 4200 loss 0.03157
INFO:name:epoch 2 step 4300 loss 0.03234
INFO:name:epoch 2 step 4400 loss 0.03658
INFO:name:epoch 2 step 4500 loss 0.0338
INFO:name:epoch 2 step 4600 loss 0.03174
INFO:name:epoch 2 step 4700 loss 0.03891
INFO:name:epoch 2 step 4800 loss 0.03502
INFO:name:epoch 2 step 4900 loss 0.03292
INFO:name:epoch 2 step 5000 loss 0.02599
INFO:name:epoch 2 step 5100 loss 0.02383
INFO:name:epoch 2 step 5200 loss 0.02848
INFO:name:epoch 2 step 5300 loss 0.03532
INFO:name:epoch 2 step 5400 loss 0.03742
INFO:name:epoch 2 step 5500 loss 0.03347
INFO:name:epoch 2 step 5600 loss 0.0301
INFO:name:epoch 2 step 5700 loss 0.03688
INFO:name:epoch 2 step 5800 loss 0.03282
INFO:name:epoch 2 step 5900 loss 0.03313
INFO:name:epoch 2 step 6000 loss 0.03544
INFO:name:epoch 2 step 6100 loss 0.02959
INFO:name:epoch 2 step 6200 loss 0.03457
INFO:name:epoch 2 step 6300 loss 0.04043
INFO:name:epoch 2 step 6400 loss 0.03211
INFO:name:epoch 2 step 6500 loss 0.02929
INFO:name:epoch 2 step 6600 loss 0.02987
INFO:name:epoch 2 step 6700 loss 0.03729
INFO:name:epoch 2 step 6800 loss 0.03067
INFO:name:epoch 2 step 6900 loss 0.0332
INFO:name:epoch 2 step 7000 loss 0.0371
INFO:name:epoch 2 step 7100 loss 0.03687
INFO:name:epoch 2 step 7200 loss 0.03529
INFO:name:epoch 2 step 7300 loss 0.03767
INFO:name:epoch 2 step 7400 loss 0.02659
INFO:name:epoch 2 step 7500 loss 0.03214
INFO:name:epoch 2 step 7600 loss 0.03466
INFO:name:epoch 2 step 7700 loss 0.03593
INFO:name:epoch 2 step 7800 loss 0.02684
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4454
INFO:name:epoch 3 step 100 loss 0.02349
INFO:name:epoch 3 step 200 loss 0.02389
INFO:name:epoch 3 step 300 loss 0.02111
INFO:name:epoch 3 step 400 loss 0.02668
INFO:name:epoch 3 step 500 loss 0.02597
INFO:name:epoch 3 step 600 loss 0.0241
INFO:name:epoch 3 step 700 loss 0.02417
INFO:name:epoch 3 step 800 loss 0.0212
INFO:name:epoch 3 step 900 loss 0.02068
INFO:name:epoch 3 step 1000 loss 0.02615
INFO:name:epoch 3 step 1100 loss 0.02171
INFO:name:epoch 3 step 1200 loss 0.02752
INFO:name:epoch 3 step 1300 loss 0.02217
INFO:name:epoch 3 step 1400 loss 0.02465
INFO:name:epoch 3 step 1500 loss 0.02071
INFO:name:epoch 3 step 1600 loss 0.02409
INFO:name:epoch 3 step 1700 loss 0.02657
INFO:name:epoch 3 step 1800 loss 0.02431
INFO:name:epoch 3 step 1900 loss 0.02628
INFO:name:epoch 3 step 2000 loss 0.03451
INFO:name:epoch 3 step 2100 loss 0.02974
INFO:name:epoch 3 step 2200 loss 0.02622
INFO:name:epoch 3 step 2300 loss 0.02647
INFO:name:epoch 3 step 2400 loss 0.03078
INFO:name:epoch 3 step 2500 loss 0.02356
INFO:name:epoch 3 step 2600 loss 0.01988
INFO:name:epoch 3 step 2700 loss 0.02216
INFO:name:epoch 3 step 2800 loss 0.02564
INFO:name:epoch 3 step 2900 loss 0.02603
INFO:name:epoch 3 step 3000 loss 0.02406
INFO:name:epoch 3 step 3100 loss 0.02506
INFO:name:epoch 3 step 3200 loss 0.02865
INFO:name:epoch 3 step 3300 loss 0.02101
INFO:name:epoch 3 step 3400 loss 0.02483
INFO:name:epoch 3 step 3500 loss 0.01686
INFO:name:epoch 3 step 3600 loss 0.0195
INFO:name:epoch 3 step 3700 loss 0.03138
INFO:name:epoch 3 step 3800 loss 0.02662
INFO:name:epoch 3 step 3900 loss 0.02856
INFO:name:epoch 3 step 4000 loss 0.01857
INFO:name:epoch 3 step 4100 loss 0.02527
INFO:name:epoch 3 step 4200 loss 0.02495
INFO:name:epoch 3 step 4300 loss 0.02809
INFO:name:epoch 3 step 4400 loss 0.02355
INFO:name:epoch 3 step 4500 loss 0.0318
INFO:name:epoch 3 step 4600 loss 0.02949
INFO:name:epoch 3 step 4700 loss 0.02325
INFO:name:epoch 3 step 4800 loss 0.02349
INFO:name:epoch 3 step 4900 loss 0.01964
INFO:name:epoch 3 step 5000 loss 0.02005
INFO:name:epoch 3 step 5100 loss 0.029
INFO:name:epoch 3 step 5200 loss 0.0234
INFO:name:epoch 3 step 5300 loss 0.02523
INFO:name:epoch 3 step 5400 loss 0.03018
INFO:name:epoch 3 step 5500 loss 0.02521
INFO:name:epoch 3 step 5600 loss 0.02749
INFO:name:epoch 3 step 5700 loss 0.02084
INFO:name:epoch 3 step 5800 loss 0.02383
INFO:name:epoch 3 step 5900 loss 0.02118
INFO:name:epoch 3 step 6000 loss 0.02433
INFO:name:epoch 3 step 6100 loss 0.02349
INFO:name:epoch 3 step 6200 loss 0.02774
INFO:name:epoch 3 step 6300 loss 0.02822
INFO:name:epoch 3 step 6400 loss 0.02272
INFO:name:epoch 3 step 6500 loss 0.0227
INFO:name:epoch 3 step 6600 loss 0.02322
INFO:name:epoch 3 step 6700 loss 0.02743
INFO:name:epoch 3 step 6800 loss 0.03052
INFO:name:epoch 3 step 6900 loss 0.0285
INFO:name:epoch 3 step 7000 loss 0.0249
INFO:name:epoch 3 step 7100 loss 0.02312
INFO:name:epoch 3 step 7200 loss 0.02767
INFO:name:epoch 3 step 7300 loss 0.02711
INFO:name:epoch 3 step 7400 loss 0.02518
INFO:name:epoch 3 step 7500 loss 0.02453
INFO:name:epoch 3 step 7600 loss 0.02967
INFO:name:epoch 3 step 7700 loss 0.02606
INFO:name:epoch 3 step 7800 loss 0.02246
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4585
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4585
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.392
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 4 step 100 loss 0.02134
INFO:name:epoch 4 step 200 loss 0.01996
INFO:name:epoch 4 step 300 loss 0.02014
INFO:name:epoch 4 step 400 loss 0.01598
INFO:name:epoch 4 step 500 loss 0.01564
INFO:name:epoch 4 step 600 loss 0.0179
INFO:name:epoch 4 step 700 loss 0.01955
INFO:name:epoch 4 step 800 loss 0.01861
INFO:name:epoch 4 step 900 loss 0.02455
INFO:name:epoch 4 step 1000 loss 0.01877
INFO:name:epoch 4 step 1100 loss 0.0178
INFO:name:epoch 4 step 1200 loss 0.01813
INFO:name:epoch 4 step 1300 loss 0.02457
INFO:name:epoch 4 step 1400 loss 0.01811
INFO:name:epoch 4 step 1500 loss 0.01646
INFO:name:epoch 4 step 1600 loss 0.02285
INFO:name:epoch 4 step 1700 loss 0.01723
INFO:name:epoch 4 step 1800 loss 0.01962
INFO:name:epoch 4 step 1900 loss 0.01949
INFO:name:epoch 4 step 2000 loss 0.01628
INFO:name:epoch 4 step 2100 loss 0.01769
INFO:name:epoch 4 step 2200 loss 0.01948
INFO:name:epoch 4 step 2300 loss 0.01705
INFO:name:epoch 4 step 2400 loss 0.01861
INFO:name:epoch 4 step 2500 loss 0.01526
INFO:name:epoch 4 step 2600 loss 0.01468
INFO:name:epoch 4 step 2700 loss 0.02013
INFO:name:epoch 4 step 2800 loss 0.0198
INFO:name:epoch 4 step 2900 loss 0.02115
INFO:name:epoch 4 step 3000 loss 0.02167
INFO:name:epoch 4 step 3100 loss 0.0192
INFO:name:epoch 4 step 3200 loss 0.01764
INFO:name:epoch 4 step 3300 loss 0.0211
INFO:name:epoch 4 step 3400 loss 0.01704
INFO:name:epoch 4 step 3500 loss 0.01553
INFO:name:epoch 4 step 3600 loss 0.01867
INFO:name:epoch 4 step 3700 loss 0.02023
INFO:name:epoch 4 step 3800 loss 0.01822
INFO:name:epoch 4 step 3900 loss 0.02749
INFO:name:epoch 4 step 4000 loss 0.02557
INFO:name:epoch 4 step 4100 loss 0.01943
INFO:name:epoch 4 step 4200 loss 0.01839
INFO:name:epoch 4 step 4300 loss 0.01832
INFO:name:epoch 4 step 4400 loss 0.0216
INFO:name:epoch 4 step 4500 loss 0.02137
INFO:name:epoch 4 step 4600 loss 0.0233
INFO:name:epoch 4 step 4700 loss 0.01832
INFO:name:epoch 4 step 4800 loss 0.01856
INFO:name:epoch 4 step 4900 loss 0.02209
INFO:name:epoch 4 step 5000 loss 0.01942
INFO:name:epoch 4 step 5100 loss 0.02244
INFO:name:epoch 4 step 5200 loss 0.01786
INFO:name:epoch 4 step 5300 loss 0.01982
INFO:name:epoch 4 step 5400 loss 0.0245
INFO:name:epoch 4 step 5500 loss 0.01941
INFO:name:epoch 4 step 5600 loss 0.02308
INFO:name:epoch 4 step 5700 loss 0.02001
INFO:name:epoch 4 step 5800 loss 0.01603
INFO:name:epoch 4 step 5900 loss 0.02218
INFO:name:epoch 4 step 6000 loss 0.01939
INFO:name:epoch 4 step 6100 loss 0.01913
INFO:name:epoch 4 step 6200 loss 0.01616
INFO:name:epoch 4 step 6300 loss 0.01712
INFO:name:epoch 4 step 6400 loss 0.01766
INFO:name:epoch 4 step 6500 loss 0.0282
INFO:name:epoch 4 step 6600 loss 0.01806
INFO:name:epoch 4 step 6700 loss 0.01903
INFO:name:epoch 4 step 6800 loss 0.0172
INFO:name:epoch 4 step 6900 loss 0.01805
INFO:name:epoch 4 step 7000 loss 0.01941
INFO:name:epoch 4 step 7100 loss 0.02263
INFO:name:epoch 4 step 7200 loss 0.02086
INFO:name:epoch 4 step 7300 loss 0.01808
INFO:name:epoch 4 step 7400 loss 0.01922
INFO:name:epoch 4 step 7500 loss 0.02633
INFO:name:epoch 4 step 7600 loss 0.0224
INFO:name:epoch 4 step 7700 loss 0.01753
INFO:name:epoch 4 step 7800 loss 0.01982
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4624
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4624
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.394
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 5 step 100 loss 0.01856
INFO:name:epoch 5 step 200 loss 0.01695
INFO:name:epoch 5 step 300 loss 0.01457
INFO:name:epoch 5 step 400 loss 0.01458
INFO:name:epoch 5 step 500 loss 0.01668
INFO:name:epoch 5 step 600 loss 0.01728
INFO:name:epoch 5 step 700 loss 0.01922
INFO:name:epoch 5 step 800 loss 0.01606
INFO:name:epoch 5 step 900 loss 0.01534
INFO:name:epoch 5 step 1000 loss 0.01631
INFO:name:epoch 5 step 1100 loss 0.01293
INFO:name:epoch 5 step 1200 loss 0.01577
INFO:name:epoch 5 step 1300 loss 0.01412
INFO:name:epoch 5 step 1400 loss 0.01336
INFO:name:epoch 5 step 1500 loss 0.01422
INFO:name:epoch 5 step 1600 loss 0.01573
INFO:name:epoch 5 step 1700 loss 0.01321
INFO:name:epoch 5 step 1800 loss 0.0143
INFO:name:epoch 5 step 1900 loss 0.01319
INFO:name:epoch 5 step 2000 loss 0.01596
INFO:name:epoch 5 step 2100 loss 0.01197
INFO:name:epoch 5 step 2200 loss 0.01463
INFO:name:epoch 5 step 2300 loss 0.01482
INFO:name:epoch 5 step 2400 loss 0.01191
INFO:name:epoch 5 step 2500 loss 0.0143
INFO:name:epoch 5 step 2600 loss 0.01799
INFO:name:epoch 5 step 2700 loss 0.01934
INFO:name:epoch 5 step 2800 loss 0.01923
INFO:name:epoch 5 step 2900 loss 0.0167
INFO:name:epoch 5 step 3000 loss 0.0191
INFO:name:epoch 5 step 3100 loss 0.02005
INFO:name:epoch 5 step 3200 loss 0.0163
INFO:name:epoch 5 step 3300 loss 0.01176
INFO:name:epoch 5 step 3400 loss 0.01716
INFO:name:epoch 5 step 3500 loss 0.01676
INFO:name:epoch 5 step 3600 loss 0.01444
INFO:name:epoch 5 step 3700 loss 0.01908
INFO:name:epoch 5 step 3800 loss 0.01883
INFO:name:epoch 5 step 3900 loss 0.01569
INFO:name:epoch 5 step 4000 loss 0.01566
INFO:name:epoch 5 step 4100 loss 0.01809
INFO:name:epoch 5 step 4200 loss 0.01328
INFO:name:epoch 5 step 4300 loss 0.01462
INFO:name:epoch 5 step 4400 loss 0.01815
INFO:name:epoch 5 step 4500 loss 0.01755
INFO:name:epoch 5 step 4600 loss 0.01576
INFO:name:epoch 5 step 4700 loss 0.01783
INFO:name:epoch 5 step 4800 loss 0.02091
INFO:name:epoch 5 step 4900 loss 0.01551
INFO:name:epoch 5 step 5000 loss 0.01633
INFO:name:epoch 5 step 5100 loss 0.01329
INFO:name:epoch 5 step 5200 loss 0.01416
INFO:name:epoch 5 step 5300 loss 0.0177
INFO:name:epoch 5 step 5400 loss 0.01542
INFO:name:epoch 5 step 5500 loss 0.0114
INFO:name:epoch 5 step 5600 loss 0.02018
INFO:name:epoch 5 step 5700 loss 0.01583
INFO:name:epoch 5 step 5800 loss 0.01363
INFO:name:epoch 5 step 5900 loss 0.01752
INFO:name:epoch 5 step 6000 loss 0.02073
INFO:name:epoch 5 step 6100 loss 0.02045
INFO:name:epoch 5 step 6200 loss 0.01802
INFO:name:epoch 5 step 6300 loss 0.01753
INFO:name:epoch 5 step 6400 loss 0.01619
INFO:name:epoch 5 step 6500 loss 0.01532
INFO:name:epoch 5 step 6600 loss 0.01769
INFO:name:epoch 5 step 6700 loss 0.01574
INFO:name:epoch 5 step 6800 loss 0.0213
INFO:name:epoch 5 step 6900 loss 0.0181
INFO:name:epoch 5 step 7000 loss 0.01891
INFO:name:epoch 5 step 7100 loss 0.0183
INFO:name:epoch 5 step 7200 loss 0.01908
INFO:name:epoch 5 step 7300 loss 0.0186
INFO:name:epoch 5 step 7400 loss 0.01237
INFO:name:epoch 5 step 7500 loss 0.01799
INFO:name:epoch 5 step 7600 loss 0.0145
INFO:name:epoch 5 step 7700 loss 0.01417
INFO:name:epoch 5 step 7800 loss 0.02098
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4648
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4648
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3984
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 6 step 100 loss 0.01762
INFO:name:epoch 6 step 200 loss 0.01339
INFO:name:epoch 6 step 300 loss 0.01355
INFO:name:epoch 6 step 400 loss 0.01063
INFO:name:epoch 6 step 500 loss 0.01469
INFO:name:epoch 6 step 600 loss 0.01483
INFO:name:epoch 6 step 700 loss 0.01388
INFO:name:epoch 6 step 800 loss 0.01342
INFO:name:epoch 6 step 900 loss 0.0158
INFO:name:epoch 6 step 1000 loss 0.01227
INFO:name:epoch 6 step 1100 loss 0.01317
INFO:name:epoch 6 step 1200 loss 0.01442
INFO:name:epoch 6 step 1300 loss 0.01423
INFO:name:epoch 6 step 1400 loss 0.01289
INFO:name:epoch 6 step 1500 loss 0.01184
INFO:name:epoch 6 step 1600 loss 0.0151
INFO:name:epoch 6 step 1700 loss 0.01113
INFO:name:epoch 6 step 1800 loss 0.01145
INFO:name:epoch 6 step 1900 loss 0.01384
INFO:name:epoch 6 step 2000 loss 0.01088
INFO:name:epoch 6 step 2100 loss 0.01472
INFO:name:epoch 6 step 2200 loss 0.01158
INFO:name:epoch 6 step 2300 loss 0.01354
INFO:name:epoch 6 step 2400 loss 0.01004
INFO:name:epoch 6 step 2500 loss 0.01056
INFO:name:epoch 6 step 2600 loss 0.01238
INFO:name:epoch 6 step 2700 loss 0.01448
INFO:name:epoch 6 step 2800 loss 0.01145
INFO:name:epoch 6 step 2900 loss 0.01306
INFO:name:epoch 6 step 3000 loss 0.01192
INFO:name:epoch 6 step 3100 loss 0.01352
INFO:name:epoch 6 step 3200 loss 0.01292
INFO:name:epoch 6 step 3300 loss 0.01139
INFO:name:epoch 6 step 3400 loss 0.01189
INFO:name:epoch 6 step 3500 loss 0.01356
INFO:name:epoch 6 step 3600 loss 0.01492
INFO:name:epoch 6 step 3700 loss 0.01701
INFO:name:epoch 6 step 3800 loss 0.01028
INFO:name:epoch 6 step 3900 loss 0.01575
INFO:name:epoch 6 step 4000 loss 0.01239
INFO:name:epoch 6 step 4100 loss 0.01426
INFO:name:epoch 6 step 4200 loss 0.01335
INFO:name:epoch 6 step 4300 loss 0.01569
INFO:name:epoch 6 step 4400 loss 0.01288
INFO:name:epoch 6 step 4500 loss 0.01398
INFO:name:epoch 6 step 4600 loss 0.01558
INFO:name:epoch 6 step 4700 loss 0.01442
INFO:name:epoch 6 step 4800 loss 0.01018
INFO:name:epoch 6 step 4900 loss 0.01483
INFO:name:epoch 6 step 5000 loss 0.01304
INFO:name:epoch 6 step 5100 loss 0.01273
INFO:name:epoch 6 step 5200 loss 0.01257
INFO:name:epoch 6 step 5300 loss 0.01617
INFO:name:epoch 6 step 5400 loss 0.01619
INFO:name:epoch 6 step 5500 loss 0.01675
INFO:name:epoch 6 step 5600 loss 0.01215
INFO:name:epoch 6 step 5700 loss 0.01305
INFO:name:epoch 6 step 5800 loss 0.01579
INFO:name:epoch 6 step 5900 loss 0.01476
INFO:name:epoch 6 step 6000 loss 0.01571
INFO:name:epoch 6 step 6100 loss 0.01349
INFO:name:epoch 6 step 6200 loss 0.01273
INFO:name:epoch 6 step 6300 loss 0.01558
INFO:name:epoch 6 step 6400 loss 0.01302
INFO:name:epoch 6 step 6500 loss 0.01537
INFO:name:epoch 6 step 6600 loss 0.01434
INFO:name:epoch 6 step 6700 loss 0.01495
INFO:name:epoch 6 step 6800 loss 0.01166
INFO:name:epoch 6 step 6900 loss 0.01298
INFO:name:epoch 6 step 7000 loss 0.01215
INFO:name:epoch 6 step 7100 loss 0.0135
INFO:name:epoch 6 step 7200 loss 0.01332
INFO:name:epoch 6 step 7300 loss 0.01201
INFO:name:epoch 6 step 7400 loss 0.015
INFO:name:epoch 6 step 7500 loss 0.01447
INFO:name:epoch 6 step 7600 loss 0.01548
INFO:name:epoch 6 step 7700 loss 0.01495
INFO:name:epoch 6 step 7800 loss 0.01405
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4546
INFO:name:epoch 7 step 100 loss 0.01417
INFO:name:epoch 7 step 200 loss 0.00985
INFO:name:epoch 7 step 300 loss 0.01106
INFO:name:epoch 7 step 400 loss 0.01354
INFO:name:epoch 7 step 500 loss 0.01272
INFO:name:epoch 7 step 600 loss 0.01084
INFO:name:epoch 7 step 700 loss 0.01302
INFO:name:epoch 7 step 800 loss 0.01139
INFO:name:epoch 7 step 900 loss 0.01263
INFO:name:epoch 7 step 1000 loss 0.01331
INFO:name:epoch 7 step 1100 loss 0.01406
INFO:name:epoch 7 step 1200 loss 0.00983
INFO:name:epoch 7 step 1300 loss 0.0108
INFO:name:epoch 7 step 1400 loss 0.01214
INFO:name:epoch 7 step 1500 loss 0.0135
INFO:name:epoch 7 step 1600 loss 0.01091
INFO:name:epoch 7 step 1700 loss 0.01173
INFO:name:epoch 7 step 1800 loss 0.01102
INFO:name:epoch 7 step 1900 loss 0.01039
INFO:name:epoch 7 step 2000 loss 0.01185
INFO:name:epoch 7 step 2100 loss 0.0113
INFO:name:epoch 7 step 2200 loss 0.01145
INFO:name:epoch 7 step 2300 loss 0.01292
INFO:name:epoch 7 step 2400 loss 0.00895
INFO:name:epoch 7 step 2500 loss 0.0107
INFO:name:epoch 7 step 2600 loss 0.01034
INFO:name:epoch 7 step 2700 loss 0.01453
INFO:name:epoch 7 step 2800 loss 0.00788
INFO:name:epoch 7 step 2900 loss 0.01359
INFO:name:epoch 7 step 3000 loss 0.01256
INFO:name:epoch 7 step 3100 loss 0.01346
INFO:name:epoch 7 step 3200 loss 0.01318
INFO:name:epoch 7 step 3300 loss 0.01204
INFO:name:epoch 7 step 3400 loss 0.01216
INFO:name:epoch 7 step 3500 loss 0.01202
INFO:name:epoch 7 step 3600 loss 0.01834
INFO:name:epoch 7 step 3700 loss 0.01049
INFO:name:epoch 7 step 3800 loss 0.01366
INFO:name:epoch 7 step 3900 loss 0.01099
INFO:name:epoch 7 step 4000 loss 0.01185
INFO:name:epoch 7 step 4100 loss 0.00908
INFO:name:epoch 7 step 4200 loss 0.01202
INFO:name:epoch 7 step 4300 loss 0.0118
INFO:name:epoch 7 step 4400 loss 0.01448
INFO:name:epoch 7 step 4500 loss 0.01072
INFO:name:epoch 7 step 4600 loss 0.01263
INFO:name:epoch 7 step 4700 loss 0.0149
INFO:name:epoch 7 step 4800 loss 0.01534
INFO:name:epoch 7 step 4900 loss 0.01147
INFO:name:epoch 7 step 5000 loss 0.01098
INFO:name:epoch 7 step 5100 loss 0.01198
INFO:name:epoch 7 step 5200 loss 0.01404
INFO:name:epoch 7 step 5300 loss 0.01314
INFO:name:epoch 7 step 5400 loss 0.01427
INFO:name:epoch 7 step 5500 loss 0.01362
INFO:name:epoch 7 step 5600 loss 0.01718
INFO:name:epoch 7 step 5700 loss 0.01053
INFO:name:epoch 7 step 5800 loss 0.01107
INFO:name:epoch 7 step 5900 loss 0.01313
INFO:name:epoch 7 step 6000 loss 0.01602
INFO:name:epoch 7 step 6100 loss 0.01207
INFO:name:epoch 7 step 6200 loss 0.01257
INFO:name:epoch 7 step 6300 loss 0.01285
INFO:name:epoch 7 step 6400 loss 0.01004
INFO:name:epoch 7 step 6500 loss 0.01171
INFO:name:epoch 7 step 6600 loss 0.01333
INFO:name:epoch 7 step 6700 loss 0.01289
INFO:name:epoch 7 step 6800 loss 0.00989
INFO:name:epoch 7 step 6900 loss 0.01091
INFO:name:epoch 7 step 7000 loss 0.01028
INFO:name:epoch 7 step 7100 loss 0.01204
INFO:name:epoch 7 step 7200 loss 0.01308
INFO:name:epoch 7 step 7300 loss 0.01091
INFO:name:epoch 7 step 7400 loss 0.01443
INFO:name:epoch 7 step 7500 loss 0.01044
INFO:name:epoch 7 step 7600 loss 0.01198
INFO:name:epoch 7 step 7700 loss 0.01085
INFO:name:epoch 7 step 7800 loss 0.01073
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4625
INFO:name:epoch 8 step 100 loss 0.01215
INFO:name:epoch 8 step 200 loss 0.00918
INFO:name:epoch 8 step 300 loss 0.01097
INFO:name:epoch 8 step 400 loss 0.01231
INFO:name:epoch 8 step 500 loss 0.01027
INFO:name:epoch 8 step 600 loss 0.01046
INFO:name:epoch 8 step 700 loss 0.01055
INFO:name:epoch 8 step 800 loss 0.00935
INFO:name:epoch 8 step 900 loss 0.01241
INFO:name:epoch 8 step 1000 loss 0.01112
INFO:name:epoch 8 step 1100 loss 0.00957
INFO:name:epoch 8 step 1200 loss 0.0118
INFO:name:epoch 8 step 1300 loss 0.01074
INFO:name:epoch 8 step 1400 loss 0.00969
INFO:name:epoch 8 step 1500 loss 0.01077
INFO:name:epoch 8 step 1600 loss 0.0088
INFO:name:epoch 8 step 1700 loss 0.00944
INFO:name:epoch 8 step 1800 loss 0.00979
INFO:name:epoch 8 step 1900 loss 0.00967
INFO:name:epoch 8 step 2000 loss 0.01025
INFO:name:epoch 8 step 2100 loss 0.01032
INFO:name:epoch 8 step 2200 loss 0.0088
INFO:name:epoch 8 step 2300 loss 0.00941
INFO:name:epoch 8 step 2400 loss 0.0084
INFO:name:epoch 8 step 2500 loss 0.00784
INFO:name:epoch 8 step 2600 loss 0.01098
INFO:name:epoch 8 step 2700 loss 0.01343
INFO:name:epoch 8 step 2800 loss 0.01103
INFO:name:epoch 8 step 2900 loss 0.01021
INFO:name:epoch 8 step 3000 loss 0.01112
INFO:name:epoch 8 step 3100 loss 0.00806
INFO:name:epoch 8 step 3200 loss 0.00929
INFO:name:epoch 8 step 3300 loss 0.00921
INFO:name:epoch 8 step 3400 loss 0.00968
INFO:name:epoch 8 step 3500 loss 0.01133
INFO:name:epoch 8 step 3600 loss 0.01222
INFO:name:epoch 8 step 3700 loss 0.01088
INFO:name:epoch 8 step 3800 loss 0.0091
INFO:name:epoch 8 step 3900 loss 0.01338
INFO:name:epoch 8 step 4000 loss 0.00942
INFO:name:epoch 8 step 4100 loss 0.01072
INFO:name:epoch 8 step 4200 loss 0.01151
INFO:name:epoch 8 step 4300 loss 0.01025
INFO:name:epoch 8 step 4400 loss 0.0118
INFO:name:epoch 8 step 4500 loss 0.01046
INFO:name:epoch 8 step 4600 loss 0.01331
INFO:name:epoch 8 step 4700 loss 0.01047
INFO:name:epoch 8 step 4800 loss 0.00866
INFO:name:epoch 8 step 4900 loss 0.01124
INFO:name:epoch 8 step 5000 loss 0.01039
INFO:name:epoch 8 step 5100 loss 0.01251
INFO:name:epoch 8 step 5200 loss 0.01017
INFO:name:epoch 8 step 5300 loss 0.01144
INFO:name:epoch 8 step 5400 loss 0.00972
INFO:name:epoch 8 step 5500 loss 0.00939
INFO:name:epoch 8 step 5600 loss 0.00967
INFO:name:epoch 8 step 5700 loss 0.016
INFO:name:epoch 8 step 5800 loss 0.01176
INFO:name:epoch 8 step 5900 loss 0.01002
INFO:name:epoch 8 step 6000 loss 0.01305
INFO:name:epoch 8 step 6100 loss 0.01142
INFO:name:epoch 8 step 6200 loss 0.01048
INFO:name:epoch 8 step 6300 loss 0.01007
INFO:name:epoch 8 step 6400 loss 0.01084
INFO:name:epoch 8 step 6500 loss 0.00928
INFO:name:epoch 8 step 6600 loss 0.00966
INFO:name:epoch 8 step 6700 loss 0.00935
INFO:name:epoch 8 step 6800 loss 0.01017
INFO:name:epoch 8 step 6900 loss 0.01028
INFO:name:epoch 8 step 7000 loss 0.00883
INFO:name:epoch 8 step 7100 loss 0.01203
INFO:name:epoch 8 step 7200 loss 0.01088
INFO:name:epoch 8 step 7300 loss 0.01115
INFO:name:epoch 8 step 7400 loss 0.00906
INFO:name:epoch 8 step 7500 loss 0.01157
INFO:name:epoch 8 step 7600 loss 0.01007
INFO:name:epoch 8 step 7700 loss 0.00922
INFO:name:epoch 8 step 7800 loss 0.01188
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4559
INFO:name:epoch 9 step 100 loss 0.00996
INFO:name:epoch 9 step 200 loss 0.00902
INFO:name:epoch 9 step 300 loss 0.00923
INFO:name:epoch 9 step 400 loss 0.01242
INFO:name:epoch 9 step 500 loss 0.00949
INFO:name:epoch 9 step 600 loss 0.01035
INFO:name:epoch 9 step 700 loss 0.0098
INFO:name:epoch 9 step 800 loss 0.00897
INFO:name:epoch 9 step 900 loss 0.0075
INFO:name:epoch 9 step 1000 loss 0.00946
INFO:name:epoch 9 step 1100 loss 0.00772
INFO:name:epoch 9 step 1200 loss 0.00913
INFO:name:epoch 9 step 1300 loss 0.00933
INFO:name:epoch 9 step 1400 loss 0.00911
INFO:name:epoch 9 step 1500 loss 0.01008
INFO:name:epoch 9 step 1600 loss 0.00986
INFO:name:epoch 9 step 1700 loss 0.00938
INFO:name:epoch 9 step 1800 loss 0.01172
INFO:name:epoch 9 step 1900 loss 0.00904
INFO:name:epoch 9 step 2000 loss 0.00979
INFO:name:epoch 9 step 2100 loss 0.00814
INFO:name:epoch 9 step 2200 loss 0.00963
INFO:name:epoch 9 step 2300 loss 0.01114
INFO:name:epoch 9 step 2400 loss 0.00962
INFO:name:epoch 9 step 2500 loss 0.01404
INFO:name:epoch 9 step 2600 loss 0.00886
INFO:name:epoch 9 step 2700 loss 0.00871
INFO:name:epoch 9 step 2800 loss 0.00806
INFO:name:epoch 9 step 2900 loss 0.00866
INFO:name:epoch 9 step 3000 loss 0.01045
INFO:name:epoch 9 step 3100 loss 0.01075
INFO:name:epoch 9 step 3200 loss 0.01047
INFO:name:epoch 9 step 3300 loss 0.00978
INFO:name:epoch 9 step 3400 loss 0.0127
INFO:name:epoch 9 step 3500 loss 0.01092
INFO:name:epoch 9 step 3600 loss 0.00832
INFO:name:epoch 9 step 3700 loss 0.01237
INFO:name:epoch 9 step 3800 loss 0.00954
INFO:name:epoch 9 step 3900 loss 0.01026
INFO:name:epoch 9 step 4000 loss 0.00946
INFO:name:epoch 9 step 4100 loss 0.00856
INFO:name:epoch 9 step 4200 loss 0.00998
INFO:name:epoch 9 step 4300 loss 0.00683
INFO:name:epoch 9 step 4400 loss 0.00993
INFO:name:epoch 9 step 4500 loss 0.00819
INFO:name:epoch 9 step 4600 loss 0.0099
INFO:name:epoch 9 step 4700 loss 0.0084
INFO:name:epoch 9 step 4800 loss 0.00733
INFO:name:epoch 9 step 4900 loss 0.00624
INFO:name:epoch 9 step 5000 loss 0.01173
INFO:name:epoch 9 step 5100 loss 0.00927
INFO:name:epoch 9 step 5200 loss 0.01106
INFO:name:epoch 9 step 5300 loss 0.01102
INFO:name:epoch 9 step 5400 loss 0.00996
INFO:name:epoch 9 step 5500 loss 0.00913
INFO:name:epoch 9 step 5600 loss 0.00871
INFO:name:epoch 9 step 5700 loss 0.01503
INFO:name:epoch 9 step 5800 loss 0.01283
INFO:name:epoch 9 step 5900 loss 0.01094
INFO:name:epoch 9 step 6000 loss 0.00968
INFO:name:epoch 9 step 6100 loss 0.011
INFO:name:epoch 9 step 6200 loss 0.01262
INFO:name:epoch 9 step 6300 loss 0.01183
INFO:name:epoch 9 step 6400 loss 0.01124
INFO:name:epoch 9 step 6500 loss 0.00855
INFO:name:epoch 9 step 6600 loss 0.0108
INFO:name:epoch 9 step 6700 loss 0.00828
INFO:name:epoch 9 step 6800 loss 0.01052
INFO:name:epoch 9 step 6900 loss 0.0096
INFO:name:epoch 9 step 7000 loss 0.00893
INFO:name:epoch 9 step 7100 loss 0.00972
INFO:name:epoch 9 step 7200 loss 0.01017
INFO:name:epoch 9 step 7300 loss 0.00997
INFO:name:epoch 9 step 7400 loss 0.00695
INFO:name:epoch 9 step 7500 loss 0.00973
INFO:name:epoch 9 step 7600 loss 0.00974
INFO:name:epoch 9 step 7700 loss 0.00763
INFO:name:epoch 9 step 7800 loss 0.00817
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4476
INFO:name:epoch 10 step 100 loss 0.00876
INFO:name:epoch 10 step 200 loss 0.00875
INFO:name:epoch 10 step 300 loss 0.00868
INFO:name:epoch 10 step 400 loss 0.00905
INFO:name:epoch 10 step 500 loss 0.0085
INFO:name:epoch 10 step 600 loss 0.00752
INFO:name:epoch 10 step 700 loss 0.00876
INFO:name:epoch 10 step 800 loss 0.00858
INFO:name:epoch 10 step 900 loss 0.00788
INFO:name:epoch 10 step 1000 loss 0.00986
INFO:name:epoch 10 step 1100 loss 0.00814
INFO:name:epoch 10 step 1200 loss 0.00859
INFO:name:epoch 10 step 1300 loss 0.01184
INFO:name:epoch 10 step 1400 loss 0.01027
INFO:name:epoch 10 step 1500 loss 0.00835
INFO:name:epoch 10 step 1600 loss 0.00661
INFO:name:epoch 10 step 1700 loss 0.00723
INFO:name:epoch 10 step 1800 loss 0.00969
INFO:name:epoch 10 step 1900 loss 0.01101
INFO:name:epoch 10 step 2000 loss 0.01001
INFO:name:epoch 10 step 2100 loss 0.01026
INFO:name:epoch 10 step 2200 loss 0.00781
INFO:name:epoch 10 step 2300 loss 0.00725
INFO:name:epoch 10 step 2400 loss 0.00723
INFO:name:epoch 10 step 2500 loss 0.0067
INFO:name:epoch 10 step 2600 loss 0.00918
INFO:name:epoch 10 step 2700 loss 0.00964
INFO:name:epoch 10 step 2800 loss 0.01019
INFO:name:epoch 10 step 2900 loss 0.00789
INFO:name:epoch 10 step 3000 loss 0.00778
INFO:name:epoch 10 step 3100 loss 0.00854
INFO:name:epoch 10 step 3200 loss 0.00685
INFO:name:epoch 10 step 3300 loss 0.0086
INFO:name:epoch 10 step 3400 loss 0.01107
INFO:name:epoch 10 step 3500 loss 0.00935
INFO:name:epoch 10 step 3600 loss 0.01092
INFO:name:epoch 10 step 3700 loss 0.01045
INFO:name:epoch 10 step 3800 loss 0.00782
INFO:name:epoch 10 step 3900 loss 0.00789
INFO:name:epoch 10 step 4000 loss 0.01042
INFO:name:epoch 10 step 4100 loss 0.00936
INFO:name:epoch 10 step 4200 loss 0.01027
INFO:name:epoch 10 step 4300 loss 0.00947
INFO:name:epoch 10 step 4400 loss 0.00912
INFO:name:epoch 10 step 4500 loss 0.01049
INFO:name:epoch 10 step 4600 loss 0.01051
INFO:name:epoch 10 step 4700 loss 0.0081
INFO:name:epoch 10 step 4800 loss 0.00901
INFO:name:epoch 10 step 4900 loss 0.00858
INFO:name:epoch 10 step 5000 loss 0.00715
INFO:name:epoch 10 step 5100 loss 0.0079
INFO:name:epoch 10 step 5200 loss 0.00727
INFO:name:epoch 10 step 5300 loss 0.00954
INFO:name:epoch 10 step 5400 loss 0.00981
INFO:name:epoch 10 step 5500 loss 0.00976
INFO:name:epoch 10 step 5600 loss 0.00994
INFO:name:epoch 10 step 5700 loss 0.01019
INFO:name:epoch 10 step 5800 loss 0.01046
INFO:name:epoch 10 step 5900 loss 0.0088
INFO:name:epoch 10 step 6000 loss 0.00749
INFO:name:epoch 10 step 6100 loss 0.00768
INFO:name:epoch 10 step 6200 loss 0.01012
INFO:name:epoch 10 step 6300 loss 0.01039
INFO:name:epoch 10 step 6400 loss 0.01284
INFO:name:epoch 10 step 6500 loss 0.0089
INFO:name:epoch 10 step 6600 loss 0.00923
INFO:name:epoch 10 step 6700 loss 0.00774
INFO:name:epoch 10 step 6800 loss 0.00741
INFO:name:epoch 10 step 6900 loss 0.00793
INFO:name:epoch 10 step 7000 loss 0.00841
INFO:name:epoch 10 step 7100 loss 0.00774
INFO:name:epoch 10 step 7200 loss 0.00972
INFO:name:epoch 10 step 7300 loss 0.00754
INFO:name:epoch 10 step 7400 loss 0.00864
INFO:name:epoch 10 step 7500 loss 0.0106
INFO:name:epoch 10 step 7600 loss 0.01083
INFO:name:epoch 10 step 7700 loss 0.0093
INFO:name:epoch 10 step 7800 loss 0.00647
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4502
INFO:name:epoch 11 step 100 loss 0.00796
INFO:name:epoch 11 step 200 loss 0.0066
INFO:name:epoch 11 step 300 loss 0.00986
INFO:name:epoch 11 step 400 loss 0.00538
INFO:name:epoch 11 step 500 loss 0.01118
INFO:name:epoch 11 step 600 loss 0.00932
INFO:name:epoch 11 step 700 loss 0.00969
INFO:name:epoch 11 step 800 loss 0.0085
INFO:name:epoch 11 step 900 loss 0.00768
INFO:name:epoch 11 step 1000 loss 0.0087
INFO:name:epoch 11 step 1100 loss 0.00619
INFO:name:epoch 11 step 1200 loss 0.00924
INFO:name:epoch 11 step 1300 loss 0.00812
INFO:name:epoch 11 step 1400 loss 0.00519
INFO:name:epoch 11 step 1500 loss 0.00868
INFO:name:epoch 11 step 1600 loss 0.01025
INFO:name:epoch 11 step 1700 loss 0.00871
INFO:name:epoch 11 step 1800 loss 0.005
INFO:name:epoch 11 step 1900 loss 0.00852
INFO:name:epoch 11 step 2000 loss 0.00722
INFO:name:epoch 11 step 2100 loss 0.01018
INFO:name:epoch 11 step 2200 loss 0.0081
INFO:name:epoch 11 step 2300 loss 0.0061
INFO:name:epoch 11 step 2400 loss 0.00865
INFO:name:epoch 11 step 2500 loss 0.00897
INFO:name:epoch 11 step 2600 loss 0.00892
INFO:name:epoch 11 step 2700 loss 0.00803
INFO:name:epoch 11 step 2800 loss 0.00914
INFO:name:epoch 11 step 2900 loss 0.00898
INFO:name:epoch 11 step 3000 loss 0.01001
INFO:name:epoch 11 step 3100 loss 0.00698
INFO:name:epoch 11 step 3200 loss 0.0075
INFO:name:epoch 11 step 3300 loss 0.0098
INFO:name:epoch 11 step 3400 loss 0.00808
INFO:name:epoch 11 step 3500 loss 0.00794
INFO:name:epoch 11 step 3600 loss 0.00686
INFO:name:epoch 11 step 3700 loss 0.00842
INFO:name:epoch 11 step 3800 loss 0.0069
INFO:name:epoch 11 step 3900 loss 0.00716
INFO:name:epoch 11 step 4000 loss 0.00827
INFO:name:epoch 11 step 4100 loss 0.00521
INFO:name:epoch 11 step 4200 loss 0.01044
INFO:name:epoch 11 step 4300 loss 0.00646
INFO:name:epoch 11 step 4400 loss 0.00938
INFO:name:epoch 11 step 4500 loss 0.00995
INFO:name:epoch 11 step 4600 loss 0.00805
INFO:name:epoch 11 step 4700 loss 0.00671
INFO:name:epoch 11 step 4800 loss 0.00817
INFO:name:epoch 11 step 4900 loss 0.01149
INFO:name:epoch 11 step 5000 loss 0.0086
INFO:name:epoch 11 step 5100 loss 0.0071
INFO:name:epoch 11 step 5200 loss 0.00787
INFO:name:epoch 11 step 5300 loss 0.00896
INFO:name:epoch 11 step 5400 loss 0.00627
INFO:name:epoch 11 step 5500 loss 0.00818
INFO:name:epoch 11 step 5600 loss 0.0065
INFO:name:epoch 11 step 5700 loss 0.00726
INFO:name:epoch 11 step 5800 loss 0.00727
INFO:name:epoch 11 step 5900 loss 0.01124
INFO:name:epoch 11 step 6000 loss 0.00925
INFO:name:epoch 11 step 6100 loss 0.00638
INFO:name:epoch 11 step 6200 loss 0.00798
INFO:name:epoch 11 step 6300 loss 0.01009
INFO:name:epoch 11 step 6400 loss 0.00729
INFO:name:epoch 11 step 6500 loss 0.00752
INFO:name:epoch 11 step 6600 loss 0.00817
INFO:name:epoch 11 step 6700 loss 0.01128
INFO:name:epoch 11 step 6800 loss 0.00799
INFO:name:epoch 11 step 6900 loss 0.00856
INFO:name:epoch 11 step 7000 loss 0.00522
INFO:name:epoch 11 step 7100 loss 0.00821
INFO:name:epoch 11 step 7200 loss 0.00641
INFO:name:epoch 11 step 7300 loss 0.00756
INFO:name:epoch 11 step 7400 loss 0.00808
INFO:name:epoch 11 step 7500 loss 0.00737
INFO:name:epoch 11 step 7600 loss 0.00796
INFO:name:epoch 11 step 7700 loss 0.00585
INFO:name:epoch 11 step 7800 loss 0.0085
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4479
INFO:name:epoch 12 step 100 loss 0.00641
INFO:name:epoch 12 step 200 loss 0.00698
INFO:name:epoch 12 step 300 loss 0.00621
INFO:name:epoch 12 step 400 loss 0.01072
INFO:name:epoch 12 step 500 loss 0.00661
INFO:name:epoch 12 step 600 loss 0.00673
INFO:name:epoch 12 step 700 loss 0.00911
INFO:name:epoch 12 step 800 loss 0.00858
INFO:name:epoch 12 step 900 loss 0.00857
INFO:name:epoch 12 step 1000 loss 0.00606
INFO:name:epoch 12 step 1100 loss 0.00884
INFO:name:epoch 12 step 1200 loss 0.00691
INFO:name:epoch 12 step 1300 loss 0.00766
INFO:name:epoch 12 step 1400 loss 0.00842
INFO:name:epoch 12 step 1500 loss 0.00825
INFO:name:epoch 12 step 1600 loss 0.00702
INFO:name:epoch 12 step 1700 loss 0.00801
INFO:name:epoch 12 step 1800 loss 0.0067
INFO:name:epoch 12 step 1900 loss 0.00695
INFO:name:epoch 12 step 2000 loss 0.00854
INFO:name:epoch 12 step 2100 loss 0.0086
INFO:name:epoch 12 step 2200 loss 0.00679
INFO:name:epoch 12 step 2300 loss 0.00745
INFO:name:epoch 12 step 2400 loss 0.00716
INFO:name:epoch 12 step 2500 loss 0.0074
INFO:name:epoch 12 step 2600 loss 0.00801
INFO:name:epoch 12 step 2700 loss 0.00891
INFO:name:epoch 12 step 2800 loss 0.00874
INFO:name:epoch 12 step 2900 loss 0.00871
INFO:name:epoch 12 step 3000 loss 0.00829
INFO:name:epoch 12 step 3100 loss 0.0062
INFO:name:epoch 12 step 3200 loss 0.0078
INFO:name:epoch 12 step 3300 loss 0.00827
INFO:name:epoch 12 step 3400 loss 0.01109
INFO:name:epoch 12 step 3500 loss 0.00672
INFO:name:epoch 12 step 3600 loss 0.00822
INFO:name:epoch 12 step 3700 loss 0.0079
INFO:name:epoch 12 step 3800 loss 0.00626
INFO:name:epoch 12 step 3900 loss 0.00762
INFO:name:epoch 12 step 4000 loss 0.007
INFO:name:epoch 12 step 4100 loss 0.00988
INFO:name:epoch 12 step 4200 loss 0.00601
INFO:name:epoch 12 step 4300 loss 0.01107
INFO:name:epoch 12 step 4400 loss 0.01057
INFO:name:epoch 12 step 4500 loss 0.00682
INFO:name:epoch 12 step 4600 loss 0.00863
INFO:name:epoch 12 step 4700 loss 0.00856
INFO:name:epoch 12 step 4800 loss 0.00688
INFO:name:epoch 12 step 4900 loss 0.00767
INFO:name:epoch 12 step 5000 loss 0.00822
INFO:name:epoch 12 step 5100 loss 0.00879
INFO:name:epoch 12 step 5200 loss 0.00631
INFO:name:epoch 12 step 5300 loss 0.00678
INFO:name:epoch 12 step 5400 loss 0.00837
INFO:name:epoch 12 step 5500 loss 0.00649
INFO:name:epoch 12 step 5600 loss 0.0078
INFO:name:epoch 12 step 5700 loss 0.00598
INFO:name:epoch 12 step 5800 loss 0.00868
INFO:name:epoch 12 step 5900 loss 0.008
INFO:name:epoch 12 step 6000 loss 0.01034
INFO:name:epoch 12 step 6100 loss 0.00774
INFO:name:epoch 12 step 6200 loss 0.00691
INFO:name:epoch 12 step 6300 loss 0.0084
INFO:name:epoch 12 step 6400 loss 0.00666
INFO:name:epoch 12 step 6500 loss 0.00681
INFO:name:epoch 12 step 6600 loss 0.00665
INFO:name:epoch 12 step 6700 loss 0.00719
INFO:name:epoch 12 step 6800 loss 0.0062
INFO:name:epoch 12 step 6900 loss 0.00949
INFO:name:epoch 12 step 7000 loss 0.00777
INFO:name:epoch 12 step 7100 loss 0.00733
INFO:name:epoch 12 step 7200 loss 0.00857
INFO:name:epoch 12 step 7300 loss 0.00641
INFO:name:epoch 12 step 7400 loss 0.00721
INFO:name:epoch 12 step 7500 loss 0.00845
INFO:name:epoch 12 step 7600 loss 0.00641
INFO:name:epoch 12 step 7700 loss 0.0083
INFO:name:epoch 12 step 7800 loss 0.00693
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4484
INFO:name:epoch 13 step 100 loss 0.00774
INFO:name:epoch 13 step 200 loss 0.00646
INFO:name:epoch 13 step 300 loss 0.00723
INFO:name:epoch 13 step 400 loss 0.00887
INFO:name:epoch 13 step 500 loss 0.00689
INFO:name:epoch 13 step 600 loss 0.00913
INFO:name:epoch 13 step 700 loss 0.0093
INFO:name:epoch 13 step 800 loss 0.00725
INFO:name:epoch 13 step 900 loss 0.00621
INFO:name:epoch 13 step 1000 loss 0.00524
INFO:name:epoch 13 step 1100 loss 0.0081
INFO:name:epoch 13 step 1200 loss 0.00674
INFO:name:epoch 13 step 1300 loss 0.00796
INFO:name:epoch 13 step 1400 loss 0.00839
INFO:name:epoch 13 step 1500 loss 0.00732
INFO:name:epoch 13 step 1600 loss 0.00735
INFO:name:epoch 13 step 1700 loss 0.00754
INFO:name:epoch 13 step 1800 loss 0.00738
INFO:name:epoch 13 step 1900 loss 0.00775
INFO:name:epoch 13 step 2000 loss 0.00771
INFO:name:epoch 13 step 2100 loss 0.00637
INFO:name:epoch 13 step 2200 loss 0.00729
INFO:name:epoch 13 step 2300 loss 0.00929
INFO:name:epoch 13 step 2400 loss 0.00476
INFO:name:epoch 13 step 2500 loss 0.00779
INFO:name:epoch 13 step 2600 loss 0.0059
INFO:name:epoch 13 step 2700 loss 0.00675
INFO:name:epoch 13 step 2800 loss 0.00545
INFO:name:epoch 13 step 2900 loss 0.00679
INFO:name:epoch 13 step 3000 loss 0.00671
INFO:name:epoch 13 step 3100 loss 0.00622
INFO:name:epoch 13 step 3200 loss 0.00515
INFO:name:epoch 13 step 3300 loss 0.00662
INFO:name:epoch 13 step 3400 loss 0.00828
INFO:name:epoch 13 step 3500 loss 0.00794
INFO:name:epoch 13 step 3600 loss 0.0072
INFO:name:epoch 13 step 3700 loss 0.00803
INFO:name:epoch 13 step 3800 loss 0.00893
INFO:name:epoch 13 step 3900 loss 0.00735
INFO:name:epoch 13 step 4000 loss 0.01008
INFO:name:epoch 13 step 4100 loss 0.00886
INFO:name:epoch 13 step 4200 loss 0.00818
INFO:name:epoch 13 step 4300 loss 0.00763
INFO:name:epoch 13 step 4400 loss 0.00584
INFO:name:epoch 13 step 4500 loss 0.00571
INFO:name:epoch 13 step 4600 loss 0.00702
INFO:name:epoch 13 step 4700 loss 0.00814
INFO:name:epoch 13 step 4800 loss 0.00662
INFO:name:epoch 13 step 4900 loss 0.00533
INFO:name:epoch 13 step 5000 loss 0.00516
INFO:name:epoch 13 step 5100 loss 0.01129
INFO:name:epoch 13 step 5200 loss 0.00881
INFO:name:epoch 13 step 5300 loss 0.0077
INFO:name:epoch 13 step 5400 loss 0.0074
INFO:name:epoch 13 step 5500 loss 0.00889
INFO:name:epoch 13 step 5600 loss 0.005
INFO:name:epoch 13 step 5700 loss 0.00698
INFO:name:epoch 13 step 5800 loss 0.00591
INFO:name:epoch 13 step 5900 loss 0.00707
INFO:name:epoch 13 step 6000 loss 0.0071
INFO:name:epoch 13 step 6100 loss 0.00785
INFO:name:epoch 13 step 6200 loss 0.00677
INFO:name:epoch 13 step 6300 loss 0.00733
INFO:name:epoch 13 step 6400 loss 0.00666
INFO:name:epoch 13 step 6500 loss 0.00769
INFO:name:epoch 13 step 6600 loss 0.00634
INFO:name:epoch 13 step 6700 loss 0.00973
INFO:name:epoch 13 step 6800 loss 0.00572
INFO:name:epoch 13 step 6900 loss 0.00721
INFO:name:epoch 13 step 7000 loss 0.00448
INFO:name:epoch 13 step 7100 loss 0.00484
INFO:name:epoch 13 step 7200 loss 0.00813
INFO:name:epoch 13 step 7300 loss 0.00573
INFO:name:epoch 13 step 7400 loss 0.00662
INFO:name:epoch 13 step 7500 loss 0.00714
INFO:name:epoch 13 step 7600 loss 0.00688
INFO:name:epoch 13 step 7700 loss 0.00589
INFO:name:epoch 13 step 7800 loss 0.00654
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4471
INFO:name:epoch 14 step 100 loss 0.00755
INFO:name:epoch 14 step 200 loss 0.00701
INFO:name:epoch 14 step 300 loss 0.00805
INFO:name:epoch 14 step 400 loss 0.00605
INFO:name:epoch 14 step 500 loss 0.00566
INFO:name:epoch 14 step 600 loss 0.00574
INFO:name:epoch 14 step 700 loss 0.00624
INFO:name:epoch 14 step 800 loss 0.00826
INFO:name:epoch 14 step 900 loss 0.00633
INFO:name:epoch 14 step 1000 loss 0.00726
INFO:name:epoch 14 step 1100 loss 0.00595
INFO:name:epoch 14 step 1200 loss 0.00626
INFO:name:epoch 14 step 1300 loss 0.00726
INFO:name:epoch 14 step 1400 loss 0.00614
INFO:name:epoch 14 step 1500 loss 0.00699
INFO:name:epoch 14 step 1600 loss 0.00596
INFO:name:epoch 14 step 1700 loss 0.00633
INFO:name:epoch 14 step 1800 loss 0.00774
INFO:name:epoch 14 step 1900 loss 0.00838
INFO:name:epoch 14 step 2000 loss 0.00795
INFO:name:epoch 14 step 2100 loss 0.00979
INFO:name:epoch 14 step 2200 loss 0.00658
INFO:name:epoch 14 step 2300 loss 0.00539
INFO:name:epoch 14 step 2400 loss 0.00813
INFO:name:epoch 14 step 2500 loss 0.0053
INFO:name:epoch 14 step 2600 loss 0.00752
INFO:name:epoch 14 step 2700 loss 0.00556
INFO:name:epoch 14 step 2800 loss 0.00551
INFO:name:epoch 14 step 2900 loss 0.00779
INFO:name:epoch 14 step 3000 loss 0.007
INFO:name:epoch 14 step 3100 loss 0.00546
INFO:name:epoch 14 step 3200 loss 0.0085
INFO:name:epoch 14 step 3300 loss 0.00751
INFO:name:epoch 14 step 3400 loss 0.00683
INFO:name:epoch 14 step 3500 loss 0.00624
INFO:name:epoch 14 step 3600 loss 0.00765
INFO:name:epoch 14 step 3700 loss 0.00646
INFO:name:epoch 14 step 3800 loss 0.00705
INFO:name:epoch 14 step 3900 loss 0.0087
INFO:name:epoch 14 step 4000 loss 0.00623
INFO:name:epoch 14 step 4100 loss 0.00802
INFO:name:epoch 14 step 4200 loss 0.00755
INFO:name:epoch 14 step 4300 loss 0.00511
INFO:name:epoch 14 step 4400 loss 0.00501
INFO:name:epoch 14 step 4500 loss 0.00569
INFO:name:epoch 14 step 4600 loss 0.00821
INFO:name:epoch 14 step 4700 loss 0.00649
INFO:name:epoch 14 step 4800 loss 0.00867
INFO:name:epoch 14 step 4900 loss 0.0064
INFO:name:epoch 14 step 5000 loss 0.00806
INFO:name:epoch 14 step 5100 loss 0.00731
INFO:name:epoch 14 step 5200 loss 0.00641
INFO:name:epoch 14 step 5300 loss 0.00656
INFO:name:epoch 14 step 5400 loss 0.0047
INFO:name:epoch 14 step 5500 loss 0.00619
INFO:name:epoch 14 step 5600 loss 0.0058
INFO:name:epoch 14 step 5700 loss 0.00739
INFO:name:epoch 14 step 5800 loss 0.0063
INFO:name:epoch 14 step 5900 loss 0.00538
INFO:name:epoch 14 step 6000 loss 0.00769
INFO:name:epoch 14 step 6100 loss 0.00662
INFO:name:epoch 14 step 6200 loss 0.00681
INFO:name:epoch 14 step 6300 loss 0.00836
INFO:name:epoch 14 step 6400 loss 0.00607
INFO:name:epoch 14 step 6500 loss 0.00542
INFO:name:epoch 14 step 6600 loss 0.00623
INFO:name:epoch 14 step 6700 loss 0.0067
INFO:name:epoch 14 step 6800 loss 0.00587
INFO:name:epoch 14 step 6900 loss 0.00483
INFO:name:epoch 14 step 7000 loss 0.00701
INFO:name:epoch 14 step 7100 loss 0.00822
INFO:name:epoch 14 step 7200 loss 0.00618
INFO:name:epoch 14 step 7300 loss 0.0062
INFO:name:epoch 14 step 7400 loss 0.00776
INFO:name:epoch 14 step 7500 loss 0.00681
INFO:name:epoch 14 step 7600 loss 0.00851
INFO:name:epoch 14 step 7700 loss 0.00637
INFO:name:epoch 14 step 7800 loss 0.00766
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4483
INFO:name:Saving model checkpoint to ./models/final_model_codeSearch/model.bin
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:[{'insert_modules': ('attention.output',), 'bottleneck_dim': (32,), 'non_linearity': 'relu', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('intermediate', 'output', 'attention.self'), 'bottleneck_dim': (64, 256, 32), 'non_linearity': 'relu', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}, 0, {'insert_modules': ('attention.output',), 'bottleneck_dim': (32,), 'non_linearity': 'swish', 'dropout_rate': 0.1, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.self',), 'bottleneck_dim': (32,), 'non_linearity': 'silu', 'dropout_rate': 0.3, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.self', 'output'), 'bottleneck_dim': (16, 256), 'non_linearity': 'leakyrelu', 'dropout_rate': 0.1, 'normalization': None, 'skip_connection': True}, 0, 0, {'insert_modules': ('attention.self', 'intermediate', 'attention.output'), 'bottleneck_dim': (32, 128, 32), 'non_linearity': 'leakyrelu', 'dropout_rate': 0.1, 'normalization': None, 'skip_connection': True}, 0, {'insert_modules': ('output', 'attention.output'), 'bottleneck_dim': (128, 32), 'non_linearity': 'gelu', 'dropout_rate': 0.25, 'normalization': 'layer_norm', 'skip_connection': True}, {'insert_modules': ('attention.self', 'output'), 'bottleneck_dim': (16, 128), 'non_linearity': 'gelu', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}]
[INFO|(OpenDelta)basemodel:700]2025-01-07 16:26:20,090 >> Trainable Ratio: 2770176/128699904=2.152431%
[INFO|(OpenDelta)basemodel:702]2025-01-07 16:26:20,090 >> Delta Parameter Ratio: 2770176/128699904=2.152431%
[INFO|(OpenDelta)basemodel:704]2025-01-07 16:26:20,090 >> Static Memory 0.99 GB, Max Memory 8.57 GB
INFO:name:3.15
INFO:name:***** Running training *****
INFO:name:  Num examples = 251820
INFO:name:  Num Epochs = 15
INFO:name:  Instantaneous batch size per GPU = 32
INFO:name:  Total train batch size  = 32
INFO:name:  Total optimization steps = 118050
INFO:name:epoch 0 step 100 loss 0.31367
INFO:name:epoch 0 step 200 loss 0.16032
INFO:name:epoch 0 step 300 loss 0.12798
INFO:name:epoch 0 step 400 loss 0.11508
INFO:name:epoch 0 step 500 loss 0.11015
INFO:name:epoch 0 step 600 loss 0.10969
INFO:name:epoch 0 step 700 loss 0.09433
INFO:name:epoch 0 step 800 loss 0.10215
INFO:name:epoch 0 step 900 loss 0.1029
INFO:name:epoch 0 step 1000 loss 0.09111
INFO:name:epoch 0 step 1100 loss 0.0843
INFO:name:epoch 0 step 1200 loss 0.10691
INFO:name:epoch 0 step 1300 loss 0.11082
INFO:name:epoch 0 step 1400 loss 0.10136
INFO:name:epoch 0 step 1500 loss 0.08637
INFO:name:epoch 0 step 1600 loss 0.07873
INFO:name:epoch 0 step 1700 loss 0.08123
INFO:name:epoch 0 step 1800 loss 0.10614
INFO:name:epoch 0 step 1900 loss 0.08752
INFO:name:epoch 0 step 2000 loss 0.08551
INFO:name:epoch 0 step 2100 loss 0.08234
INFO:name:epoch 0 step 2200 loss 0.08778
INFO:name:epoch 0 step 2300 loss 0.0861
INFO:name:epoch 0 step 2400 loss 0.07536
INFO:name:epoch 0 step 2500 loss 0.08856
INFO:name:epoch 0 step 2600 loss 0.07699
INFO:name:epoch 0 step 2700 loss 0.06515
INFO:name:epoch 0 step 2800 loss 0.07084
INFO:name:epoch 0 step 2900 loss 0.07871
INFO:name:epoch 0 step 3000 loss 0.08903
INFO:name:epoch 0 step 3100 loss 0.08678
INFO:name:epoch 0 step 3200 loss 0.07743
INFO:name:epoch 0 step 3300 loss 0.06993
INFO:name:epoch 0 step 3400 loss 0.08782
INFO:name:epoch 0 step 3500 loss 0.07073
INFO:name:epoch 0 step 3600 loss 0.08005
INFO:name:epoch 0 step 3700 loss 0.08853
INFO:name:epoch 0 step 3800 loss 0.06987
INFO:name:epoch 0 step 3900 loss 0.08224
INFO:name:epoch 0 step 4000 loss 0.07366
INFO:name:epoch 0 step 4100 loss 0.08866
INFO:name:epoch 0 step 4200 loss 0.07443
INFO:name:epoch 0 step 4300 loss 0.06778
INFO:name:epoch 0 step 4400 loss 0.08068
INFO:name:epoch 0 step 4500 loss 0.07619
INFO:name:epoch 0 step 4600 loss 0.07726
INFO:name:epoch 0 step 4700 loss 0.071
INFO:name:epoch 0 step 4800 loss 0.0681
INFO:name:epoch 0 step 4900 loss 0.07562
INFO:name:epoch 0 step 5000 loss 0.07164
INFO:name:epoch 0 step 5100 loss 0.07439
INFO:name:epoch 0 step 5200 loss 0.06292
INFO:name:epoch 0 step 5300 loss 0.07493
INFO:name:epoch 0 step 5400 loss 0.06572
INFO:name:epoch 0 step 5500 loss 0.07156
INFO:name:epoch 0 step 5600 loss 0.07286
INFO:name:epoch 0 step 5700 loss 0.06213
INFO:name:epoch 0 step 5800 loss 0.07539
INFO:name:epoch 0 step 5900 loss 0.08169
INFO:name:epoch 0 step 6000 loss 0.06757
INFO:name:epoch 0 step 6100 loss 0.07402
INFO:name:epoch 0 step 6200 loss 0.07814
INFO:name:epoch 0 step 6300 loss 0.07388
INFO:name:epoch 0 step 6400 loss 0.07009
INFO:name:epoch 0 step 6500 loss 0.06702
INFO:name:epoch 0 step 6600 loss 0.05934
INFO:name:epoch 0 step 6700 loss 0.07752
INFO:name:epoch 0 step 6800 loss 0.06053
INFO:name:epoch 0 step 6900 loss 0.06268
INFO:name:epoch 0 step 7000 loss 0.07614
INFO:name:epoch 0 step 7100 loss 0.08429
INFO:name:epoch 0 step 7200 loss 0.07521
INFO:name:epoch 0 step 7300 loss 0.06942
INFO:name:epoch 0 step 7400 loss 0.06621
INFO:name:epoch 0 step 7500 loss 0.05925
INFO:name:epoch 0 step 7600 loss 0.0705
INFO:name:epoch 0 step 7700 loss 0.0773
INFO:name:epoch 0 step 7800 loss 0.07184
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4219
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4219
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3591
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 1 step 100 loss 0.06032
INFO:name:epoch 1 step 200 loss 0.04505
INFO:name:epoch 1 step 300 loss 0.04393
INFO:name:epoch 1 step 400 loss 0.04018
INFO:name:epoch 1 step 500 loss 0.03992
INFO:name:epoch 1 step 600 loss 0.02976
INFO:name:epoch 1 step 700 loss 0.04305
INFO:name:epoch 1 step 800 loss 0.03916
INFO:name:epoch 1 step 900 loss 0.04482
INFO:name:epoch 1 step 1000 loss 0.04678
INFO:name:epoch 1 step 1100 loss 0.04057
INFO:name:epoch 1 step 1200 loss 0.04736
INFO:name:epoch 1 step 1300 loss 0.03669
INFO:name:epoch 1 step 1400 loss 0.0518
INFO:name:epoch 1 step 1500 loss 0.04089
INFO:name:epoch 1 step 1600 loss 0.04404
INFO:name:epoch 1 step 1700 loss 0.03472
INFO:name:epoch 1 step 1800 loss 0.04308
INFO:name:epoch 1 step 1900 loss 0.04255
INFO:name:epoch 1 step 2000 loss 0.04846
INFO:name:epoch 1 step 2100 loss 0.03764
INFO:name:epoch 1 step 2200 loss 0.04079
INFO:name:epoch 1 step 2300 loss 0.03662
INFO:name:epoch 1 step 2400 loss 0.04557
INFO:name:epoch 1 step 2500 loss 0.04103
INFO:name:epoch 1 step 2600 loss 0.04461
INFO:name:epoch 1 step 2700 loss 0.04062
INFO:name:epoch 1 step 2800 loss 0.04623
INFO:name:epoch 1 step 2900 loss 0.03686
INFO:name:epoch 1 step 3000 loss 0.04765
INFO:name:epoch 1 step 3100 loss 0.04047
INFO:name:epoch 1 step 3200 loss 0.04158
INFO:name:epoch 1 step 3300 loss 0.04375
INFO:name:epoch 1 step 3400 loss 0.04349
INFO:name:epoch 1 step 3500 loss 0.03985
INFO:name:epoch 1 step 3600 loss 0.0419
INFO:name:epoch 1 step 3700 loss 0.04347
INFO:name:epoch 1 step 3800 loss 0.03337
INFO:name:epoch 1 step 3900 loss 0.04432
INFO:name:epoch 1 step 4000 loss 0.04804
INFO:name:epoch 1 step 4100 loss 0.05351
INFO:name:epoch 1 step 4200 loss 0.04577
INFO:name:epoch 1 step 4300 loss 0.03638
INFO:name:epoch 1 step 4400 loss 0.04294
INFO:name:epoch 1 step 4500 loss 0.04231
INFO:name:epoch 1 step 4600 loss 0.03419
INFO:name:epoch 1 step 4700 loss 0.04113
INFO:name:epoch 1 step 4800 loss 0.03679
INFO:name:epoch 1 step 4900 loss 0.04479
INFO:name:epoch 1 step 5000 loss 0.05167
INFO:name:epoch 1 step 5100 loss 0.03965
INFO:name:epoch 1 step 5200 loss 0.04732
INFO:name:epoch 1 step 5300 loss 0.04572
INFO:name:epoch 1 step 5400 loss 0.05514
INFO:name:epoch 1 step 5500 loss 0.03574
INFO:name:epoch 1 step 5600 loss 0.03154
INFO:name:epoch 1 step 5700 loss 0.05116
INFO:name:epoch 1 step 5800 loss 0.039
INFO:name:epoch 1 step 5900 loss 0.0452
INFO:name:epoch 1 step 6000 loss 0.03795
INFO:name:epoch 1 step 6100 loss 0.04041
INFO:name:epoch 1 step 6200 loss 0.04379
INFO:name:epoch 1 step 6300 loss 0.03991
INFO:name:epoch 1 step 6400 loss 0.03317
INFO:name:epoch 1 step 6500 loss 0.04266
INFO:name:epoch 1 step 6600 loss 0.04317
INFO:name:epoch 1 step 6700 loss 0.03959
INFO:name:epoch 1 step 6800 loss 0.03927
INFO:name:epoch 1 step 6900 loss 0.04592
INFO:name:epoch 1 step 7000 loss 0.03809
INFO:name:epoch 1 step 7100 loss 0.03273
INFO:name:epoch 1 step 7200 loss 0.04903
INFO:name:epoch 1 step 7300 loss 0.04764
INFO:name:epoch 1 step 7400 loss 0.05405
INFO:name:epoch 1 step 7500 loss 0.04014
INFO:name:epoch 1 step 7600 loss 0.04573
INFO:name:epoch 1 step 7700 loss 0.05118
INFO:name:epoch 1 step 7800 loss 0.03441
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4569
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4569
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3938
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 2 step 100 loss 0.03612
INFO:name:epoch 2 step 200 loss 0.03449
INFO:name:epoch 2 step 300 loss 0.02889
INFO:name:epoch 2 step 400 loss 0.03257
INFO:name:epoch 2 step 500 loss 0.03089
INFO:name:epoch 2 step 600 loss 0.03054
INFO:name:epoch 2 step 700 loss 0.03192
INFO:name:epoch 2 step 800 loss 0.02989
INFO:name:epoch 2 step 900 loss 0.03947
INFO:name:epoch 2 step 1000 loss 0.0376
INFO:name:epoch 2 step 1100 loss 0.02688
INFO:name:epoch 2 step 1200 loss 0.02991
INFO:name:epoch 2 step 1300 loss 0.03135
INFO:name:epoch 2 step 1400 loss 0.03656
INFO:name:epoch 2 step 1500 loss 0.03239
INFO:name:epoch 2 step 1600 loss 0.02576
INFO:name:epoch 2 step 1700 loss 0.0298
INFO:name:epoch 2 step 1800 loss 0.03784
INFO:name:epoch 2 step 1900 loss 0.0361
INFO:name:epoch 2 step 2000 loss 0.03342
INFO:name:epoch 2 step 2100 loss 0.03202
INFO:name:epoch 2 step 2200 loss 0.03947
INFO:name:epoch 2 step 2300 loss 0.0269
INFO:name:epoch 2 step 2400 loss 0.03343
INFO:name:epoch 2 step 2500 loss 0.023
INFO:name:epoch 2 step 2600 loss 0.03872
INFO:name:epoch 2 step 2700 loss 0.03422
INFO:name:epoch 2 step 2800 loss 0.02831
INFO:name:epoch 2 step 2900 loss 0.0295
INFO:name:epoch 2 step 3000 loss 0.04058
INFO:name:epoch 2 step 3100 loss 0.03975
INFO:name:epoch 2 step 3200 loss 0.03278
INFO:name:epoch 2 step 3300 loss 0.03323
INFO:name:epoch 2 step 3400 loss 0.02809
INFO:name:epoch 2 step 3500 loss 0.03192
INFO:name:epoch 2 step 3600 loss 0.02781
INFO:name:epoch 2 step 3700 loss 0.02747
INFO:name:epoch 2 step 3800 loss 0.03354
INFO:name:epoch 2 step 3900 loss 0.03281
INFO:name:epoch 2 step 4000 loss 0.03408
INFO:name:epoch 2 step 4100 loss 0.03303
INFO:name:epoch 2 step 4200 loss 0.04447
INFO:name:epoch 2 step 4300 loss 0.03492
INFO:name:epoch 2 step 4400 loss 0.03198
INFO:name:epoch 2 step 4500 loss 0.02774
INFO:name:epoch 2 step 4600 loss 0.02616
INFO:name:epoch 2 step 4700 loss 0.03191
INFO:name:epoch 2 step 4800 loss 0.03656
INFO:name:epoch 2 step 4900 loss 0.0288
INFO:name:epoch 2 step 5000 loss 0.03142
INFO:name:epoch 2 step 5100 loss 0.02489
INFO:name:epoch 2 step 5200 loss 0.02933
INFO:name:epoch 2 step 5300 loss 0.02335
INFO:name:epoch 2 step 5400 loss 0.02904
INFO:name:epoch 2 step 5500 loss 0.02844
INFO:name:epoch 2 step 5600 loss 0.04551
INFO:name:epoch 2 step 5700 loss 0.02951
INFO:name:epoch 2 step 5800 loss 0.02489
INFO:name:epoch 2 step 5900 loss 0.03674
INFO:name:epoch 2 step 6000 loss 0.03048
INFO:name:epoch 2 step 6100 loss 0.02905
INFO:name:epoch 2 step 6200 loss 0.02923
INFO:name:epoch 2 step 6300 loss 0.03837
INFO:name:epoch 2 step 6400 loss 0.02759
INFO:name:epoch 2 step 6500 loss 0.03081
INFO:name:epoch 2 step 6600 loss 0.02908
INFO:name:epoch 2 step 6700 loss 0.02913
INFO:name:epoch 2 step 6800 loss 0.02878
INFO:name:epoch 2 step 6900 loss 0.02768
INFO:name:epoch 2 step 7000 loss 0.03012
INFO:name:epoch 2 step 7100 loss 0.02795
INFO:name:epoch 2 step 7200 loss 0.0335
INFO:name:epoch 2 step 7300 loss 0.02773
INFO:name:epoch 2 step 7400 loss 0.03484
INFO:name:epoch 2 step 7500 loss 0.03178
INFO:name:epoch 2 step 7600 loss 0.03191
INFO:name:epoch 2 step 7700 loss 0.03256
INFO:name:epoch 2 step 7800 loss 0.02651
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4453
INFO:name:epoch 3 step 100 loss 0.02477
INFO:name:epoch 3 step 200 loss 0.02454
INFO:name:epoch 3 step 300 loss 0.02986
INFO:name:epoch 3 step 400 loss 0.02454
INFO:name:epoch 3 step 500 loss 0.02764
INFO:name:epoch 3 step 600 loss 0.01872
INFO:name:epoch 3 step 700 loss 0.02048
INFO:name:epoch 3 step 800 loss 0.02316
INFO:name:epoch 3 step 900 loss 0.02147
INFO:name:epoch 3 step 1000 loss 0.0303
INFO:name:epoch 3 step 1100 loss 0.02672
INFO:name:epoch 3 step 1200 loss 0.02903
INFO:name:epoch 3 step 1300 loss 0.02494
INFO:name:epoch 3 step 1400 loss 0.02191
INFO:name:epoch 3 step 1500 loss 0.0216
INFO:name:epoch 3 step 1600 loss 0.02771
INFO:name:epoch 3 step 1700 loss 0.01933
INFO:name:epoch 3 step 1800 loss 0.02107
INFO:name:epoch 3 step 1900 loss 0.02462
INFO:name:epoch 3 step 2000 loss 0.01916
INFO:name:epoch 3 step 2100 loss 0.02763
INFO:name:epoch 3 step 2200 loss 0.02728
INFO:name:epoch 3 step 2300 loss 0.02574
INFO:name:epoch 3 step 2400 loss 0.02379
INFO:name:epoch 3 step 2500 loss 0.02064
INFO:name:epoch 3 step 2600 loss 0.02439
INFO:name:epoch 3 step 2700 loss 0.02063
INFO:name:epoch 3 step 2800 loss 0.02332
INFO:name:epoch 3 step 2900 loss 0.02283
INFO:name:epoch 3 step 3000 loss 0.02377
INFO:name:epoch 3 step 3100 loss 0.03045
INFO:name:epoch 3 step 3200 loss 0.02278
INFO:name:epoch 3 step 3300 loss 0.02315
INFO:name:epoch 3 step 3400 loss 0.03569
INFO:name:epoch 3 step 3500 loss 0.02286
INFO:name:epoch 3 step 3600 loss 0.01887
INFO:name:epoch 3 step 3700 loss 0.01802
INFO:name:epoch 3 step 3800 loss 0.02658
INFO:name:epoch 3 step 3900 loss 0.02601
INFO:name:epoch 3 step 4000 loss 0.03087
INFO:name:epoch 3 step 4100 loss 0.02853
INFO:name:epoch 3 step 4200 loss 0.02292
INFO:name:epoch 3 step 4300 loss 0.0268
INFO:name:epoch 3 step 4400 loss 0.02294
INFO:name:epoch 3 step 4500 loss 0.02381
INFO:name:epoch 3 step 4600 loss 0.02105
INFO:name:epoch 3 step 4700 loss 0.02498
INFO:name:epoch 3 step 4800 loss 0.02744
INFO:name:epoch 3 step 4900 loss 0.02495
INFO:name:epoch 3 step 5000 loss 0.02695
INFO:name:epoch 3 step 5100 loss 0.02303
INFO:name:epoch 3 step 5200 loss 0.03041
INFO:name:epoch 3 step 5300 loss 0.02165
INFO:name:epoch 3 step 5400 loss 0.02734
INFO:name:epoch 3 step 5500 loss 0.02825
INFO:name:epoch 3 step 5600 loss 0.0275
INFO:name:epoch 3 step 5700 loss 0.02637
INFO:name:epoch 3 step 5800 loss 0.01896
INFO:name:epoch 3 step 5900 loss 0.02373
INFO:name:epoch 3 step 6000 loss 0.02809
INFO:name:epoch 3 step 6100 loss 0.01941
INFO:name:epoch 3 step 6200 loss 0.0192
INFO:name:epoch 3 step 6300 loss 0.02131
INFO:name:epoch 3 step 6400 loss 0.02345
INFO:name:epoch 3 step 6500 loss 0.02309
INFO:name:epoch 3 step 6600 loss 0.03066
INFO:name:epoch 3 step 6700 loss 0.0253
INFO:name:epoch 3 step 6800 loss 0.02107
INFO:name:epoch 3 step 6900 loss 0.02387
INFO:name:epoch 3 step 7000 loss 0.02424
INFO:name:epoch 3 step 7100 loss 0.02419
INFO:name:epoch 3 step 7200 loss 0.02451
INFO:name:epoch 3 step 7300 loss 0.02336
INFO:name:epoch 3 step 7400 loss 0.02202
INFO:name:epoch 3 step 7500 loss 0.02128
INFO:name:epoch 3 step 7600 loss 0.01978
INFO:name:epoch 3 step 7700 loss 0.02626
INFO:name:epoch 3 step 7800 loss 0.02234
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4494
INFO:name:epoch 4 step 100 loss 0.02324
INFO:name:epoch 4 step 200 loss 0.01654
INFO:name:epoch 4 step 300 loss 0.01638
INFO:name:epoch 4 step 400 loss 0.01959
INFO:name:epoch 4 step 500 loss 0.01811
INFO:name:epoch 4 step 600 loss 0.01992
INFO:name:epoch 4 step 700 loss 0.01497
INFO:name:epoch 4 step 800 loss 0.01926
INFO:name:epoch 4 step 900 loss 0.01312
INFO:name:epoch 4 step 1000 loss 0.01924
INFO:name:epoch 4 step 1100 loss 0.01732
INFO:name:epoch 4 step 1200 loss 0.01722
INFO:name:epoch 4 step 1300 loss 0.01992
INFO:name:epoch 4 step 1400 loss 0.01678
INFO:name:epoch 4 step 1500 loss 0.02001
INFO:name:epoch 4 step 1600 loss 0.01844
INFO:name:epoch 4 step 1700 loss 0.01577
INFO:name:epoch 4 step 1800 loss 0.01578
INFO:name:epoch 4 step 1900 loss 0.01761
INFO:name:epoch 4 step 2000 loss 0.0231
INFO:name:epoch 4 step 2100 loss 0.0188
INFO:name:epoch 4 step 2200 loss 0.01638
INFO:name:epoch 4 step 2300 loss 0.0171
INFO:name:epoch 4 step 2400 loss 0.02084
INFO:name:epoch 4 step 2500 loss 0.01941
INFO:name:epoch 4 step 2600 loss 0.01864
INFO:name:epoch 4 step 2700 loss 0.01532
INFO:name:epoch 4 step 2800 loss 0.02216
INFO:name:epoch 4 step 2900 loss 0.01722
INFO:name:epoch 4 step 3000 loss 0.01957
INFO:name:epoch 4 step 3100 loss 0.01707
INFO:name:epoch 4 step 3200 loss 0.02314
INFO:name:epoch 4 step 3300 loss 0.01617
INFO:name:epoch 4 step 3400 loss 0.01797
INFO:name:epoch 4 step 3500 loss 0.01953
INFO:name:epoch 4 step 3600 loss 0.01569
INFO:name:epoch 4 step 3700 loss 0.02435
INFO:name:epoch 4 step 3800 loss 0.01723
INFO:name:epoch 4 step 3900 loss 0.01949
INFO:name:epoch 4 step 4000 loss 0.01839
INFO:name:epoch 4 step 4100 loss 0.01819
INFO:name:epoch 4 step 4200 loss 0.01662
INFO:name:epoch 4 step 4300 loss 0.02143
INFO:name:epoch 4 step 4400 loss 0.01768
INFO:name:epoch 4 step 4500 loss 0.01911
INFO:name:epoch 4 step 4600 loss 0.01929
INFO:name:epoch 4 step 4700 loss 0.01836
INFO:name:epoch 4 step 4800 loss 0.01476
INFO:name:epoch 4 step 4900 loss 0.02121
INFO:name:epoch 4 step 5000 loss 0.02094
INFO:name:epoch 4 step 5100 loss 0.01737
INFO:name:epoch 4 step 5200 loss 0.01861
INFO:name:epoch 4 step 5300 loss 0.01758
INFO:name:epoch 4 step 5400 loss 0.01961
INFO:name:epoch 4 step 5500 loss 0.02089
INFO:name:epoch 4 step 5600 loss 0.01872
INFO:name:epoch 4 step 5700 loss 0.0172
INFO:name:epoch 4 step 5800 loss 0.01806
INFO:name:epoch 4 step 5900 loss 0.0218
INFO:name:epoch 4 step 6000 loss 0.02349
INFO:name:epoch 4 step 6100 loss 0.02074
INFO:name:epoch 4 step 6200 loss 0.01709
INFO:name:epoch 4 step 6300 loss 0.02023
INFO:name:epoch 4 step 6400 loss 0.02314
INFO:name:epoch 4 step 6500 loss 0.01571
INFO:name:epoch 4 step 6600 loss 0.02122
INFO:name:epoch 4 step 6700 loss 0.01846
INFO:name:epoch 4 step 6800 loss 0.01668
INFO:name:epoch 4 step 6900 loss 0.02236
INFO:name:epoch 4 step 7000 loss 0.01679
INFO:name:epoch 4 step 7100 loss 0.02085
INFO:name:epoch 4 step 7200 loss 0.02287
INFO:name:epoch 4 step 7300 loss 0.02429
INFO:name:epoch 4 step 7400 loss 0.01718
INFO:name:epoch 4 step 7500 loss 0.01629
INFO:name:epoch 4 step 7600 loss 0.02103
INFO:name:epoch 4 step 7700 loss 0.02135
INFO:name:epoch 4 step 7800 loss 0.02404
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4475
INFO:name:epoch 5 step 100 loss 0.01552
INFO:name:epoch 5 step 200 loss 0.0114
INFO:name:epoch 5 step 300 loss 0.01564
INFO:name:epoch 5 step 400 loss 0.01273
INFO:name:epoch 5 step 500 loss 0.01568
INFO:name:epoch 5 step 600 loss 0.01584
INFO:name:epoch 5 step 700 loss 0.01452
INFO:name:epoch 5 step 800 loss 0.01568
INFO:name:epoch 5 step 900 loss 0.01711
INFO:name:epoch 5 step 1000 loss 0.01836
INFO:name:epoch 5 step 1100 loss 0.01502
INFO:name:epoch 5 step 1200 loss 0.01454
INFO:name:epoch 5 step 1300 loss 0.01457
INFO:name:epoch 5 step 1400 loss 0.01799
INFO:name:epoch 5 step 1500 loss 0.0137
INFO:name:epoch 5 step 1600 loss 0.01588
INFO:name:epoch 5 step 1700 loss 0.01425
INFO:name:epoch 5 step 1800 loss 0.01422
INFO:name:epoch 5 step 1900 loss 0.01535
INFO:name:epoch 5 step 2000 loss 0.01794
INFO:name:epoch 5 step 2100 loss 0.01538
INFO:name:epoch 5 step 2200 loss 0.01269
INFO:name:epoch 5 step 2300 loss 0.01305
INFO:name:epoch 5 step 2400 loss 0.0146
INFO:name:epoch 5 step 2500 loss 0.01742
INFO:name:epoch 5 step 2600 loss 0.01526
INFO:name:epoch 5 step 2700 loss 0.01631
INFO:name:epoch 5 step 2800 loss 0.01727
INFO:name:epoch 5 step 2900 loss 0.01837
INFO:name:epoch 5 step 3000 loss 0.01459
INFO:name:epoch 5 step 3100 loss 0.01519
INFO:name:epoch 5 step 3200 loss 0.01283
INFO:name:epoch 5 step 3300 loss 0.01728
INFO:name:epoch 5 step 3400 loss 0.01635
INFO:name:epoch 5 step 3500 loss 0.01208
INFO:name:epoch 5 step 3600 loss 0.01033
INFO:name:epoch 5 step 3700 loss 0.0146
INFO:name:epoch 5 step 3800 loss 0.01602
INFO:name:epoch 5 step 3900 loss 0.01694
INFO:name:epoch 5 step 4000 loss 0.01195
INFO:name:epoch 5 step 4100 loss 0.01205
INFO:name:epoch 5 step 4200 loss 0.01585
INFO:name:epoch 5 step 4300 loss 0.01415
INFO:name:epoch 5 step 4400 loss 0.01745
INFO:name:epoch 5 step 4500 loss 0.01863
INFO:name:epoch 5 step 4600 loss 0.0168
INFO:name:epoch 5 step 4700 loss 0.01561
INFO:name:epoch 5 step 4800 loss 0.01971
INFO:name:epoch 5 step 4900 loss 0.01934
INFO:name:epoch 5 step 5000 loss 0.01788
INFO:name:epoch 5 step 5100 loss 0.01415
INFO:name:epoch 5 step 5200 loss 0.01264
INFO:name:epoch 5 step 5300 loss 0.01828
INFO:name:epoch 5 step 5400 loss 0.0158
INFO:name:epoch 5 step 5500 loss 0.01567
INFO:name:epoch 5 step 5600 loss 0.01138
INFO:name:epoch 5 step 5700 loss 0.01589
INFO:name:epoch 5 step 5800 loss 0.01344
INFO:name:epoch 5 step 5900 loss 0.01288
INFO:name:epoch 5 step 6000 loss 0.0141
INFO:name:epoch 5 step 6100 loss 0.01484
INFO:name:epoch 5 step 6200 loss 0.0165
INFO:name:epoch 5 step 6300 loss 0.01942
INFO:name:epoch 5 step 6400 loss 0.01632
INFO:name:epoch 5 step 6500 loss 0.01479
INFO:name:epoch 5 step 6600 loss 0.01417
INFO:name:epoch 5 step 6700 loss 0.01417
INFO:name:epoch 5 step 6800 loss 0.01519
INFO:name:epoch 5 step 6900 loss 0.01152
INFO:name:epoch 5 step 7000 loss 0.014
INFO:name:epoch 5 step 7100 loss 0.01782
INFO:name:epoch 5 step 7200 loss 0.0184
INFO:name:epoch 5 step 7300 loss 0.01561
INFO:name:epoch 5 step 7400 loss 0.01708
INFO:name:epoch 5 step 7500 loss 0.01688
INFO:name:epoch 5 step 7600 loss 0.01809
INFO:name:epoch 5 step 7700 loss 0.0173
INFO:name:epoch 5 step 7800 loss 0.01508
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4416
INFO:name:epoch 6 step 100 loss 0.01487
INFO:name:epoch 6 step 200 loss 0.01138
INFO:name:epoch 6 step 300 loss 0.01121
INFO:name:epoch 6 step 400 loss 0.01062
INFO:name:epoch 6 step 500 loss 0.01032
INFO:name:epoch 6 step 600 loss 0.01452
INFO:name:epoch 6 step 700 loss 0.0134
INFO:name:epoch 6 step 800 loss 0.01007
INFO:name:epoch 6 step 900 loss 0.01398
INFO:name:epoch 6 step 1000 loss 0.0094
INFO:name:epoch 6 step 1100 loss 0.01228
INFO:name:epoch 6 step 1200 loss 0.01127
INFO:name:epoch 6 step 1300 loss 0.01222
INFO:name:epoch 6 step 1400 loss 0.00921
INFO:name:epoch 6 step 1500 loss 0.01134
INFO:name:epoch 6 step 1600 loss 0.01194
INFO:name:epoch 6 step 1700 loss 0.00868
INFO:name:epoch 6 step 1800 loss 0.01238
INFO:name:epoch 6 step 1900 loss 0.01071
INFO:name:epoch 6 step 2000 loss 0.00977
INFO:name:epoch 6 step 2100 loss 0.01119
INFO:name:epoch 6 step 2200 loss 0.01368
INFO:name:epoch 6 step 2300 loss 0.01203
INFO:name:epoch 6 step 2400 loss 0.01495
INFO:name:epoch 6 step 2500 loss 0.01153
INFO:name:epoch 6 step 2600 loss 0.014
INFO:name:epoch 6 step 2700 loss 0.01167
INFO:name:epoch 6 step 2800 loss 0.01153
INFO:name:epoch 6 step 2900 loss 0.01293
INFO:name:epoch 6 step 3000 loss 0.01372
INFO:name:epoch 6 step 3100 loss 0.01121
INFO:name:epoch 6 step 3200 loss 0.01647
INFO:name:epoch 6 step 3300 loss 0.01382
INFO:name:epoch 6 step 3400 loss 0.01283
INFO:name:epoch 6 step 3500 loss 0.00971
INFO:name:epoch 6 step 3600 loss 0.01188
INFO:name:epoch 6 step 3700 loss 0.01508
INFO:name:epoch 6 step 3800 loss 0.0124
INFO:name:epoch 6 step 3900 loss 0.01414
INFO:name:epoch 6 step 4000 loss 0.01208
INFO:name:epoch 6 step 4100 loss 0.01184
INFO:name:epoch 6 step 4200 loss 0.01147
INFO:name:epoch 6 step 4300 loss 0.01254
INFO:name:epoch 6 step 4400 loss 0.01311
INFO:name:epoch 6 step 4500 loss 0.01187
INFO:name:epoch 6 step 4600 loss 0.01413
INFO:name:epoch 6 step 4700 loss 0.01416
INFO:name:epoch 6 step 4800 loss 0.0158
INFO:name:epoch 6 step 4900 loss 0.01066
INFO:name:epoch 6 step 5000 loss 0.0136
INFO:name:epoch 6 step 5100 loss 0.01433
INFO:name:epoch 6 step 5200 loss 0.01406
INFO:name:epoch 6 step 5300 loss 0.01582
INFO:name:epoch 6 step 5400 loss 0.01164
INFO:name:epoch 6 step 5500 loss 0.00811
INFO:name:epoch 6 step 5600 loss 0.0131
INFO:name:epoch 6 step 5700 loss 0.01329
INFO:name:epoch 6 step 5800 loss 0.01279
INFO:name:epoch 6 step 5900 loss 0.01428
INFO:name:epoch 6 step 6000 loss 0.0109
INFO:name:epoch 6 step 6100 loss 0.0139
INFO:name:epoch 6 step 6200 loss 0.01147
INFO:name:epoch 6 step 6300 loss 0.01232
INFO:name:epoch 6 step 6400 loss 0.00887
INFO:name:epoch 6 step 6500 loss 0.01255
INFO:name:epoch 6 step 6600 loss 0.01356
INFO:name:epoch 6 step 6700 loss 0.01307
INFO:name:epoch 6 step 6800 loss 0.01389
INFO:name:epoch 6 step 6900 loss 0.014
INFO:name:epoch 6 step 7000 loss 0.01438
INFO:name:epoch 6 step 7100 loss 0.01228
INFO:name:epoch 6 step 7200 loss 0.01228
INFO:name:epoch 6 step 7300 loss 0.01278
INFO:name:epoch 6 step 7400 loss 0.01397
INFO:name:epoch 6 step 7500 loss 0.01644
INFO:name:epoch 6 step 7600 loss 0.01062
INFO:name:epoch 6 step 7700 loss 0.01594
INFO:name:epoch 6 step 7800 loss 0.01377
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4453
INFO:name:epoch 7 step 100 loss 0.0115
INFO:name:epoch 7 step 200 loss 0.01253
INFO:name:epoch 7 step 300 loss 0.01162
INFO:name:epoch 7 step 400 loss 0.00913
INFO:name:epoch 7 step 500 loss 0.00975
INFO:name:epoch 7 step 600 loss 0.01026
INFO:name:epoch 7 step 700 loss 0.01177
INFO:name:epoch 7 step 800 loss 0.01239
INFO:name:epoch 7 step 900 loss 0.01375
INFO:name:epoch 7 step 1000 loss 0.01198
INFO:name:epoch 7 step 1100 loss 0.0097
INFO:name:epoch 7 step 1200 loss 0.01123
INFO:name:epoch 7 step 1300 loss 0.01063
INFO:name:epoch 7 step 1400 loss 0.00932
INFO:name:epoch 7 step 1500 loss 0.0082
INFO:name:epoch 7 step 1600 loss 0.00691
INFO:name:epoch 7 step 1700 loss 0.00961
INFO:name:epoch 7 step 1800 loss 0.00933
INFO:name:epoch 7 step 1900 loss 0.01035
INFO:name:epoch 7 step 2000 loss 0.00791
INFO:name:epoch 7 step 2100 loss 0.0106
INFO:name:epoch 7 step 2200 loss 0.01003
INFO:name:epoch 7 step 2300 loss 0.00886
INFO:name:epoch 7 step 2400 loss 0.00826
INFO:name:epoch 7 step 2500 loss 0.01138
INFO:name:epoch 7 step 2600 loss 0.0078
INFO:name:epoch 7 step 2700 loss 0.01089
INFO:name:epoch 7 step 2800 loss 0.01082
INFO:name:epoch 7 step 2900 loss 0.00946
INFO:name:epoch 7 step 3000 loss 0.00852
INFO:name:epoch 7 step 3100 loss 0.0099
INFO:name:epoch 7 step 3200 loss 0.00931
INFO:name:epoch 7 step 3300 loss 0.0114
INFO:name:epoch 7 step 3400 loss 0.01001
INFO:name:epoch 7 step 3500 loss 0.011
INFO:name:epoch 7 step 3600 loss 0.01031
INFO:name:epoch 7 step 3700 loss 0.01038
INFO:name:epoch 7 step 3800 loss 0.01214
INFO:name:epoch 7 step 3900 loss 0.01099
INFO:name:epoch 7 step 4000 loss 0.00862
INFO:name:epoch 7 step 4100 loss 0.01191
INFO:name:epoch 7 step 4200 loss 0.00919
INFO:name:epoch 7 step 4300 loss 0.00943
INFO:name:epoch 7 step 4400 loss 0.01085
INFO:name:epoch 7 step 4500 loss 0.01157
INFO:name:epoch 7 step 4600 loss 0.00925
INFO:name:epoch 7 step 4700 loss 0.01369
INFO:name:epoch 7 step 4800 loss 0.01281
INFO:name:epoch 7 step 4900 loss 0.00932
INFO:name:epoch 7 step 5000 loss 0.00832
INFO:name:epoch 7 step 5100 loss 0.01034
INFO:name:epoch 7 step 5200 loss 0.01248
INFO:name:epoch 7 step 5300 loss 0.01112
INFO:name:epoch 7 step 5400 loss 0.01023
INFO:name:epoch 7 step 5500 loss 0.01165
INFO:name:epoch 7 step 5600 loss 0.0125
INFO:name:epoch 7 step 5700 loss 0.00852
INFO:name:epoch 7 step 5800 loss 0.00986
INFO:name:epoch 7 step 5900 loss 0.00923
INFO:name:epoch 7 step 6000 loss 0.01151
INFO:name:epoch 7 step 6100 loss 0.01024
INFO:name:epoch 7 step 6200 loss 0.00876
INFO:name:epoch 7 step 6300 loss 0.01206
INFO:name:epoch 7 step 6400 loss 0.01063
INFO:name:epoch 7 step 6500 loss 0.00952
INFO:name:epoch 7 step 6600 loss 0.01316
INFO:name:epoch 7 step 6700 loss 0.0092
INFO:name:epoch 7 step 6800 loss 0.01089
INFO:name:epoch 7 step 6900 loss 0.01493
INFO:name:epoch 7 step 7000 loss 0.0142
INFO:name:epoch 7 step 7100 loss 0.01004
INFO:name:epoch 7 step 7200 loss 0.0104
INFO:name:epoch 7 step 7300 loss 0.00953
INFO:name:epoch 7 step 7400 loss 0.01223
INFO:name:epoch 7 step 7500 loss 0.01238
INFO:name:epoch 7 step 7600 loss 0.01224
INFO:name:epoch 7 step 7700 loss 0.0121
INFO:name:epoch 7 step 7800 loss 0.01203
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4541
INFO:name:epoch 8 step 100 loss 0.00859
INFO:name:epoch 8 step 200 loss 0.00949
INFO:name:epoch 8 step 300 loss 0.00834
INFO:name:epoch 8 step 400 loss 0.01165
INFO:name:epoch 8 step 500 loss 0.00672
INFO:name:epoch 8 step 600 loss 0.00952
INFO:name:epoch 8 step 700 loss 0.01323
INFO:name:epoch 8 step 800 loss 0.00734
INFO:name:epoch 8 step 900 loss 0.00876
INFO:name:epoch 8 step 1000 loss 0.01277
INFO:name:epoch 8 step 1100 loss 0.00898
INFO:name:epoch 8 step 1200 loss 0.00847
INFO:name:epoch 8 step 1300 loss 0.01077
INFO:name:epoch 8 step 1400 loss 0.00809
INFO:name:epoch 8 step 1500 loss 0.00777
INFO:name:epoch 8 step 1600 loss 0.01323
