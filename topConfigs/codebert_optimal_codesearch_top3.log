/home/aakli/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
INFO:name:device: cuda:1, n_gpu: 1
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /microsoft/codebert-base/resolve/main/config.json HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /microsoft/codebert-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
INFO:name:Preparing the code search Dataset...

INFO:name:Preparing the code search Dataset...

INFO:name:Preparing the code search Dataset...

INFO:name:[{'insert_modules': ('output',), 'bottleneck_dim': (256,), 'non_linearity': 'relu', 'dropout_rate': 0.2, 'normalization': None, 'skip_connection': True}, 0, 0, 0, {'insert_modules': ('output', 'attention.self', 'attention.output'), 'bottleneck_dim': (128, 32, 32), 'non_linearity': 'relu', 'dropout_rate': 0.15, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.output', 'output', 'intermediate'), 'bottleneck_dim': (64, 128, 64), 'non_linearity': 'leakyrelu', 'dropout_rate': 0.15, 'normalization': None, 'skip_connection': True}, 0, 0, 0, 0, 0, {'insert_modules': ('intermediate', 'attention.self', 'output'), 'bottleneck_dim': (128, 32, 256), 'non_linearity': 'gelu_new', 'dropout_rate': 0.25, 'normalization': None, 'skip_connection': True}]
[INFO|(OpenDelta)basemodel:700]2025-01-09 16:11:34,679 >> Trainable Ratio: 2618464/127264096=2.057504%
[INFO|(OpenDelta)basemodel:702]2025-01-09 16:11:34,679 >> Delta Parameter Ratio: 2618464/127264096=2.057504%
[INFO|(OpenDelta)basemodel:704]2025-01-09 16:11:34,679 >> Static Memory 0.00 GB, Max Memory 0.00 GB
INFO:name:2.9899999999999998
/home/aakli/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:name:***** Running training *****
INFO:name:  Num examples = 251820
INFO:name:  Num Epochs = 15
INFO:name:  Instantaneous batch size per GPU = 32
INFO:name:  Total train batch size  = 32
INFO:name:  Total optimization steps = 118050
INFO:name:epoch 0 step 100 loss 3.02
INFO:name:epoch 0 step 200 loss 0.73301
INFO:name:epoch 0 step 300 loss 0.35675
INFO:name:epoch 0 step 400 loss 0.27163
INFO:name:epoch 0 step 500 loss 0.22246
INFO:name:epoch 0 step 600 loss 0.21743
INFO:name:epoch 0 step 700 loss 0.22079
INFO:name:epoch 0 step 800 loss 0.19681
INFO:name:epoch 0 step 900 loss 0.1739
INFO:name:epoch 0 step 1000 loss 0.2048
INFO:name:epoch 0 step 1100 loss 0.17134
INFO:name:epoch 0 step 1200 loss 0.16419
INFO:name:epoch 0 step 1300 loss 0.1691
INFO:name:epoch 0 step 1400 loss 0.1527
INFO:name:epoch 0 step 1500 loss 0.15889
INFO:name:epoch 0 step 1600 loss 0.16655
INFO:name:epoch 0 step 1700 loss 0.14438
INFO:name:epoch 0 step 1800 loss 0.15088
INFO:name:epoch 0 step 1900 loss 0.16
INFO:name:epoch 0 step 2000 loss 0.13487
INFO:name:epoch 0 step 2100 loss 0.16456
INFO:name:epoch 0 step 2200 loss 0.14677
INFO:name:epoch 0 step 2300 loss 0.15219
INFO:name:epoch 0 step 2400 loss 0.13864
INFO:name:epoch 0 step 2500 loss 0.13319
INFO:name:epoch 0 step 2600 loss 0.14226
INFO:name:epoch 0 step 2700 loss 0.13507
INFO:name:epoch 0 step 2800 loss 0.14435
INFO:name:epoch 0 step 2900 loss 0.14809
INFO:name:epoch 0 step 3000 loss 0.13528
INFO:name:epoch 0 step 3100 loss 0.13167
INFO:name:epoch 0 step 3200 loss 0.13317
INFO:name:epoch 0 step 3300 loss 0.14261
INFO:name:epoch 0 step 3400 loss 0.14151
INFO:name:epoch 0 step 3500 loss 0.1249
INFO:name:epoch 0 step 3600 loss 0.15416
INFO:name:epoch 0 step 3700 loss 0.13736
INFO:name:epoch 0 step 3800 loss 0.13622
INFO:name:epoch 0 step 3900 loss 0.12775
INFO:name:epoch 0 step 4000 loss 0.14224
INFO:name:epoch 0 step 4100 loss 0.12728
INFO:name:epoch 0 step 4200 loss 0.10365
INFO:name:epoch 0 step 4300 loss 0.14328
INFO:name:epoch 0 step 4400 loss 0.13035
INFO:name:epoch 0 step 4500 loss 0.1172
INFO:name:epoch 0 step 4600 loss 0.11793
INFO:name:epoch 0 step 4700 loss 0.13313
INFO:name:epoch 0 step 4800 loss 0.12659
INFO:name:epoch 0 step 4900 loss 0.1067
INFO:name:epoch 0 step 5000 loss 0.12136
INFO:name:epoch 0 step 5100 loss 0.12417
INFO:name:epoch 0 step 5200 loss 0.1039
INFO:name:epoch 0 step 5300 loss 0.10707
INFO:name:epoch 0 step 5400 loss 0.13654
INFO:name:epoch 0 step 5500 loss 0.11956
INFO:name:epoch 0 step 5600 loss 0.11181
INFO:name:epoch 0 step 5700 loss 0.11574
INFO:name:epoch 0 step 5800 loss 0.12328
INFO:name:epoch 0 step 5900 loss 0.12799
INFO:name:epoch 0 step 6000 loss 0.12825
INFO:name:epoch 0 step 6100 loss 0.13472
INFO:name:epoch 0 step 6200 loss 0.11796
INFO:name:epoch 0 step 6300 loss 0.10742
INFO:name:epoch 0 step 6400 loss 0.10251
INFO:name:epoch 0 step 6500 loss 0.11387
INFO:name:epoch 0 step 6600 loss 0.11728
INFO:name:epoch 0 step 6700 loss 0.09981
INFO:name:epoch 0 step 6800 loss 0.12079
INFO:name:epoch 0 step 6900 loss 0.10991
INFO:name:epoch 0 step 7000 loss 0.11139
INFO:name:epoch 0 step 7100 loss 0.12643
INFO:name:epoch 0 step 7200 loss 0.09798
INFO:name:epoch 0 step 7300 loss 0.11432
INFO:name:epoch 0 step 7400 loss 0.12279
INFO:name:epoch 0 step 7500 loss 0.11478
INFO:name:epoch 0 step 7600 loss 0.11028
INFO:name:epoch 0 step 7700 loss 0.10453
INFO:name:epoch 0 step 7800 loss 0.11017
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3604
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3604
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3009
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 1 step 100 loss 0.09735
INFO:name:epoch 1 step 200 loss 0.07615
INFO:name:epoch 1 step 300 loss 0.05406
INFO:name:epoch 1 step 400 loss 0.06645
INFO:name:epoch 1 step 500 loss 0.07099
INFO:name:epoch 1 step 600 loss 0.07061
INFO:name:epoch 1 step 700 loss 0.07454
INFO:name:epoch 1 step 800 loss 0.05771
INFO:name:epoch 1 step 900 loss 0.07007
INFO:name:epoch 1 step 1000 loss 0.07884
INFO:name:epoch 1 step 1100 loss 0.05832
INFO:name:epoch 1 step 1200 loss 0.06777
INFO:name:epoch 1 step 1300 loss 0.0619
INFO:name:epoch 1 step 1400 loss 0.05092
INFO:name:epoch 1 step 1500 loss 0.06959
INFO:name:epoch 1 step 1600 loss 0.0643
INFO:name:epoch 1 step 1700 loss 0.0657
INFO:name:epoch 1 step 1800 loss 0.08238
INFO:name:epoch 1 step 1900 loss 0.0646
INFO:name:epoch 1 step 2000 loss 0.06742
INFO:name:epoch 1 step 2100 loss 0.08551
INFO:name:epoch 1 step 2200 loss 0.06144
INFO:name:epoch 1 step 2300 loss 0.0841
INFO:name:epoch 1 step 2400 loss 0.06622
INFO:name:epoch 1 step 2500 loss 0.07133
INFO:name:epoch 1 step 2600 loss 0.06379
INFO:name:epoch 1 step 2700 loss 0.07588
INFO:name:epoch 1 step 2800 loss 0.06974
INFO:name:epoch 1 step 2900 loss 0.07615
INFO:name:epoch 1 step 3000 loss 0.06585
INFO:name:epoch 1 step 3100 loss 0.0669
INFO:name:epoch 1 step 3200 loss 0.07656
INFO:name:epoch 1 step 3300 loss 0.06343
INFO:name:epoch 1 step 3400 loss 0.06548
INFO:name:epoch 1 step 3500 loss 0.05794
INFO:name:epoch 1 step 3600 loss 0.06262
INFO:name:epoch 1 step 3700 loss 0.06918
INFO:name:epoch 1 step 3800 loss 0.06848
INFO:name:epoch 1 step 3900 loss 0.07413
INFO:name:epoch 1 step 4000 loss 0.05565
INFO:name:epoch 1 step 4100 loss 0.07883
INFO:name:epoch 1 step 4200 loss 0.06427
INFO:name:epoch 1 step 4300 loss 0.07593
INFO:name:epoch 1 step 4400 loss 0.07219
INFO:name:epoch 1 step 4500 loss 0.06904
INFO:name:epoch 1 step 4600 loss 0.06622
INFO:name:epoch 1 step 4700 loss 0.05242
INFO:name:epoch 1 step 4800 loss 0.07569
INFO:name:epoch 1 step 4900 loss 0.05942
INFO:name:epoch 1 step 5000 loss 0.057
INFO:name:epoch 1 step 5100 loss 0.06279
INFO:name:epoch 1 step 5200 loss 0.06723
INFO:name:epoch 1 step 5300 loss 0.06715
INFO:name:epoch 1 step 5400 loss 0.06628
INFO:name:epoch 1 step 5500 loss 0.06694
INFO:name:epoch 1 step 5600 loss 0.06355
INFO:name:epoch 1 step 5700 loss 0.05775
INFO:name:epoch 1 step 5800 loss 0.07217
INFO:name:epoch 1 step 5900 loss 0.07653
INFO:name:epoch 1 step 6000 loss 0.07024
INFO:name:epoch 1 step 6100 loss 0.07795
INFO:name:epoch 1 step 6200 loss 0.05727
INFO:name:epoch 1 step 6300 loss 0.07239
INFO:name:epoch 1 step 6400 loss 0.05151
INFO:name:epoch 1 step 6500 loss 0.07795
INFO:name:epoch 1 step 6600 loss 0.07545
INFO:name:epoch 1 step 6700 loss 0.06186
INFO:name:epoch 1 step 6800 loss 0.06894
INFO:name:epoch 1 step 6900 loss 0.06915
INFO:name:epoch 1 step 7000 loss 0.08063
INFO:name:epoch 1 step 7100 loss 0.06689
INFO:name:epoch 1 step 7200 loss 0.07461
INFO:name:epoch 1 step 7300 loss 0.06006
INFO:name:epoch 1 step 7400 loss 0.06366
INFO:name:epoch 1 step 7500 loss 0.05798
INFO:name:epoch 1 step 7600 loss 0.05502
INFO:name:epoch 1 step 7700 loss 0.06854
INFO:name:epoch 1 step 7800 loss 0.07042
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3895
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3895
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3271
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 2 step 100 loss 0.05496
INFO:name:epoch 2 step 200 loss 0.05319
INFO:name:epoch 2 step 300 loss 0.05428
INFO:name:epoch 2 step 400 loss 0.05466
INFO:name:epoch 2 step 500 loss 0.05794
INFO:name:epoch 2 step 600 loss 0.04222
INFO:name:epoch 2 step 700 loss 0.04338
INFO:name:epoch 2 step 800 loss 0.05079
INFO:name:epoch 2 step 900 loss 0.04331
INFO:name:epoch 2 step 1000 loss 0.04501
INFO:name:epoch 2 step 1100 loss 0.05891
INFO:name:epoch 2 step 1200 loss 0.05625
INFO:name:epoch 2 step 1300 loss 0.05802
INFO:name:epoch 2 step 1400 loss 0.04271
INFO:name:epoch 2 step 1500 loss 0.05306
INFO:name:epoch 2 step 1600 loss 0.0412
INFO:name:epoch 2 step 1700 loss 0.04471
INFO:name:epoch 2 step 1800 loss 0.04638
INFO:name:epoch 2 step 1900 loss 0.04088
INFO:name:epoch 2 step 2000 loss 0.05478
INFO:name:epoch 2 step 2100 loss 0.05545
INFO:name:epoch 2 step 2200 loss 0.06102
INFO:name:epoch 2 step 2300 loss 0.06468
INFO:name:epoch 2 step 2400 loss 0.05047
INFO:name:epoch 2 step 2500 loss 0.05054
INFO:name:epoch 2 step 2600 loss 0.04967
INFO:name:epoch 2 step 2700 loss 0.05786
INFO:name:epoch 2 step 2800 loss 0.05264
INFO:name:epoch 2 step 2900 loss 0.05016
INFO:name:epoch 2 step 3000 loss 0.05079
INFO:name:epoch 2 step 3100 loss 0.04567
INFO:name:epoch 2 step 3200 loss 0.04578
INFO:name:epoch 2 step 3300 loss 0.05043
INFO:name:epoch 2 step 3400 loss 0.04925
INFO:name:epoch 2 step 3500 loss 0.05219
INFO:name:epoch 2 step 3600 loss 0.04696
INFO:name:epoch 2 step 3700 loss 0.04848
INFO:name:epoch 2 step 3800 loss 0.04449
INFO:name:epoch 2 step 3900 loss 0.04606
INFO:name:epoch 2 step 4000 loss 0.04396
INFO:name:epoch 2 step 4100 loss 0.05676
INFO:name:epoch 2 step 4200 loss 0.04569
INFO:name:epoch 2 step 4300 loss 0.04571
INFO:name:epoch 2 step 4400 loss 0.04959
INFO:name:epoch 2 step 4500 loss 0.04173
INFO:name:epoch 2 step 4600 loss 0.04606
INFO:name:epoch 2 step 4700 loss 0.0591
INFO:name:epoch 2 step 4800 loss 0.05956
INFO:name:epoch 2 step 4900 loss 0.05218
INFO:name:epoch 2 step 5000 loss 0.04866
INFO:name:epoch 2 step 5100 loss 0.05376
INFO:name:epoch 2 step 5200 loss 0.05645
INFO:name:epoch 2 step 5300 loss 0.06747
INFO:name:epoch 2 step 5400 loss 0.04861
INFO:name:epoch 2 step 5500 loss 0.05578
INFO:name:epoch 2 step 5600 loss 0.05322
INFO:name:epoch 2 step 5700 loss 0.06078
INFO:name:epoch 2 step 5800 loss 0.04295
INFO:name:epoch 2 step 5900 loss 0.06325
INFO:name:epoch 2 step 6000 loss 0.04458
INFO:name:epoch 2 step 6100 loss 0.04636
INFO:name:epoch 2 step 6200 loss 0.04355
INFO:name:epoch 2 step 6300 loss 0.04901
INFO:name:epoch 2 step 6400 loss 0.05406
INFO:name:epoch 2 step 6500 loss 0.04325
INFO:name:epoch 2 step 6600 loss 0.05384
INFO:name:epoch 2 step 6700 loss 0.0402
INFO:name:epoch 2 step 6800 loss 0.04315
INFO:name:epoch 2 step 6900 loss 0.05356
INFO:name:epoch 2 step 7000 loss 0.06046
INFO:name:epoch 2 step 7100 loss 0.05941
INFO:name:epoch 2 step 7200 loss 0.05308
INFO:name:epoch 2 step 7300 loss 0.05793
INFO:name:epoch 2 step 7400 loss 0.05388
INFO:name:epoch 2 step 7500 loss 0.06168
INFO:name:epoch 2 step 7600 loss 0.04179
INFO:name:epoch 2 step 7700 loss 0.05745
INFO:name:epoch 2 step 7800 loss 0.05477
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3785
INFO:name:epoch 3 step 100 loss 0.04559
INFO:name:epoch 3 step 200 loss 0.03361
INFO:name:epoch 3 step 300 loss 0.0342
INFO:name:epoch 3 step 400 loss 0.03389
INFO:name:epoch 3 step 500 loss 0.03008
INFO:name:epoch 3 step 600 loss 0.03873
INFO:name:epoch 3 step 700 loss 0.03391
INFO:name:epoch 3 step 800 loss 0.04519
INFO:name:epoch 3 step 900 loss 0.03497
INFO:name:epoch 3 step 1000 loss 0.03986
INFO:name:epoch 3 step 1100 loss 0.04511
INFO:name:epoch 3 step 1200 loss 0.03463
INFO:name:epoch 3 step 1300 loss 0.03745
INFO:name:epoch 3 step 1400 loss 0.03812
INFO:name:epoch 3 step 1500 loss 0.03426
INFO:name:epoch 3 step 1600 loss 0.04137
INFO:name:epoch 3 step 1700 loss 0.03723
INFO:name:epoch 3 step 1800 loss 0.03383
INFO:name:epoch 3 step 1900 loss 0.03576
INFO:name:epoch 3 step 2000 loss 0.03977
INFO:name:epoch 3 step 2100 loss 0.03077
INFO:name:epoch 3 step 2200 loss 0.03776
INFO:name:epoch 3 step 2300 loss 0.03125
INFO:name:epoch 3 step 2400 loss 0.0407
INFO:name:epoch 3 step 2500 loss 0.03966
INFO:name:epoch 3 step 2600 loss 0.0427
INFO:name:epoch 3 step 2700 loss 0.03532
INFO:name:epoch 3 step 2800 loss 0.03998
INFO:name:epoch 3 step 2900 loss 0.03789
INFO:name:epoch 3 step 3000 loss 0.0421
INFO:name:epoch 3 step 3100 loss 0.03451
INFO:name:epoch 3 step 3200 loss 0.03586
INFO:name:epoch 3 step 3300 loss 0.03698
INFO:name:epoch 3 step 3400 loss 0.03711
INFO:name:epoch 3 step 3500 loss 0.03982
INFO:name:epoch 3 step 3600 loss 0.04116
INFO:name:epoch 3 step 3700 loss 0.03943
INFO:name:epoch 3 step 3800 loss 0.03882
INFO:name:epoch 3 step 3900 loss 0.04108
INFO:name:epoch 3 step 4000 loss 0.03825
INFO:name:epoch 3 step 4100 loss 0.03002
INFO:name:epoch 3 step 4200 loss 0.04005
INFO:name:epoch 3 step 4300 loss 0.04178
INFO:name:epoch 3 step 4400 loss 0.04323
INFO:name:epoch 3 step 4500 loss 0.03531
INFO:name:epoch 3 step 4600 loss 0.04084
INFO:name:epoch 3 step 4700 loss 0.04413
INFO:name:epoch 3 step 4800 loss 0.03954
INFO:name:epoch 3 step 4900 loss 0.032
INFO:name:epoch 3 step 5000 loss 0.03701
INFO:name:epoch 3 step 5100 loss 0.03882
INFO:name:epoch 3 step 5200 loss 0.04374
INFO:name:epoch 3 step 5300 loss 0.03609
INFO:name:epoch 3 step 5400 loss 0.04546
INFO:name:epoch 3 step 5500 loss 0.04015
INFO:name:epoch 3 step 5600 loss 0.0513
INFO:name:epoch 3 step 5700 loss 0.03756
INFO:name:epoch 3 step 5800 loss 0.03633
INFO:name:epoch 3 step 5900 loss 0.03655
INFO:name:epoch 3 step 6000 loss 0.03922
INFO:name:epoch 3 step 6100 loss 0.04168
INFO:name:epoch 3 step 6200 loss 0.03617
INFO:name:epoch 3 step 6300 loss 0.04019
INFO:name:epoch 3 step 6400 loss 0.04501
INFO:name:epoch 3 step 6500 loss 0.03938
INFO:name:epoch 3 step 6600 loss 0.04068
INFO:name:epoch 3 step 6700 loss 0.03635
INFO:name:epoch 3 step 6800 loss 0.03318
INFO:name:epoch 3 step 6900 loss 0.04165
INFO:name:epoch 3 step 7000 loss 0.04313
INFO:name:epoch 3 step 7100 loss 0.03501
INFO:name:epoch 3 step 7200 loss 0.03245
INFO:name:epoch 3 step 7300 loss 0.04621
INFO:name:epoch 3 step 7400 loss 0.03901
INFO:name:epoch 3 step 7500 loss 0.04652
INFO:name:epoch 3 step 7600 loss 0.03658
INFO:name:epoch 3 step 7700 loss 0.03741
INFO:name:epoch 3 step 7800 loss 0.04539
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3912
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3912
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3263
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 4 step 100 loss 0.03034
INFO:name:epoch 4 step 200 loss 0.02152
INFO:name:epoch 4 step 300 loss 0.02538
INFO:name:epoch 4 step 400 loss 0.02631
INFO:name:epoch 4 step 500 loss 0.02925
INFO:name:epoch 4 step 600 loss 0.02274
INFO:name:epoch 4 step 700 loss 0.03196
INFO:name:epoch 4 step 800 loss 0.03311
INFO:name:epoch 4 step 900 loss 0.02835
INFO:name:epoch 4 step 1000 loss 0.03206
INFO:name:epoch 4 step 1100 loss 0.02456
INFO:name:epoch 4 step 1200 loss 0.03074
INFO:name:epoch 4 step 1300 loss 0.02969
INFO:name:epoch 4 step 1400 loss 0.02543
INFO:name:epoch 4 step 1500 loss 0.03164
INFO:name:epoch 4 step 1600 loss 0.02815
INFO:name:epoch 4 step 1700 loss 0.02556
INFO:name:epoch 4 step 1800 loss 0.03106
INFO:name:epoch 4 step 1900 loss 0.03395
INFO:name:epoch 4 step 2000 loss 0.02645
INFO:name:epoch 4 step 2100 loss 0.02851
INFO:name:epoch 4 step 2200 loss 0.02718
INFO:name:epoch 4 step 2300 loss 0.02713
INFO:name:epoch 4 step 2400 loss 0.02906
INFO:name:epoch 4 step 2500 loss 0.03439
INFO:name:epoch 4 step 2600 loss 0.03345
INFO:name:epoch 4 step 2700 loss 0.03233
INFO:name:epoch 4 step 2800 loss 0.03036
INFO:name:epoch 4 step 2900 loss 0.03149
INFO:name:epoch 4 step 3000 loss 0.02413
INFO:name:epoch 4 step 3100 loss 0.02695
INFO:name:epoch 4 step 3200 loss 0.02835
INFO:name:epoch 4 step 3300 loss 0.02347
INFO:name:epoch 4 step 3400 loss 0.02994
INFO:name:epoch 4 step 3500 loss 0.03417
INFO:name:epoch 4 step 3600 loss 0.02482
INFO:name:epoch 4 step 3700 loss 0.03612
INFO:name:epoch 4 step 3800 loss 0.029
INFO:name:epoch 4 step 3900 loss 0.02661
INFO:name:epoch 4 step 4000 loss 0.02572
INFO:name:epoch 4 step 4100 loss 0.03249
INFO:name:epoch 4 step 4200 loss 0.0276
INFO:name:epoch 4 step 4300 loss 0.02983
INFO:name:epoch 4 step 4400 loss 0.03529
INFO:name:epoch 4 step 4500 loss 0.02994
INFO:name:epoch 4 step 4600 loss 0.03413
INFO:name:epoch 4 step 4700 loss 0.03507
INFO:name:epoch 4 step 4800 loss 0.02785
INFO:name:epoch 4 step 4900 loss 0.02449
INFO:name:epoch 4 step 5000 loss 0.02917
INFO:name:epoch 4 step 5100 loss 0.0287
INFO:name:epoch 4 step 5200 loss 0.03659
INFO:name:epoch 4 step 5300 loss 0.0282
INFO:name:epoch 4 step 5400 loss 0.0295
INFO:name:epoch 4 step 5500 loss 0.03106
INFO:name:epoch 4 step 5600 loss 0.03107
INFO:name:epoch 4 step 5700 loss 0.03261
INFO:name:epoch 4 step 5800 loss 0.02804
INFO:name:epoch 4 step 5900 loss 0.0284
INFO:name:epoch 4 step 6000 loss 0.03328
INFO:name:epoch 4 step 6100 loss 0.02342
INFO:name:epoch 4 step 6200 loss 0.02945
INFO:name:epoch 4 step 6300 loss 0.02688
INFO:name:epoch 4 step 6400 loss 0.03007
INFO:name:epoch 4 step 6500 loss 0.03004
INFO:name:epoch 4 step 6600 loss 0.03118
INFO:name:epoch 4 step 6700 loss 0.02814
INFO:name:epoch 4 step 6800 loss 0.02768
INFO:name:epoch 4 step 6900 loss 0.02701
INFO:name:epoch 4 step 7000 loss 0.03756
INFO:name:epoch 4 step 7100 loss 0.03038
INFO:name:epoch 4 step 7200 loss 0.02662
INFO:name:epoch 4 step 7300 loss 0.03674
INFO:name:epoch 4 step 7400 loss 0.03699
INFO:name:epoch 4 step 7500 loss 0.03155
INFO:name:epoch 4 step 7600 loss 0.02786
INFO:name:epoch 4 step 7700 loss 0.02989
INFO:name:epoch 4 step 7800 loss 0.03492
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3796
INFO:name:epoch 5 step 100 loss 0.02755
INFO:name:epoch 5 step 200 loss 0.02619
INFO:name:epoch 5 step 300 loss 0.02216
INFO:name:epoch 5 step 400 loss 0.02452
INFO:name:epoch 5 step 500 loss 0.02193
INFO:name:epoch 5 step 600 loss 0.02124
INFO:name:epoch 5 step 700 loss 0.02046
INFO:name:epoch 5 step 800 loss 0.03022
INFO:name:epoch 5 step 900 loss 0.02363
INFO:name:epoch 5 step 1000 loss 0.02196
INFO:name:epoch 5 step 1100 loss 0.02142
INFO:name:epoch 5 step 1200 loss 0.02262
INFO:name:epoch 5 step 1300 loss 0.023
INFO:name:epoch 5 step 1400 loss 0.02232
INFO:name:epoch 5 step 1500 loss 0.02319
INFO:name:epoch 5 step 1600 loss 0.021
INFO:name:epoch 5 step 1700 loss 0.01924
INFO:name:epoch 5 step 1800 loss 0.01623
INFO:name:epoch 5 step 1900 loss 0.02119
INFO:name:epoch 5 step 2000 loss 0.02527
INFO:name:epoch 5 step 2100 loss 0.02627
INFO:name:epoch 5 step 2200 loss 0.0236
INFO:name:epoch 5 step 2300 loss 0.02765
INFO:name:epoch 5 step 2400 loss 0.0243
INFO:name:epoch 5 step 2500 loss 0.02266
INFO:name:epoch 5 step 2600 loss 0.01962
INFO:name:epoch 5 step 2700 loss 0.02077
INFO:name:epoch 5 step 2800 loss 0.02333
INFO:name:epoch 5 step 2900 loss 0.02013
INFO:name:epoch 5 step 3000 loss 0.02488
INFO:name:epoch 5 step 3100 loss 0.02399
INFO:name:epoch 5 step 3200 loss 0.02299
INFO:name:epoch 5 step 3300 loss 0.02089
INFO:name:epoch 5 step 3400 loss 0.02201
INFO:name:epoch 5 step 3500 loss 0.02413
INFO:name:epoch 5 step 3600 loss 0.0246
INFO:name:epoch 5 step 3700 loss 0.02464
INFO:name:epoch 5 step 3800 loss 0.02452
INFO:name:epoch 5 step 3900 loss 0.02176
INFO:name:epoch 5 step 4000 loss 0.0207
INFO:name:epoch 5 step 4100 loss 0.02296
INFO:name:epoch 5 step 4200 loss 0.02636
INFO:name:epoch 5 step 4300 loss 0.02064
INFO:name:epoch 5 step 4400 loss 0.02733
INFO:name:epoch 5 step 4500 loss 0.02396
INFO:name:epoch 5 step 4600 loss 0.0245
INFO:name:epoch 5 step 4700 loss 0.02165
INFO:name:epoch 5 step 4800 loss 0.02305
INFO:name:epoch 5 step 4900 loss 0.02428
INFO:name:epoch 5 step 5000 loss 0.02585
INFO:name:epoch 5 step 5100 loss 0.02258
INFO:name:epoch 5 step 5200 loss 0.02432
INFO:name:epoch 5 step 5300 loss 0.0229
INFO:name:epoch 5 step 5400 loss 0.02767
INFO:name:epoch 5 step 5500 loss 0.02238
INFO:name:epoch 5 step 5600 loss 0.01956
INFO:name:epoch 5 step 5700 loss 0.02329
INFO:name:epoch 5 step 5800 loss 0.0219
INFO:name:epoch 5 step 5900 loss 0.021
INFO:name:epoch 5 step 6000 loss 0.02868
INFO:name:epoch 5 step 6100 loss 0.0218
INFO:name:epoch 5 step 6200 loss 0.02219
INFO:name:epoch 5 step 6300 loss 0.02553
INFO:name:epoch 5 step 6400 loss 0.02657
INFO:name:epoch 5 step 6500 loss 0.02256
INFO:name:epoch 5 step 6600 loss 0.01805
INFO:name:epoch 5 step 6700 loss 0.02741
INFO:name:epoch 5 step 6800 loss 0.02573
INFO:name:epoch 5 step 6900 loss 0.02727
INFO:name:epoch 5 step 7000 loss 0.0228
INFO:name:epoch 5 step 7100 loss 0.02308
INFO:name:epoch 5 step 7200 loss 0.02367
INFO:name:epoch 5 step 7300 loss 0.025
INFO:name:epoch 5 step 7400 loss 0.02418
INFO:name:epoch 5 step 7500 loss 0.02083
INFO:name:epoch 5 step 7600 loss 0.02263
INFO:name:epoch 5 step 7700 loss 0.02457
INFO:name:epoch 5 step 7800 loss 0.02236
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3826
INFO:name:epoch 6 step 100 loss 0.02042
INFO:name:epoch 6 step 200 loss 0.01941
INFO:name:epoch 6 step 300 loss 0.01452
INFO:name:epoch 6 step 400 loss 0.02363
INFO:name:epoch 6 step 500 loss 0.01795
INFO:name:epoch 6 step 600 loss 0.01725
INFO:name:epoch 6 step 700 loss 0.02085
INFO:name:epoch 6 step 800 loss 0.0165
INFO:name:epoch 6 step 900 loss 0.0168
INFO:name:epoch 6 step 1000 loss 0.01715
INFO:name:epoch 6 step 1100 loss 0.01937
INFO:name:epoch 6 step 1200 loss 0.02053
INFO:name:epoch 6 step 1300 loss 0.0226
INFO:name:epoch 6 step 1400 loss 0.01694
INFO:name:epoch 6 step 1500 loss 0.02021
INFO:name:epoch 6 step 1600 loss 0.01731
INFO:name:epoch 6 step 1700 loss 0.01819
INFO:name:epoch 6 step 1800 loss 0.02276
INFO:name:epoch 6 step 1900 loss 0.01823
INFO:name:epoch 6 step 2000 loss 0.02209
INFO:name:epoch 6 step 2100 loss 0.02124
INFO:name:epoch 6 step 2200 loss 0.01858
INFO:name:epoch 6 step 2300 loss 0.01899
INFO:name:epoch 6 step 2400 loss 0.01732
INFO:name:epoch 6 step 2500 loss 0.01701
INFO:name:epoch 6 step 2600 loss 0.01882
INFO:name:epoch 6 step 2700 loss 0.02433
INFO:name:epoch 6 step 2800 loss 0.01686
INFO:name:epoch 6 step 2900 loss 0.0226
INFO:name:epoch 6 step 3000 loss 0.01705
INFO:name:epoch 6 step 3100 loss 0.01844
INFO:name:epoch 6 step 3200 loss 0.02003
INFO:name:epoch 6 step 3300 loss 0.0172
INFO:name:epoch 6 step 3400 loss 0.01739
INFO:name:epoch 6 step 3500 loss 0.01608
INFO:name:epoch 6 step 3600 loss 0.01651
INFO:name:epoch 6 step 3700 loss 0.02397
INFO:name:epoch 6 step 3800 loss 0.02165
INFO:name:epoch 6 step 3900 loss 0.01855
INFO:name:epoch 6 step 4000 loss 0.01848
INFO:name:epoch 6 step 4100 loss 0.01745
INFO:name:epoch 6 step 4200 loss 0.02302
INFO:name:epoch 6 step 4300 loss 0.0203
INFO:name:epoch 6 step 4400 loss 0.02047
INFO:name:epoch 6 step 4500 loss 0.01996
INFO:name:epoch 6 step 4600 loss 0.01743
INFO:name:epoch 6 step 4700 loss 0.01851
INFO:name:epoch 6 step 4800 loss 0.01767
INFO:name:epoch 6 step 4900 loss 0.01695
INFO:name:epoch 6 step 5000 loss 0.01981
INFO:name:epoch 6 step 5100 loss 0.01942
INFO:name:epoch 6 step 5200 loss 0.0213
INFO:name:epoch 6 step 5300 loss 0.01551
INFO:name:epoch 6 step 5400 loss 0.02015
INFO:name:epoch 6 step 5500 loss 0.01428
INFO:name:epoch 6 step 5600 loss 0.01765
INFO:name:epoch 6 step 5700 loss 0.01798
INFO:name:epoch 6 step 5800 loss 0.02253
INFO:name:epoch 6 step 5900 loss 0.02046
INFO:name:epoch 6 step 6000 loss 0.01956
INFO:name:epoch 6 step 6100 loss 0.0196
INFO:name:epoch 6 step 6200 loss 0.02024
INFO:name:epoch 6 step 6300 loss 0.02049
INFO:name:epoch 6 step 6400 loss 0.02576
INFO:name:epoch 6 step 6500 loss 0.01834
INFO:name:epoch 6 step 6600 loss 0.02096
INFO:name:epoch 6 step 6700 loss 0.01818
INFO:name:epoch 6 step 6800 loss 0.01973
INFO:name:epoch 6 step 6900 loss 0.01799
INFO:name:epoch 6 step 7000 loss 0.02303
INFO:name:epoch 6 step 7100 loss 0.02257
INFO:name:epoch 6 step 7200 loss 0.01662
INFO:name:epoch 6 step 7300 loss 0.02261
INFO:name:epoch 6 step 7400 loss 0.02116
INFO:name:epoch 6 step 7500 loss 0.02196
INFO:name:epoch 6 step 7600 loss 0.02036
INFO:name:epoch 6 step 7700 loss 0.02081
INFO:name:epoch 6 step 7800 loss 0.02168
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.382
INFO:name:epoch 7 step 100 loss 0.01725
INFO:name:epoch 7 step 200 loss 0.01648
INFO:name:epoch 7 step 300 loss 0.01739
INFO:name:epoch 7 step 400 loss 0.01551
INFO:name:epoch 7 step 500 loss 0.01381
INFO:name:epoch 7 step 600 loss 0.01618
INFO:name:epoch 7 step 700 loss 0.01813
INFO:name:epoch 7 step 800 loss 0.01316
INFO:name:epoch 7 step 900 loss 0.01502
INFO:name:epoch 7 step 1000 loss 0.01531
INFO:name:epoch 7 step 1100 loss 0.01566
INFO:name:epoch 7 step 1200 loss 0.01648
INFO:name:epoch 7 step 1300 loss 0.01515
INFO:name:epoch 7 step 1400 loss 0.01399
INFO:name:epoch 7 step 1500 loss 0.01413
INFO:name:epoch 7 step 1600 loss 0.01959
INFO:name:epoch 7 step 1700 loss 0.01599
INFO:name:epoch 7 step 1800 loss 0.02198
INFO:name:epoch 7 step 1900 loss 0.01231
INFO:name:epoch 7 step 2000 loss 0.01422
INFO:name:epoch 7 step 2100 loss 0.01455
INFO:name:epoch 7 step 2200 loss 0.01751
INFO:name:epoch 7 step 2300 loss 0.01882
INFO:name:epoch 7 step 2400 loss 0.01757
INFO:name:epoch 7 step 2500 loss 0.01872
INFO:name:epoch 7 step 2600 loss 0.01313
INFO:name:epoch 7 step 2700 loss 0.01679
INFO:name:epoch 7 step 2800 loss 0.01534
INFO:name:epoch 7 step 2900 loss 0.01713
INFO:name:epoch 7 step 3000 loss 0.01689
INFO:name:epoch 7 step 3100 loss 0.0141
INFO:name:epoch 7 step 3200 loss 0.01555
INFO:name:epoch 7 step 3300 loss 0.01664
INFO:name:epoch 7 step 3400 loss 0.01563
INFO:name:epoch 7 step 3500 loss 0.01955
INFO:name:epoch 7 step 3600 loss 0.01615
INFO:name:epoch 7 step 3700 loss 0.01879
INFO:name:epoch 7 step 3800 loss 0.01419
INFO:name:epoch 7 step 3900 loss 0.01776
INFO:name:epoch 7 step 4000 loss 0.01736
INFO:name:epoch 7 step 4100 loss 0.01769
INFO:name:epoch 7 step 4200 loss 0.01765
INFO:name:epoch 7 step 4300 loss 0.01407
INFO:name:epoch 7 step 4400 loss 0.02235
INFO:name:epoch 7 step 4500 loss 0.01933
INFO:name:epoch 7 step 4600 loss 0.0172
INFO:name:epoch 7 step 4700 loss 0.01744
INFO:name:epoch 7 step 4800 loss 0.01491
INFO:name:epoch 7 step 4900 loss 0.01739
INFO:name:epoch 7 step 5000 loss 0.01775
INFO:name:epoch 7 step 5100 loss 0.01668
INFO:name:epoch 7 step 5200 loss 0.0168
INFO:name:epoch 7 step 5300 loss 0.01518
INFO:name:epoch 7 step 5400 loss 0.01539
INFO:name:epoch 7 step 5500 loss 0.01831
INFO:name:epoch 7 step 5600 loss 0.01565
INFO:name:epoch 7 step 5700 loss 0.01789
INFO:name:epoch 7 step 5800 loss 0.01643
INFO:name:epoch 7 step 5900 loss 0.01972
INFO:name:epoch 7 step 6000 loss 0.01779
INFO:name:epoch 7 step 6100 loss 0.01595
INFO:name:epoch 7 step 6200 loss 0.01953
INFO:name:epoch 7 step 6300 loss 0.01636
INFO:name:epoch 7 step 6400 loss 0.01521
INFO:name:epoch 7 step 6500 loss 0.01576
INFO:name:epoch 7 step 6600 loss 0.01464
INFO:name:epoch 7 step 6700 loss 0.0158
INFO:name:epoch 7 step 6800 loss 0.01622
INFO:name:epoch 7 step 6900 loss 0.01541
INFO:name:epoch 7 step 7000 loss 0.01869
INFO:name:epoch 7 step 7100 loss 0.01903
INFO:name:epoch 7 step 7200 loss 0.01611
INFO:name:epoch 7 step 7300 loss 0.01884
INFO:name:epoch 7 step 7400 loss 0.01578
INFO:name:epoch 7 step 7500 loss 0.01569
INFO:name:epoch 7 step 7600 loss 0.01596
INFO:name:epoch 7 step 7700 loss 0.01769
INFO:name:epoch 7 step 7800 loss 0.01796
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3838
INFO:name:epoch 8 step 100 loss 0.01337
INFO:name:epoch 8 step 200 loss 0.01394
INFO:name:epoch 8 step 300 loss 0.01729
INFO:name:epoch 8 step 400 loss 0.01428
INFO:name:epoch 8 step 500 loss 0.01262
INFO:name:epoch 8 step 600 loss 0.01178
INFO:name:epoch 8 step 700 loss 0.01317
INFO:name:epoch 8 step 800 loss 0.01474
INFO:name:epoch 8 step 900 loss 0.01195
INFO:name:epoch 8 step 1000 loss 0.01538
INFO:name:epoch 8 step 1100 loss 0.01285
INFO:name:epoch 8 step 1200 loss 0.0132
INFO:name:epoch 8 step 1300 loss 0.01573
INFO:name:epoch 8 step 1400 loss 0.01356
INFO:name:epoch 8 step 1500 loss 0.01185
INFO:name:epoch 8 step 1600 loss 0.01298
INFO:name:epoch 8 step 1700 loss 0.01447
INFO:name:epoch 8 step 1800 loss 0.01414
INFO:name:epoch 8 step 1900 loss 0.01568
INFO:name:epoch 8 step 2000 loss 0.0108
INFO:name:epoch 8 step 2100 loss 0.01658
INFO:name:epoch 8 step 2200 loss 0.01401
INFO:name:epoch 8 step 2300 loss 0.01171
INFO:name:epoch 8 step 2400 loss 0.01475
INFO:name:epoch 8 step 2500 loss 0.01777
INFO:name:epoch 8 step 2600 loss 0.0142
INFO:name:epoch 8 step 2700 loss 0.01495
INFO:name:epoch 8 step 2800 loss 0.01464
INFO:name:epoch 8 step 2900 loss 0.01755
INFO:name:epoch 8 step 3000 loss 0.01481
INFO:name:epoch 8 step 3100 loss 0.01197
INFO:name:epoch 8 step 3200 loss 0.01618
INFO:name:epoch 8 step 3300 loss 0.01457
INFO:name:epoch 8 step 3400 loss 0.0137
INFO:name:epoch 8 step 3500 loss 0.01519
INFO:name:epoch 8 step 3600 loss 0.01397
INFO:name:epoch 8 step 3700 loss 0.0137
INFO:name:epoch 8 step 3800 loss 0.01346
INFO:name:epoch 8 step 3900 loss 0.01539
INFO:name:epoch 8 step 4000 loss 0.01582
INFO:name:epoch 8 step 4100 loss 0.01424
INFO:name:epoch 8 step 4200 loss 0.01449
INFO:name:epoch 8 step 4300 loss 0.01609
INFO:name:epoch 8 step 4400 loss 0.01565
INFO:name:epoch 8 step 4500 loss 0.01233
INFO:name:epoch 8 step 4600 loss 0.01513
INFO:name:epoch 8 step 4700 loss 0.01355
INFO:name:epoch 8 step 4800 loss 0.01479
INFO:name:epoch 8 step 4900 loss 0.01347
INFO:name:epoch 8 step 5000 loss 0.0121
INFO:name:epoch 8 step 5100 loss 0.01646
INFO:name:epoch 8 step 5200 loss 0.01181
INFO:name:epoch 8 step 5300 loss 0.01398
INFO:name:epoch 8 step 5400 loss 0.01365
INFO:name:epoch 8 step 5500 loss 0.01312
INFO:name:epoch 8 step 5600 loss 0.01419
INFO:name:epoch 8 step 5700 loss 0.01363
INFO:name:epoch 8 step 5800 loss 0.01509
INFO:name:epoch 8 step 5900 loss 0.01512
INFO:name:epoch 8 step 6000 loss 0.01401
INFO:name:epoch 8 step 6100 loss 0.01682
INFO:name:epoch 8 step 6200 loss 0.01431
INFO:name:epoch 8 step 6300 loss 0.01414
INFO:name:epoch 8 step 6400 loss 0.01624
INFO:name:epoch 8 step 6500 loss 0.01114
INFO:name:epoch 8 step 6600 loss 0.01303
INFO:name:epoch 8 step 6700 loss 0.0162
INFO:name:epoch 8 step 6800 loss 0.01506
INFO:name:epoch 8 step 6900 loss 0.01705
INFO:name:epoch 8 step 7000 loss 0.01258
INFO:name:epoch 8 step 7100 loss 0.01307
INFO:name:epoch 8 step 7200 loss 0.01304
INFO:name:epoch 8 step 7300 loss 0.01524
INFO:name:epoch 8 step 7400 loss 0.01482
INFO:name:epoch 8 step 7500 loss 0.01474
INFO:name:epoch 8 step 7600 loss 0.01533
INFO:name:epoch 8 step 7700 loss 0.01354
INFO:name:epoch 8 step 7800 loss 0.01561
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3744
INFO:name:epoch 9 step 100 loss 0.01128
INFO:name:epoch 9 step 200 loss 0.01272
INFO:name:epoch 9 step 300 loss 0.0102
INFO:name:epoch 9 step 400 loss 0.01156
INFO:name:epoch 9 step 500 loss 0.01238
INFO:name:epoch 9 step 600 loss 0.01406
INFO:name:epoch 9 step 700 loss 0.01165
INFO:name:epoch 9 step 800 loss 0.01271
INFO:name:epoch 9 step 900 loss 0.0101
INFO:name:epoch 9 step 1000 loss 0.01095
INFO:name:epoch 9 step 1100 loss 0.01545
INFO:name:epoch 9 step 1200 loss 0.01569
INFO:name:epoch 9 step 1300 loss 0.01623
INFO:name:epoch 9 step 1400 loss 0.01215
INFO:name:epoch 9 step 1500 loss 0.01305
INFO:name:epoch 9 step 1600 loss 0.01202
INFO:name:epoch 9 step 1700 loss 0.01439
INFO:name:epoch 9 step 1800 loss 0.01009
INFO:name:epoch 9 step 1900 loss 0.01248
INFO:name:epoch 9 step 2000 loss 0.01343
INFO:name:epoch 9 step 2100 loss 0.01395
INFO:name:epoch 9 step 2200 loss 0.01054
INFO:name:epoch 9 step 2300 loss 0.01185
INFO:name:epoch 9 step 2400 loss 0.01373
INFO:name:epoch 9 step 2500 loss 0.01139
INFO:name:epoch 9 step 2600 loss 0.01071
INFO:name:epoch 9 step 2700 loss 0.01333
INFO:name:epoch 9 step 2800 loss 0.01409
INFO:name:epoch 9 step 2900 loss 0.01095
INFO:name:epoch 9 step 3000 loss 0.01324
INFO:name:epoch 9 step 3100 loss 0.01261
INFO:name:epoch 9 step 3200 loss 0.01298
INFO:name:epoch 9 step 3300 loss 0.01192
INFO:name:epoch 9 step 3400 loss 0.01231
INFO:name:epoch 9 step 3500 loss 0.01299
INFO:name:epoch 9 step 3600 loss 0.01164
INFO:name:epoch 9 step 3700 loss 0.01046
INFO:name:epoch 9 step 3800 loss 0.00981
INFO:name:epoch 9 step 3900 loss 0.01017
INFO:name:epoch 9 step 4000 loss 0.01277
INFO:name:epoch 9 step 4100 loss 0.00876
INFO:name:epoch 9 step 4200 loss 0.01352
INFO:name:epoch 9 step 4300 loss 0.01251
INFO:name:epoch 9 step 4400 loss 0.0116
INFO:name:epoch 9 step 4500 loss 0.01186
INFO:name:epoch 9 step 4600 loss 0.01299
INFO:name:epoch 9 step 4700 loss 0.00998
INFO:name:epoch 9 step 4800 loss 0.01274
INFO:name:epoch 9 step 4900 loss 0.01286
INFO:name:epoch 9 step 5000 loss 0.0113
INFO:name:epoch 9 step 5100 loss 0.01414
INFO:name:epoch 9 step 5200 loss 0.01358
INFO:name:epoch 9 step 5300 loss 0.01365
INFO:name:epoch 9 step 5400 loss 0.01418
INFO:name:epoch 9 step 5500 loss 0.01144
INFO:name:epoch 9 step 5600 loss 0.01329
INFO:name:epoch 9 step 5700 loss 0.01789
INFO:name:epoch 9 step 5800 loss 0.01335
INFO:name:epoch 9 step 5900 loss 0.01195
INFO:name:epoch 9 step 6000 loss 0.01348
INFO:name:epoch 9 step 6100 loss 0.0147
INFO:name:epoch 9 step 6200 loss 0.01278
INFO:name:epoch 9 step 6300 loss 0.0171
INFO:name:epoch 9 step 6400 loss 0.01351
INFO:name:epoch 9 step 6500 loss 0.0139
INFO:name:epoch 9 step 6600 loss 0.01449
INFO:name:epoch 9 step 6700 loss 0.01763
INFO:name:epoch 9 step 6800 loss 0.01077
INFO:name:epoch 9 step 6900 loss 0.01427
INFO:name:epoch 9 step 7000 loss 0.01403
INFO:name:epoch 9 step 7100 loss 0.01079
INFO:name:epoch 9 step 7200 loss 0.01507
INFO:name:epoch 9 step 7300 loss 0.01377
INFO:name:epoch 9 step 7400 loss 0.01242
INFO:name:epoch 9 step 7500 loss 0.01286
INFO:name:epoch 9 step 7600 loss 0.01404
INFO:name:epoch 9 step 7700 loss 0.01384
INFO:name:epoch 9 step 7800 loss 0.01383
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3729
INFO:name:epoch 10 step 100 loss 0.01284
INFO:name:epoch 10 step 200 loss 0.00991
INFO:name:epoch 10 step 300 loss 0.01128
INFO:name:epoch 10 step 400 loss 0.01389
INFO:name:epoch 10 step 500 loss 0.01258
INFO:name:epoch 10 step 600 loss 0.01139
INFO:name:epoch 10 step 700 loss 0.01066
INFO:name:epoch 10 step 800 loss 0.01068
INFO:name:epoch 10 step 900 loss 0.01091
INFO:name:epoch 10 step 1000 loss 0.01199
INFO:name:epoch 10 step 1100 loss 0.01096
INFO:name:epoch 10 step 1200 loss 0.01297
INFO:name:epoch 10 step 1300 loss 0.01031
INFO:name:epoch 10 step 1400 loss 0.00942
INFO:name:epoch 10 step 1500 loss 0.01231
INFO:name:epoch 10 step 1600 loss 0.01242
INFO:name:epoch 10 step 1700 loss 0.01078
INFO:name:epoch 10 step 1800 loss 0.01292
INFO:name:epoch 10 step 1900 loss 0.01181
INFO:name:epoch 10 step 2000 loss 0.01187
INFO:name:epoch 10 step 2100 loss 0.01282
INFO:name:epoch 10 step 2200 loss 0.00885
INFO:name:epoch 10 step 2300 loss 0.01346
INFO:name:epoch 10 step 2400 loss 0.01232
INFO:name:epoch 10 step 2500 loss 0.01086
INFO:name:epoch 10 step 2600 loss 0.0129
INFO:name:epoch 10 step 2700 loss 0.01397
INFO:name:epoch 10 step 2800 loss 0.01227
INFO:name:epoch 10 step 2900 loss 0.01004
INFO:name:epoch 10 step 3000 loss 0.01237
INFO:name:epoch 10 step 3100 loss 0.01144
INFO:name:epoch 10 step 3200 loss 0.01247
INFO:name:epoch 10 step 3300 loss 0.00877
INFO:name:epoch 10 step 3400 loss 0.01101
INFO:name:epoch 10 step 3500 loss 0.01173
INFO:name:epoch 10 step 3600 loss 0.0117
INFO:name:epoch 10 step 3700 loss 0.00774
INFO:name:epoch 10 step 3800 loss 0.01241
INFO:name:epoch 10 step 3900 loss 0.01059
INFO:name:epoch 10 step 4000 loss 0.01422
INFO:name:epoch 10 step 4100 loss 0.01252
INFO:name:epoch 10 step 4200 loss 0.01421
INFO:name:epoch 10 step 4300 loss 0.01084
INFO:name:epoch 10 step 4400 loss 0.01024
INFO:name:epoch 10 step 4500 loss 0.01263
INFO:name:epoch 10 step 4600 loss 0.01313
INFO:name:epoch 10 step 4700 loss 0.01275
INFO:name:epoch 10 step 4800 loss 0.01045
INFO:name:epoch 10 step 4900 loss 0.01227
INFO:name:epoch 10 step 5000 loss 0.01144
INFO:name:epoch 10 step 5100 loss 0.01215
INFO:name:epoch 10 step 5200 loss 0.00997
INFO:name:epoch 10 step 5300 loss 0.01172
INFO:name:epoch 10 step 5400 loss 0.01018
INFO:name:epoch 10 step 5500 loss 0.01079
INFO:name:epoch 10 step 5600 loss 0.01137
INFO:name:epoch 10 step 5700 loss 0.01377
INFO:name:epoch 10 step 5800 loss 0.01221
INFO:name:epoch 10 step 5900 loss 0.0106
INFO:name:epoch 10 step 6000 loss 0.01535
INFO:name:epoch 10 step 6100 loss 0.01315
INFO:name:epoch 10 step 6200 loss 0.01254
INFO:name:epoch 10 step 6300 loss 0.01034
INFO:name:epoch 10 step 6400 loss 0.00916
INFO:name:epoch 10 step 6500 loss 0.01472
INFO:name:epoch 10 step 6600 loss 0.01231
INFO:name:epoch 10 step 6700 loss 0.01035
INFO:name:epoch 10 step 6800 loss 0.01085
INFO:name:epoch 10 step 6900 loss 0.01152
INFO:name:epoch 10 step 7000 loss 0.01183
INFO:name:epoch 10 step 7100 loss 0.01163
INFO:name:epoch 10 step 7200 loss 0.01131
INFO:name:epoch 10 step 7300 loss 0.01353
INFO:name:epoch 10 step 7400 loss 0.00995
INFO:name:epoch 10 step 7500 loss 0.01069
INFO:name:epoch 10 step 7600 loss 0.01132
INFO:name:epoch 10 step 7700 loss 0.01728
INFO:name:epoch 10 step 7800 loss 0.0128
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3806
INFO:name:epoch 11 step 100 loss 0.01085
INFO:name:epoch 11 step 200 loss 0.01053
INFO:name:epoch 11 step 300 loss 0.01039
INFO:name:epoch 11 step 400 loss 0.0087
INFO:name:epoch 11 step 500 loss 0.00948
INFO:name:epoch 11 step 600 loss 0.00933
INFO:name:epoch 11 step 700 loss 0.00881
INFO:name:epoch 11 step 800 loss 0.01155
INFO:name:epoch 11 step 900 loss 0.00919
INFO:name:epoch 11 step 1000 loss 0.0106
INFO:name:epoch 11 step 1100 loss 0.00991
INFO:name:epoch 11 step 1200 loss 0.00974
INFO:name:epoch 11 step 1300 loss 0.01056
INFO:name:epoch 11 step 1400 loss 0.00932
INFO:name:epoch 11 step 1500 loss 0.00822
INFO:name:epoch 11 step 1600 loss 0.01044
INFO:name:epoch 11 step 1700 loss 0.01287
INFO:name:epoch 11 step 1800 loss 0.01046
INFO:name:epoch 11 step 1900 loss 0.00829
INFO:name:epoch 11 step 2000 loss 0.01166
INFO:name:epoch 11 step 2100 loss 0.01339
INFO:name:epoch 11 step 2200 loss 0.00997
INFO:name:epoch 11 step 2300 loss 0.0126
INFO:name:epoch 11 step 2400 loss 0.01036
INFO:name:epoch 11 step 2500 loss 0.01256
INFO:name:epoch 11 step 2600 loss 0.01109
INFO:name:epoch 11 step 2700 loss 0.01267
INFO:name:epoch 11 step 2800 loss 0.01104
INFO:name:epoch 11 step 2900 loss 0.01008
INFO:name:epoch 11 step 3000 loss 0.01171
INFO:name:epoch 11 step 3100 loss 0.0137
INFO:name:epoch 11 step 3200 loss 0.01212
INFO:name:epoch 11 step 3300 loss 0.01048
INFO:name:epoch 11 step 3400 loss 0.00963
INFO:name:epoch 11 step 3500 loss 0.00904
INFO:name:epoch 11 step 3600 loss 0.01127
INFO:name:epoch 11 step 3700 loss 0.00958
INFO:name:epoch 11 step 3800 loss 0.0078
INFO:name:epoch 11 step 3900 loss 0.00979
INFO:name:epoch 11 step 4000 loss 0.01066
INFO:name:epoch 11 step 4100 loss 0.013
INFO:name:epoch 11 step 4200 loss 0.01025
INFO:name:epoch 11 step 4300 loss 0.01135
INFO:name:epoch 11 step 4400 loss 0.01083
INFO:name:epoch 11 step 4500 loss 0.00795
INFO:name:epoch 11 step 4600 loss 0.00863
INFO:name:epoch 11 step 4700 loss 0.01503
INFO:name:epoch 11 step 4800 loss 0.01098
INFO:name:epoch 11 step 4900 loss 0.00981
INFO:name:epoch 11 step 5000 loss 0.0106
INFO:name:epoch 11 step 5100 loss 0.00961
INFO:name:epoch 11 step 5200 loss 0.01281
INFO:name:epoch 11 step 5300 loss 0.00904
INFO:name:epoch 11 step 5400 loss 0.01009
INFO:name:epoch 11 step 5500 loss 0.01061
INFO:name:epoch 11 step 5600 loss 0.01212
INFO:name:epoch 11 step 5700 loss 0.01012
INFO:name:epoch 11 step 5800 loss 0.01151
INFO:name:epoch 11 step 5900 loss 0.00973
INFO:name:epoch 11 step 6000 loss 0.01175
INFO:name:epoch 11 step 6100 loss 0.00837
INFO:name:epoch 11 step 6200 loss 0.01204
INFO:name:epoch 11 step 6300 loss 0.00882
INFO:name:epoch 11 step 6400 loss 0.01141
INFO:name:epoch 11 step 6500 loss 0.01209
INFO:name:epoch 11 step 6600 loss 0.00999
INFO:name:epoch 11 step 6700 loss 0.01028
INFO:name:epoch 11 step 6800 loss 0.01183
INFO:name:epoch 11 step 6900 loss 0.01242
INFO:name:epoch 11 step 7000 loss 0.0098
INFO:name:epoch 11 step 7100 loss 0.01205
INFO:name:epoch 11 step 7200 loss 0.01239
INFO:name:epoch 11 step 7300 loss 0.01134
INFO:name:epoch 11 step 7400 loss 0.00956
INFO:name:epoch 11 step 7500 loss 0.01099
INFO:name:epoch 11 step 7600 loss 0.00984
INFO:name:epoch 11 step 7700 loss 0.01256
INFO:name:epoch 11 step 7800 loss 0.01219
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3786
INFO:name:epoch 12 step 100 loss 0.0116
INFO:name:epoch 12 step 200 loss 0.00993
INFO:name:epoch 12 step 300 loss 0.00858
INFO:name:epoch 12 step 400 loss 0.0107
INFO:name:epoch 12 step 500 loss 0.00754
INFO:name:epoch 12 step 600 loss 0.00857
INFO:name:epoch 12 step 700 loss 0.00752
INFO:name:epoch 12 step 800 loss 0.00958
INFO:name:epoch 12 step 900 loss 0.00874
INFO:name:epoch 12 step 1000 loss 0.01188
INFO:name:epoch 12 step 1100 loss 0.00994
INFO:name:epoch 12 step 1200 loss 0.00903
INFO:name:epoch 12 step 1300 loss 0.00919
INFO:name:epoch 12 step 1400 loss 0.01119
INFO:name:epoch 12 step 1500 loss 0.01086
INFO:name:epoch 12 step 1600 loss 0.01036
INFO:name:epoch 12 step 1700 loss 0.01012
INFO:name:epoch 12 step 1800 loss 0.00709
INFO:name:epoch 12 step 1900 loss 0.00955
INFO:name:epoch 12 step 2000 loss 0.01046
INFO:name:epoch 12 step 2100 loss 0.00773
INFO:name:epoch 12 step 2200 loss 0.00888
INFO:name:epoch 12 step 2300 loss 0.00859
INFO:name:epoch 12 step 2400 loss 0.00773
INFO:name:epoch 12 step 2500 loss 0.01061
INFO:name:epoch 12 step 2600 loss 0.01172
INFO:name:epoch 12 step 2700 loss 0.00996
INFO:name:epoch 12 step 2800 loss 0.00975
INFO:name:epoch 12 step 2900 loss 0.00709
INFO:name:epoch 12 step 3000 loss 0.00949
INFO:name:epoch 12 step 3100 loss 0.00968
INFO:name:epoch 12 step 3200 loss 0.00825
INFO:name:epoch 12 step 3300 loss 0.00911
INFO:name:epoch 12 step 3400 loss 0.00947
INFO:name:epoch 12 step 3500 loss 0.01025
INFO:name:epoch 12 step 3600 loss 0.00996
INFO:name:epoch 12 step 3700 loss 0.00982
INFO:name:epoch 12 step 3800 loss 0.00859
INFO:name:epoch 12 step 3900 loss 0.00713
INFO:name:epoch 12 step 4000 loss 0.01144
INFO:name:epoch 12 step 4100 loss 0.00885
INFO:name:epoch 12 step 4200 loss 0.00976
INFO:name:epoch 12 step 4300 loss 0.00974
INFO:name:epoch 12 step 4400 loss 0.0069
INFO:name:epoch 12 step 4500 loss 0.00945
INFO:name:epoch 12 step 4600 loss 0.00838
INFO:name:epoch 12 step 4700 loss 0.00919
INFO:name:epoch 12 step 4800 loss 0.00932
INFO:name:epoch 12 step 4900 loss 0.00927
INFO:name:epoch 12 step 5000 loss 0.01092
INFO:name:epoch 12 step 5100 loss 0.01325
INFO:name:epoch 12 step 5200 loss 0.00889
INFO:name:epoch 12 step 5300 loss 0.00642
INFO:name:epoch 12 step 5400 loss 0.00882
INFO:name:epoch 12 step 5500 loss 0.0091
INFO:name:epoch 12 step 5600 loss 0.00863
INFO:name:epoch 12 step 5700 loss 0.01146
INFO:name:epoch 12 step 5800 loss 0.01115
INFO:name:epoch 12 step 5900 loss 0.01117
INFO:name:epoch 12 step 6000 loss 0.0088
INFO:name:epoch 12 step 6100 loss 0.01412
INFO:name:epoch 12 step 6200 loss 0.01007
INFO:name:epoch 12 step 6300 loss 0.00836
INFO:name:epoch 12 step 6400 loss 0.01018
INFO:name:epoch 12 step 6500 loss 0.00847
INFO:name:epoch 12 step 6600 loss 0.01032
INFO:name:epoch 12 step 6700 loss 0.00736
INFO:name:epoch 12 step 6800 loss 0.00971
INFO:name:epoch 12 step 6900 loss 0.0084
INFO:name:epoch 12 step 7000 loss 0.00906
INFO:name:epoch 12 step 7100 loss 0.00711
INFO:name:epoch 12 step 7200 loss 0.00892
INFO:name:epoch 12 step 7300 loss 0.0101
INFO:name:epoch 12 step 7400 loss 0.00775
INFO:name:epoch 12 step 7500 loss 0.01321
INFO:name:epoch 12 step 7600 loss 0.01039
INFO:name:epoch 12 step 7700 loss 0.00746
INFO:name:epoch 12 step 7800 loss 0.00969
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3837
INFO:name:epoch 13 step 100 loss 0.00866
INFO:name:epoch 13 step 200 loss 0.00713
INFO:name:epoch 13 step 300 loss 0.00874
INFO:name:epoch 13 step 400 loss 0.0103
INFO:name:epoch 13 step 500 loss 0.00978
INFO:name:epoch 13 step 600 loss 0.00924
INFO:name:epoch 13 step 700 loss 0.00854
INFO:name:epoch 13 step 800 loss 0.00979
INFO:name:epoch 13 step 900 loss 0.0073
INFO:name:epoch 13 step 1000 loss 0.01069
INFO:name:epoch 13 step 1100 loss 0.01002
INFO:name:epoch 13 step 1200 loss 0.00729
INFO:name:epoch 13 step 1300 loss 0.01031
INFO:name:epoch 13 step 1400 loss 0.008
INFO:name:epoch 13 step 1500 loss 0.00816
INFO:name:epoch 13 step 1600 loss 0.0099
INFO:name:epoch 13 step 1700 loss 0.00671
INFO:name:epoch 13 step 1800 loss 0.0092
INFO:name:epoch 13 step 1900 loss 0.00869
INFO:name:epoch 13 step 2000 loss 0.00942
INFO:name:epoch 13 step 2100 loss 0.00949
INFO:name:epoch 13 step 2200 loss 0.01195
INFO:name:epoch 13 step 2300 loss 0.0071
INFO:name:epoch 13 step 2400 loss 0.00771
INFO:name:epoch 13 step 2500 loss 0.00877
INFO:name:epoch 13 step 2600 loss 0.01005
INFO:name:epoch 13 step 2700 loss 0.00882
INFO:name:epoch 13 step 2800 loss 0.00751
INFO:name:epoch 13 step 2900 loss 0.00684
INFO:name:epoch 13 step 3000 loss 0.00953
INFO:name:epoch 13 step 3100 loss 0.00766
INFO:name:epoch 13 step 3200 loss 0.00861
INFO:name:epoch 13 step 3300 loss 0.00928
INFO:name:epoch 13 step 3400 loss 0.00808
INFO:name:epoch 13 step 3500 loss 0.00861
INFO:name:epoch 13 step 3600 loss 0.00886
INFO:name:epoch 13 step 3700 loss 0.0096
INFO:name:epoch 13 step 3800 loss 0.01124
INFO:name:epoch 13 step 3900 loss 0.01134
INFO:name:epoch 13 step 4000 loss 0.00916
INFO:name:epoch 13 step 4100 loss 0.00768
INFO:name:epoch 13 step 4200 loss 0.00975
INFO:name:epoch 13 step 4300 loss 0.00774
INFO:name:epoch 13 step 4400 loss 0.01008
INFO:name:epoch 13 step 4500 loss 0.00778
INFO:name:epoch 13 step 4600 loss 0.00806
INFO:name:epoch 13 step 4700 loss 0.00864
INFO:name:epoch 13 step 4800 loss 0.01092
INFO:name:epoch 13 step 4900 loss 0.01004
INFO:name:epoch 13 step 5000 loss 0.00861
INFO:name:epoch 13 step 5100 loss 0.00921
INFO:name:epoch 13 step 5200 loss 0.00761
INFO:name:epoch 13 step 5300 loss 0.00844
INFO:name:epoch 13 step 5400 loss 0.00945
INFO:name:epoch 13 step 5500 loss 0.00778
INFO:name:epoch 13 step 5600 loss 0.00987
INFO:name:epoch 13 step 5700 loss 0.00967
INFO:name:epoch 13 step 5800 loss 0.01299
INFO:name:epoch 13 step 5900 loss 0.00925
INFO:name:epoch 13 step 6000 loss 0.00768
INFO:name:epoch 13 step 6100 loss 0.00824
INFO:name:epoch 13 step 6200 loss 0.01077
INFO:name:epoch 13 step 6300 loss 0.00934
INFO:name:epoch 13 step 6400 loss 0.00785
INFO:name:epoch 13 step 6500 loss 0.01013
INFO:name:epoch 13 step 6600 loss 0.00896
INFO:name:epoch 13 step 6700 loss 0.00788
INFO:name:epoch 13 step 6800 loss 0.00894
INFO:name:epoch 13 step 6900 loss 0.00859
INFO:name:epoch 13 step 7000 loss 0.0074
INFO:name:epoch 13 step 7100 loss 0.00832
INFO:name:epoch 13 step 7200 loss 0.00777
INFO:name:epoch 13 step 7300 loss 0.00863
INFO:name:epoch 13 step 7400 loss 0.00835
INFO:name:epoch 13 step 7500 loss 0.01148
INFO:name:epoch 13 step 7600 loss 0.00972
INFO:name:epoch 13 step 7700 loss 0.00704
INFO:name:epoch 13 step 7800 loss 0.0103
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3794
INFO:name:epoch 14 step 100 loss 0.00857
INFO:name:epoch 14 step 200 loss 0.00986
INFO:name:epoch 14 step 300 loss 0.00933
INFO:name:epoch 14 step 400 loss 0.00608
INFO:name:epoch 14 step 500 loss 0.00891
INFO:name:epoch 14 step 600 loss 0.00856
INFO:name:epoch 14 step 700 loss 0.00838
INFO:name:epoch 14 step 800 loss 0.00678
INFO:name:epoch 14 step 900 loss 0.01149
INFO:name:epoch 14 step 1000 loss 0.00824
INFO:name:epoch 14 step 1100 loss 0.0094
INFO:name:epoch 14 step 1200 loss 0.00791
INFO:name:epoch 14 step 1300 loss 0.0123
INFO:name:epoch 14 step 1400 loss 0.00784
INFO:name:epoch 14 step 1500 loss 0.0086
INFO:name:epoch 14 step 1600 loss 0.00963
INFO:name:epoch 14 step 1700 loss 0.00905
INFO:name:epoch 14 step 1800 loss 0.00903
INFO:name:epoch 14 step 1900 loss 0.00985
INFO:name:epoch 14 step 2000 loss 0.00875
INFO:name:epoch 14 step 2100 loss 0.00918
INFO:name:epoch 14 step 2200 loss 0.00965
INFO:name:epoch 14 step 2300 loss 0.00954
INFO:name:epoch 14 step 2400 loss 0.0078
INFO:name:epoch 14 step 2500 loss 0.00814
INFO:name:epoch 14 step 2600 loss 0.00956
INFO:name:epoch 14 step 2700 loss 0.00899
INFO:name:epoch 14 step 2800 loss 0.01023
INFO:name:epoch 14 step 2900 loss 0.00638
INFO:name:epoch 14 step 3000 loss 0.00783
INFO:name:epoch 14 step 3100 loss 0.0071
INFO:name:epoch 14 step 3200 loss 0.00706
INFO:name:epoch 14 step 3300 loss 0.00918
INFO:name:epoch 14 step 3400 loss 0.00731
INFO:name:epoch 14 step 3500 loss 0.00913
INFO:name:epoch 14 step 3600 loss 0.01001
INFO:name:epoch 14 step 3700 loss 0.00803
INFO:name:epoch 14 step 3800 loss 0.0076
INFO:name:epoch 14 step 3900 loss 0.00958
INFO:name:epoch 14 step 4000 loss 0.01043
INFO:name:epoch 14 step 4100 loss 0.01038
INFO:name:epoch 14 step 4200 loss 0.00822
INFO:name:epoch 14 step 4300 loss 0.00814
INFO:name:epoch 14 step 4400 loss 0.00798
INFO:name:epoch 14 step 4500 loss 0.00794
INFO:name:epoch 14 step 4600 loss 0.00661
INFO:name:epoch 14 step 4700 loss 0.00858
INFO:name:epoch 14 step 4800 loss 0.00847
INFO:name:epoch 14 step 4900 loss 0.01086
INFO:name:epoch 14 step 5000 loss 0.0068
INFO:name:epoch 14 step 5100 loss 0.00624
INFO:name:epoch 14 step 5200 loss 0.00816
INFO:name:epoch 14 step 5300 loss 0.00643
INFO:name:epoch 14 step 5400 loss 0.0107
INFO:name:epoch 14 step 5500 loss 0.00865
INFO:name:epoch 14 step 5600 loss 0.00829
INFO:name:epoch 14 step 5700 loss 0.00815
INFO:name:epoch 14 step 5800 loss 0.01004
INFO:name:epoch 14 step 5900 loss 0.00978
INFO:name:epoch 14 step 6000 loss 0.00936
INFO:name:epoch 14 step 6100 loss 0.01001
INFO:name:epoch 14 step 6200 loss 0.01225
INFO:name:epoch 14 step 6300 loss 0.00951
INFO:name:epoch 14 step 6400 loss 0.00906
INFO:name:epoch 14 step 6500 loss 0.01019
INFO:name:epoch 14 step 6600 loss 0.00956
INFO:name:epoch 14 step 6700 loss 0.00763
INFO:name:epoch 14 step 6800 loss 0.00773
INFO:name:epoch 14 step 6900 loss 0.00743
INFO:name:epoch 14 step 7000 loss 0.00711
INFO:name:epoch 14 step 7100 loss 0.00996
INFO:name:epoch 14 step 7200 loss 0.00827
INFO:name:epoch 14 step 7300 loss 0.00906
INFO:name:epoch 14 step 7400 loss 0.00816
INFO:name:epoch 14 step 7500 loss 0.0091
INFO:name:epoch 14 step 7600 loss 0.00793
INFO:name:epoch 14 step 7700 loss 0.00845
INFO:name:epoch 14 step 7800 loss 0.00964
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3784
INFO:name:Saving model checkpoint to ./models/final_model_codeSearch/model.bin
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:[{'insert_modules': ('output',), 'bottleneck_dim': (256,), 'non_linearity': 'relu', 'dropout_rate': 0.2, 'normalization': None, 'skip_connection': True}, 0, 0, 0, {'insert_modules': ('output', 'attention.self', 'attention.output'), 'bottleneck_dim': (128, 32, 32), 'non_linearity': 'relu', 'dropout_rate': 0.15, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.output', 'output', 'intermediate'), 'bottleneck_dim': (64, 128, 64), 'non_linearity': 'leakyrelu', 'dropout_rate': 0.15, 'normalization': None, 'skip_connection': True}, 0, 0, 0, 0, 0, {'insert_modules': ('intermediate', 'attention.self', 'output'), 'bottleneck_dim': (128, 32, 256), 'non_linearity': 'gelu_new', 'dropout_rate': 0.25, 'normalization': None, 'skip_connection': True}]
[INFO|(OpenDelta)basemodel:700]2025-01-09 23:02:01,466 >> Trainable Ratio: 2618464/127264096=2.057504%
[INFO|(OpenDelta)basemodel:702]2025-01-09 23:02:01,466 >> Delta Parameter Ratio: 2618464/127264096=2.057504%
[INFO|(OpenDelta)basemodel:704]2025-01-09 23:02:01,466 >> Static Memory 0.49 GB, Max Memory 7.94 GB
INFO:name:2.9899999999999998
/home/aakli/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:name:***** Running training *****
INFO:name:  Num examples = 251820
INFO:name:  Num Epochs = 15
INFO:name:  Instantaneous batch size per GPU = 32
INFO:name:  Total train batch size  = 32
INFO:name:  Total optimization steps = 118050
train results ([0.18482655808862106, 0.06773693281108409, 0.051199344256923865, 0.03850759940484173, 0.02961303926567965, 0.023304258255807807, 0.019397751583417184, 0.016561113766276142, 0.01425770568923992, 0.0128420729468613, 0.011708663448290793, 0.010695753828330254, 0.00947761142299791, 0.008951803858659978, 0.008732759461781363], [0.36042480583562775, 0.38951521023543223, 0.3784751458352865, 0.39118116696838373, 0.37963868576148746, 0.3825668563971859, 0.3820175781401786, 0.38376212060598425, 0.3743846256907754, 0.3728585011013896, 0.3806335328712275, 0.3786390031050628, 0.38371844012822093, 0.37942222883366017, 0.3783721895293047])
INFO:name:epoch 0 step 100 loss 3.02
INFO:name:epoch 0 step 200 loss 0.73301
INFO:name:epoch 0 step 300 loss 0.35675
INFO:name:epoch 0 step 400 loss 0.27163
INFO:name:epoch 0 step 500 loss 0.22246
INFO:name:epoch 0 step 600 loss 0.21743
INFO:name:epoch 0 step 700 loss 0.22079
INFO:name:epoch 0 step 800 loss 0.19681
INFO:name:epoch 0 step 900 loss 0.1739
INFO:name:epoch 0 step 1000 loss 0.2048
INFO:name:epoch 0 step 1100 loss 0.17134
INFO:name:epoch 0 step 1200 loss 0.16419
INFO:name:epoch 0 step 1300 loss 0.1691
INFO:name:epoch 0 step 1400 loss 0.1527
INFO:name:epoch 0 step 1500 loss 0.15889
INFO:name:epoch 0 step 1600 loss 0.16655
INFO:name:epoch 0 step 1700 loss 0.14438
INFO:name:epoch 0 step 1800 loss 0.15088
INFO:name:epoch 0 step 1900 loss 0.16
INFO:name:epoch 0 step 2000 loss 0.13487
INFO:name:epoch 0 step 2100 loss 0.16456
INFO:name:epoch 0 step 2200 loss 0.14677
INFO:name:epoch 0 step 2300 loss 0.15219
INFO:name:epoch 0 step 2400 loss 0.13864
INFO:name:epoch 0 step 2500 loss 0.13319
INFO:name:epoch 0 step 2600 loss 0.14226
INFO:name:epoch 0 step 2700 loss 0.13507
INFO:name:epoch 0 step 2800 loss 0.14435
INFO:name:epoch 0 step 2900 loss 0.14809
INFO:name:epoch 0 step 3000 loss 0.13528
INFO:name:epoch 0 step 3100 loss 0.13167
INFO:name:epoch 0 step 3200 loss 0.13317
INFO:name:epoch 0 step 3300 loss 0.14261
INFO:name:epoch 0 step 3400 loss 0.14151
INFO:name:epoch 0 step 3500 loss 0.1249
INFO:name:epoch 0 step 3600 loss 0.15416
INFO:name:epoch 0 step 3700 loss 0.13736
INFO:name:epoch 0 step 3800 loss 0.13622
INFO:name:epoch 0 step 3900 loss 0.12775
INFO:name:epoch 0 step 4000 loss 0.14224
INFO:name:epoch 0 step 4100 loss 0.12728
INFO:name:epoch 0 step 4200 loss 0.10365
INFO:name:epoch 0 step 4300 loss 0.14328
INFO:name:epoch 0 step 4400 loss 0.13035
INFO:name:epoch 0 step 4500 loss 0.1172
INFO:name:epoch 0 step 4600 loss 0.11793
INFO:name:epoch 0 step 4700 loss 0.13313
INFO:name:epoch 0 step 4800 loss 0.12659
INFO:name:epoch 0 step 4900 loss 0.1067
INFO:name:epoch 0 step 5000 loss 0.12136
INFO:name:epoch 0 step 5100 loss 0.12417
INFO:name:epoch 0 step 5200 loss 0.1039
INFO:name:epoch 0 step 5300 loss 0.10707
INFO:name:epoch 0 step 5400 loss 0.13654
INFO:name:epoch 0 step 5500 loss 0.11956
INFO:name:epoch 0 step 5600 loss 0.11181
INFO:name:epoch 0 step 5700 loss 0.11574
INFO:name:epoch 0 step 5800 loss 0.12328
INFO:name:epoch 0 step 5900 loss 0.12799
INFO:name:epoch 0 step 6000 loss 0.12825
INFO:name:epoch 0 step 6100 loss 0.13472
INFO:name:epoch 0 step 6200 loss 0.11796
INFO:name:epoch 0 step 6300 loss 0.10742
INFO:name:epoch 0 step 6400 loss 0.10251
INFO:name:epoch 0 step 6500 loss 0.11387
INFO:name:epoch 0 step 6600 loss 0.11728
INFO:name:epoch 0 step 6700 loss 0.09981
INFO:name:epoch 0 step 6800 loss 0.12079
INFO:name:epoch 0 step 6900 loss 0.10991
INFO:name:epoch 0 step 7000 loss 0.11139
INFO:name:epoch 0 step 7100 loss 0.12643
INFO:name:epoch 0 step 7200 loss 0.09798
INFO:name:epoch 0 step 7300 loss 0.11432
INFO:name:epoch 0 step 7400 loss 0.12279
INFO:name:epoch 0 step 7500 loss 0.11478
INFO:name:epoch 0 step 7600 loss 0.11028
INFO:name:epoch 0 step 7700 loss 0.10453
INFO:name:epoch 0 step 7800 loss 0.11017
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3604
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3604
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3009
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 1 step 100 loss 0.09735
INFO:name:epoch 1 step 200 loss 0.07615
INFO:name:epoch 1 step 300 loss 0.05406
INFO:name:epoch 1 step 400 loss 0.06645
INFO:name:epoch 1 step 500 loss 0.07099
INFO:name:epoch 1 step 600 loss 0.07061
INFO:name:epoch 1 step 700 loss 0.07454
INFO:name:epoch 1 step 800 loss 0.05771
INFO:name:epoch 1 step 900 loss 0.07007
INFO:name:epoch 1 step 1000 loss 0.07884
INFO:name:epoch 1 step 1100 loss 0.05832
INFO:name:epoch 1 step 1200 loss 0.06777
INFO:name:epoch 1 step 1300 loss 0.0619
INFO:name:epoch 1 step 1400 loss 0.05092
INFO:name:epoch 1 step 1500 loss 0.06959
INFO:name:epoch 1 step 1600 loss 0.0643
INFO:name:epoch 1 step 1700 loss 0.0657
INFO:name:epoch 1 step 1800 loss 0.08238
INFO:name:epoch 1 step 1900 loss 0.0646
INFO:name:epoch 1 step 2000 loss 0.06742
INFO:name:epoch 1 step 2100 loss 0.08551
INFO:name:epoch 1 step 2200 loss 0.06144
INFO:name:epoch 1 step 2300 loss 0.0841
INFO:name:epoch 1 step 2400 loss 0.06622
INFO:name:epoch 1 step 2500 loss 0.07133
INFO:name:epoch 1 step 2600 loss 0.06379
INFO:name:epoch 1 step 2700 loss 0.07588
INFO:name:epoch 1 step 2800 loss 0.06974
INFO:name:epoch 1 step 2900 loss 0.07615
INFO:name:epoch 1 step 3000 loss 0.06585
INFO:name:epoch 1 step 3100 loss 0.0669
INFO:name:epoch 1 step 3200 loss 0.07656
INFO:name:epoch 1 step 3300 loss 0.06343
INFO:name:epoch 1 step 3400 loss 0.06548
INFO:name:epoch 1 step 3500 loss 0.05794
INFO:name:epoch 1 step 3600 loss 0.06262
INFO:name:epoch 1 step 3700 loss 0.06918
INFO:name:epoch 1 step 3800 loss 0.06848
INFO:name:epoch 1 step 3900 loss 0.07413
INFO:name:epoch 1 step 4000 loss 0.05565
INFO:name:epoch 1 step 4100 loss 0.07883
INFO:name:epoch 1 step 4200 loss 0.06427
INFO:name:epoch 1 step 4300 loss 0.07593
INFO:name:epoch 1 step 4400 loss 0.07219
INFO:name:epoch 1 step 4500 loss 0.06904
INFO:name:epoch 1 step 4600 loss 0.06622
INFO:name:epoch 1 step 4700 loss 0.05242
INFO:name:epoch 1 step 4800 loss 0.07569
INFO:name:epoch 1 step 4900 loss 0.05942
INFO:name:epoch 1 step 5000 loss 0.057
INFO:name:epoch 1 step 5100 loss 0.06279
INFO:name:epoch 1 step 5200 loss 0.06723
INFO:name:epoch 1 step 5300 loss 0.06715
INFO:name:epoch 1 step 5400 loss 0.06628
INFO:name:epoch 1 step 5500 loss 0.06694
INFO:name:epoch 1 step 5600 loss 0.06355
INFO:name:epoch 1 step 5700 loss 0.05775
INFO:name:epoch 1 step 5800 loss 0.07217
INFO:name:epoch 1 step 5900 loss 0.07653
INFO:name:epoch 1 step 6000 loss 0.07024
INFO:name:epoch 1 step 6100 loss 0.07795
INFO:name:epoch 1 step 6200 loss 0.05727
INFO:name:epoch 1 step 6300 loss 0.07239
INFO:name:epoch 1 step 6400 loss 0.05151
INFO:name:epoch 1 step 6500 loss 0.07795
INFO:name:epoch 1 step 6600 loss 0.07545
INFO:name:epoch 1 step 6700 loss 0.06186
INFO:name:epoch 1 step 6800 loss 0.06894
INFO:name:epoch 1 step 6900 loss 0.06915
INFO:name:epoch 1 step 7000 loss 0.08063
INFO:name:epoch 1 step 7100 loss 0.06689
INFO:name:epoch 1 step 7200 loss 0.07461
INFO:name:epoch 1 step 7300 loss 0.06006
INFO:name:epoch 1 step 7400 loss 0.06366
INFO:name:epoch 1 step 7500 loss 0.05798
INFO:name:epoch 1 step 7600 loss 0.05502
INFO:name:epoch 1 step 7700 loss 0.06854
INFO:name:epoch 1 step 7800 loss 0.07042
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3895
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3895
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3271
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 2 step 100 loss 0.05496
INFO:name:epoch 2 step 200 loss 0.05319
INFO:name:epoch 2 step 300 loss 0.05428
INFO:name:epoch 2 step 400 loss 0.05466
INFO:name:epoch 2 step 500 loss 0.05794
INFO:name:epoch 2 step 600 loss 0.04222
INFO:name:epoch 2 step 700 loss 0.04338
INFO:name:epoch 2 step 800 loss 0.05079
INFO:name:epoch 2 step 900 loss 0.04331
INFO:name:epoch 2 step 1000 loss 0.04501
INFO:name:epoch 2 step 1100 loss 0.05891
INFO:name:epoch 2 step 1200 loss 0.05625
INFO:name:epoch 2 step 1300 loss 0.05802
INFO:name:epoch 2 step 1400 loss 0.04271
INFO:name:epoch 2 step 1500 loss 0.05306
INFO:name:epoch 2 step 1600 loss 0.0412
INFO:name:epoch 2 step 1700 loss 0.04471
INFO:name:epoch 2 step 1800 loss 0.04638
INFO:name:epoch 2 step 1900 loss 0.04088
INFO:name:epoch 2 step 2000 loss 0.05478
INFO:name:epoch 2 step 2100 loss 0.05545
INFO:name:epoch 2 step 2200 loss 0.06102
INFO:name:epoch 2 step 2300 loss 0.06468
INFO:name:epoch 2 step 2400 loss 0.05047
INFO:name:epoch 2 step 2500 loss 0.05054
INFO:name:epoch 2 step 2600 loss 0.04967
INFO:name:epoch 2 step 2700 loss 0.05786
INFO:name:epoch 2 step 2800 loss 0.05264
INFO:name:epoch 2 step 2900 loss 0.05016
INFO:name:epoch 2 step 3000 loss 0.05079
INFO:name:epoch 2 step 3100 loss 0.04567
INFO:name:epoch 2 step 3200 loss 0.04578
INFO:name:epoch 2 step 3300 loss 0.05043
INFO:name:epoch 2 step 3400 loss 0.04925
INFO:name:epoch 2 step 3500 loss 0.05219
INFO:name:epoch 2 step 3600 loss 0.04696
INFO:name:epoch 2 step 3700 loss 0.04848
INFO:name:epoch 2 step 3800 loss 0.04449
INFO:name:epoch 2 step 3900 loss 0.04606
INFO:name:epoch 2 step 4000 loss 0.04396
INFO:name:epoch 2 step 4100 loss 0.05676
INFO:name:epoch 2 step 4200 loss 0.04569
INFO:name:epoch 2 step 4300 loss 0.04571
INFO:name:epoch 2 step 4400 loss 0.04959
INFO:name:epoch 2 step 4500 loss 0.04173
INFO:name:epoch 2 step 4600 loss 0.04606
INFO:name:epoch 2 step 4700 loss 0.0591
INFO:name:epoch 2 step 4800 loss 0.05956
INFO:name:epoch 2 step 4900 loss 0.05218
INFO:name:epoch 2 step 5000 loss 0.04866
INFO:name:epoch 2 step 5100 loss 0.05376
INFO:name:epoch 2 step 5200 loss 0.05645
INFO:name:epoch 2 step 5300 loss 0.06747
INFO:name:epoch 2 step 5400 loss 0.04861
INFO:name:epoch 2 step 5500 loss 0.05578
INFO:name:epoch 2 step 5600 loss 0.05322
INFO:name:epoch 2 step 5700 loss 0.06078
INFO:name:epoch 2 step 5800 loss 0.04295
INFO:name:epoch 2 step 5900 loss 0.06325
INFO:name:epoch 2 step 6000 loss 0.04458
INFO:name:epoch 2 step 6100 loss 0.04636
INFO:name:epoch 2 step 6200 loss 0.04355
INFO:name:epoch 2 step 6300 loss 0.04901
INFO:name:epoch 2 step 6400 loss 0.05406
INFO:name:epoch 2 step 6500 loss 0.04325
INFO:name:epoch 2 step 6600 loss 0.05384
INFO:name:epoch 2 step 6700 loss 0.0402
INFO:name:epoch 2 step 6800 loss 0.04315
INFO:name:epoch 2 step 6900 loss 0.05356
INFO:name:epoch 2 step 7000 loss 0.06046
INFO:name:epoch 2 step 7100 loss 0.05941
INFO:name:epoch 2 step 7200 loss 0.05308
INFO:name:epoch 2 step 7300 loss 0.05793
INFO:name:epoch 2 step 7400 loss 0.05388
INFO:name:epoch 2 step 7500 loss 0.06168
INFO:name:epoch 2 step 7600 loss 0.04179
INFO:name:epoch 2 step 7700 loss 0.05745
INFO:name:epoch 2 step 7800 loss 0.05477
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3785
INFO:name:epoch 3 step 100 loss 0.04559
INFO:name:epoch 3 step 200 loss 0.03361
INFO:name:epoch 3 step 300 loss 0.0342
INFO:name:epoch 3 step 400 loss 0.03389
INFO:name:epoch 3 step 500 loss 0.03008
INFO:name:epoch 3 step 600 loss 0.03873
INFO:name:epoch 3 step 700 loss 0.03391
INFO:name:epoch 3 step 800 loss 0.04519
INFO:name:epoch 3 step 900 loss 0.03497
INFO:name:epoch 3 step 1000 loss 0.03986
INFO:name:epoch 3 step 1100 loss 0.04511
INFO:name:epoch 3 step 1200 loss 0.03463
INFO:name:epoch 3 step 1300 loss 0.03745
INFO:name:epoch 3 step 1400 loss 0.03812
INFO:name:epoch 3 step 1500 loss 0.03426
INFO:name:epoch 3 step 1600 loss 0.04137
INFO:name:epoch 3 step 1700 loss 0.03723
INFO:name:epoch 3 step 1800 loss 0.03383
INFO:name:epoch 3 step 1900 loss 0.03576
INFO:name:epoch 3 step 2000 loss 0.03977
INFO:name:epoch 3 step 2100 loss 0.03077
INFO:name:epoch 3 step 2200 loss 0.03776
INFO:name:epoch 3 step 2300 loss 0.03125
INFO:name:epoch 3 step 2400 loss 0.0407
INFO:name:epoch 3 step 2500 loss 0.03966
INFO:name:epoch 3 step 2600 loss 0.0427
INFO:name:epoch 3 step 2700 loss 0.03532
INFO:name:epoch 3 step 2800 loss 0.03998
INFO:name:epoch 3 step 2900 loss 0.03789
INFO:name:epoch 3 step 3000 loss 0.0421
INFO:name:epoch 3 step 3100 loss 0.03451
INFO:name:epoch 3 step 3200 loss 0.03586
INFO:name:epoch 3 step 3300 loss 0.03698
INFO:name:epoch 3 step 3400 loss 0.03711
INFO:name:epoch 3 step 3500 loss 0.03982
INFO:name:epoch 3 step 3600 loss 0.04116
INFO:name:epoch 3 step 3700 loss 0.03943
INFO:name:epoch 3 step 3800 loss 0.03882
INFO:name:epoch 3 step 3900 loss 0.04108
INFO:name:epoch 3 step 4000 loss 0.03825
INFO:name:epoch 3 step 4100 loss 0.03002
INFO:name:epoch 3 step 4200 loss 0.04005
INFO:name:epoch 3 step 4300 loss 0.04178
INFO:name:epoch 3 step 4400 loss 0.04323
INFO:name:epoch 3 step 4500 loss 0.03531
INFO:name:epoch 3 step 4600 loss 0.04084
INFO:name:epoch 3 step 4700 loss 0.04413
INFO:name:epoch 3 step 4800 loss 0.03954
INFO:name:epoch 3 step 4900 loss 0.032
INFO:name:epoch 3 step 5000 loss 0.03701
INFO:name:epoch 3 step 5100 loss 0.03882
INFO:name:epoch 3 step 5200 loss 0.04374
INFO:name:epoch 3 step 5300 loss 0.03609
INFO:name:epoch 3 step 5400 loss 0.04546
INFO:name:epoch 3 step 5500 loss 0.04015
INFO:name:epoch 3 step 5600 loss 0.0513
INFO:name:epoch 3 step 5700 loss 0.03756
INFO:name:epoch 3 step 5800 loss 0.03633
INFO:name:epoch 3 step 5900 loss 0.03655
INFO:name:epoch 3 step 6000 loss 0.03922
INFO:name:epoch 3 step 6100 loss 0.04168
INFO:name:epoch 3 step 6200 loss 0.03617
INFO:name:epoch 3 step 6300 loss 0.04019
INFO:name:epoch 3 step 6400 loss 0.04501
INFO:name:epoch 3 step 6500 loss 0.03938
INFO:name:epoch 3 step 6600 loss 0.04068
INFO:name:epoch 3 step 6700 loss 0.03635
INFO:name:epoch 3 step 6800 loss 0.03318
INFO:name:epoch 3 step 6900 loss 0.04165
INFO:name:epoch 3 step 7000 loss 0.04313
INFO:name:epoch 3 step 7100 loss 0.03501
INFO:name:epoch 3 step 7200 loss 0.03245
INFO:name:epoch 3 step 7300 loss 0.04621
INFO:name:epoch 3 step 7400 loss 0.03901
INFO:name:epoch 3 step 7500 loss 0.04652
INFO:name:epoch 3 step 7600 loss 0.03658
INFO:name:epoch 3 step 7700 loss 0.03741
INFO:name:epoch 3 step 7800 loss 0.04539
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3912
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3912
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3263
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 4 step 100 loss 0.03034
INFO:name:epoch 4 step 200 loss 0.02152
INFO:name:epoch 4 step 300 loss 0.02538
INFO:name:epoch 4 step 400 loss 0.02631
INFO:name:epoch 4 step 500 loss 0.02925
INFO:name:epoch 4 step 600 loss 0.02274
INFO:name:epoch 4 step 700 loss 0.03196
INFO:name:epoch 4 step 800 loss 0.03311
INFO:name:epoch 4 step 900 loss 0.02835
INFO:name:epoch 4 step 1000 loss 0.03206
INFO:name:epoch 4 step 1100 loss 0.02456
INFO:name:epoch 4 step 1200 loss 0.03074
INFO:name:epoch 4 step 1300 loss 0.02969
INFO:name:epoch 4 step 1400 loss 0.02543
INFO:name:epoch 4 step 1500 loss 0.03164
INFO:name:epoch 4 step 1600 loss 0.02815
INFO:name:epoch 4 step 1700 loss 0.02556
INFO:name:epoch 4 step 1800 loss 0.03106
INFO:name:epoch 4 step 1900 loss 0.03395
INFO:name:epoch 4 step 2000 loss 0.02645
INFO:name:epoch 4 step 2100 loss 0.02851
INFO:name:epoch 4 step 2200 loss 0.02718
INFO:name:epoch 4 step 2300 loss 0.02713
INFO:name:epoch 4 step 2400 loss 0.02906
INFO:name:epoch 4 step 2500 loss 0.03439
INFO:name:epoch 4 step 2600 loss 0.03345
INFO:name:epoch 4 step 2700 loss 0.03233
INFO:name:epoch 4 step 2800 loss 0.03036
INFO:name:epoch 4 step 2900 loss 0.03149
INFO:name:epoch 4 step 3000 loss 0.02413
INFO:name:epoch 4 step 3100 loss 0.02695
INFO:name:epoch 4 step 3200 loss 0.02835
INFO:name:epoch 4 step 3300 loss 0.02347
INFO:name:epoch 4 step 3400 loss 0.02994
INFO:name:epoch 4 step 3500 loss 0.03417
INFO:name:epoch 4 step 3600 loss 0.02482
INFO:name:epoch 4 step 3700 loss 0.03612
INFO:name:epoch 4 step 3800 loss 0.029
INFO:name:epoch 4 step 3900 loss 0.02661
INFO:name:epoch 4 step 4000 loss 0.02572
INFO:name:epoch 4 step 4100 loss 0.03249
INFO:name:epoch 4 step 4200 loss 0.0276
INFO:name:epoch 4 step 4300 loss 0.02983
INFO:name:epoch 4 step 4400 loss 0.03529
INFO:name:epoch 4 step 4500 loss 0.02994
INFO:name:epoch 4 step 4600 loss 0.03413
INFO:name:epoch 4 step 4700 loss 0.03507
INFO:name:epoch 4 step 4800 loss 0.02785
INFO:name:epoch 4 step 4900 loss 0.02449
INFO:name:epoch 4 step 5000 loss 0.02917
INFO:name:epoch 4 step 5100 loss 0.0287
INFO:name:epoch 4 step 5200 loss 0.03659
INFO:name:epoch 4 step 5300 loss 0.0282
INFO:name:epoch 4 step 5400 loss 0.0295
INFO:name:epoch 4 step 5500 loss 0.03106
INFO:name:epoch 4 step 5600 loss 0.03107
INFO:name:epoch 4 step 5700 loss 0.03261
INFO:name:epoch 4 step 5800 loss 0.02804
INFO:name:epoch 4 step 5900 loss 0.0284
INFO:name:epoch 4 step 6000 loss 0.03328
INFO:name:epoch 4 step 6100 loss 0.02342
INFO:name:epoch 4 step 6200 loss 0.02945
INFO:name:epoch 4 step 6300 loss 0.02688
INFO:name:epoch 4 step 6400 loss 0.03007
INFO:name:epoch 4 step 6500 loss 0.03004
INFO:name:epoch 4 step 6600 loss 0.03118
INFO:name:epoch 4 step 6700 loss 0.02814
INFO:name:epoch 4 step 6800 loss 0.02768
INFO:name:epoch 4 step 6900 loss 0.02701
INFO:name:epoch 4 step 7000 loss 0.03756
INFO:name:epoch 4 step 7100 loss 0.03038
INFO:name:epoch 4 step 7200 loss 0.02662
INFO:name:epoch 4 step 7300 loss 0.03674
INFO:name:epoch 4 step 7400 loss 0.03699
INFO:name:epoch 4 step 7500 loss 0.03155
INFO:name:epoch 4 step 7600 loss 0.02786
INFO:name:epoch 4 step 7700 loss 0.02989
INFO:name:epoch 4 step 7800 loss 0.03492
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3796
INFO:name:epoch 5 step 100 loss 0.02755
INFO:name:epoch 5 step 200 loss 0.02619
INFO:name:epoch 5 step 300 loss 0.02216
INFO:name:epoch 5 step 400 loss 0.02452
INFO:name:epoch 5 step 500 loss 0.02193
INFO:name:epoch 5 step 600 loss 0.02124
INFO:name:epoch 5 step 700 loss 0.02046
INFO:name:epoch 5 step 800 loss 0.03022
INFO:name:epoch 5 step 900 loss 0.02363
INFO:name:epoch 5 step 1000 loss 0.02196
INFO:name:epoch 5 step 1100 loss 0.02142
INFO:name:epoch 5 step 1200 loss 0.02262
INFO:name:epoch 5 step 1300 loss 0.023
INFO:name:epoch 5 step 1400 loss 0.02232
INFO:name:epoch 5 step 1500 loss 0.02319
INFO:name:epoch 5 step 1600 loss 0.021
INFO:name:epoch 5 step 1700 loss 0.01924
INFO:name:epoch 5 step 1800 loss 0.01623
INFO:name:epoch 5 step 1900 loss 0.02119
INFO:name:epoch 5 step 2000 loss 0.02527
INFO:name:epoch 5 step 2100 loss 0.02627
INFO:name:epoch 5 step 2200 loss 0.0236
INFO:name:epoch 5 step 2300 loss 0.02765
INFO:name:epoch 5 step 2400 loss 0.0243
INFO:name:epoch 5 step 2500 loss 0.02266
INFO:name:epoch 5 step 2600 loss 0.01962
INFO:name:epoch 5 step 2700 loss 0.02077
INFO:name:epoch 5 step 2800 loss 0.02333
INFO:name:epoch 5 step 2900 loss 0.02013
INFO:name:epoch 5 step 3000 loss 0.02488
INFO:name:epoch 5 step 3100 loss 0.02399
INFO:name:epoch 5 step 3200 loss 0.02299
INFO:name:epoch 5 step 3300 loss 0.02089
INFO:name:epoch 5 step 3400 loss 0.02201
INFO:name:epoch 5 step 3500 loss 0.02413
INFO:name:epoch 5 step 3600 loss 0.0246
INFO:name:epoch 5 step 3700 loss 0.02464
INFO:name:epoch 5 step 3800 loss 0.02452
INFO:name:epoch 5 step 3900 loss 0.02176
INFO:name:epoch 5 step 4000 loss 0.0207
INFO:name:epoch 5 step 4100 loss 0.02296
INFO:name:epoch 5 step 4200 loss 0.02636
INFO:name:epoch 5 step 4300 loss 0.02064
INFO:name:epoch 5 step 4400 loss 0.02733
INFO:name:epoch 5 step 4500 loss 0.02396
INFO:name:epoch 5 step 4600 loss 0.0245
INFO:name:epoch 5 step 4700 loss 0.02165
INFO:name:epoch 5 step 4800 loss 0.02305
INFO:name:epoch 5 step 4900 loss 0.02428
INFO:name:epoch 5 step 5000 loss 0.02585
INFO:name:epoch 5 step 5100 loss 0.02258
INFO:name:epoch 5 step 5200 loss 0.02432
INFO:name:epoch 5 step 5300 loss 0.0229
INFO:name:epoch 5 step 5400 loss 0.02767
INFO:name:epoch 5 step 5500 loss 0.02238
INFO:name:epoch 5 step 5600 loss 0.01956
INFO:name:epoch 5 step 5700 loss 0.02329
INFO:name:epoch 5 step 5800 loss 0.0219
INFO:name:epoch 5 step 5900 loss 0.021
INFO:name:epoch 5 step 6000 loss 0.02868
INFO:name:epoch 5 step 6100 loss 0.0218
INFO:name:epoch 5 step 6200 loss 0.02219
INFO:name:epoch 5 step 6300 loss 0.02553
INFO:name:epoch 5 step 6400 loss 0.02657
INFO:name:epoch 5 step 6500 loss 0.02256
INFO:name:epoch 5 step 6600 loss 0.01805
INFO:name:epoch 5 step 6700 loss 0.02741
INFO:name:epoch 5 step 6800 loss 0.02573
INFO:name:epoch 5 step 6900 loss 0.02727
INFO:name:epoch 5 step 7000 loss 0.0228
INFO:name:epoch 5 step 7100 loss 0.02308
INFO:name:epoch 5 step 7200 loss 0.02367
INFO:name:epoch 5 step 7300 loss 0.025
INFO:name:epoch 5 step 7400 loss 0.02418
INFO:name:epoch 5 step 7500 loss 0.02083
INFO:name:epoch 5 step 7600 loss 0.02263
INFO:name:epoch 5 step 7700 loss 0.02457
INFO:name:epoch 5 step 7800 loss 0.02236
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3826
INFO:name:epoch 6 step 100 loss 0.02042
INFO:name:epoch 6 step 200 loss 0.01941
INFO:name:epoch 6 step 300 loss 0.01452
INFO:name:epoch 6 step 400 loss 0.02363
INFO:name:epoch 6 step 500 loss 0.01795
INFO:name:epoch 6 step 600 loss 0.01725
INFO:name:epoch 6 step 700 loss 0.02085
INFO:name:epoch 6 step 800 loss 0.0165
INFO:name:epoch 6 step 900 loss 0.0168
INFO:name:epoch 6 step 1000 loss 0.01715
INFO:name:epoch 6 step 1100 loss 0.01937
INFO:name:epoch 6 step 1200 loss 0.02053
INFO:name:epoch 6 step 1300 loss 0.0226
INFO:name:epoch 6 step 1400 loss 0.01694
INFO:name:epoch 6 step 1500 loss 0.02021
INFO:name:epoch 6 step 1600 loss 0.01731
INFO:name:epoch 6 step 1700 loss 0.01819
INFO:name:epoch 6 step 1800 loss 0.02276
INFO:name:epoch 6 step 1900 loss 0.01823
INFO:name:epoch 6 step 2000 loss 0.02209
INFO:name:epoch 6 step 2100 loss 0.02124
INFO:name:epoch 6 step 2200 loss 0.01858
INFO:name:epoch 6 step 2300 loss 0.01899
INFO:name:epoch 6 step 2400 loss 0.01732
INFO:name:epoch 6 step 2500 loss 0.01701
INFO:name:epoch 6 step 2600 loss 0.01882
INFO:name:epoch 6 step 2700 loss 0.02433
INFO:name:epoch 6 step 2800 loss 0.01686
INFO:name:epoch 6 step 2900 loss 0.0226
INFO:name:epoch 6 step 3000 loss 0.01705
INFO:name:epoch 6 step 3100 loss 0.01844
INFO:name:epoch 6 step 3200 loss 0.02003
INFO:name:epoch 6 step 3300 loss 0.0172
INFO:name:epoch 6 step 3400 loss 0.01739
INFO:name:epoch 6 step 3500 loss 0.01608
INFO:name:epoch 6 step 3600 loss 0.01651
INFO:name:epoch 6 step 3700 loss 0.02397
INFO:name:epoch 6 step 3800 loss 0.02165
INFO:name:epoch 6 step 3900 loss 0.01855
INFO:name:epoch 6 step 4000 loss 0.01848
INFO:name:epoch 6 step 4100 loss 0.01745
INFO:name:epoch 6 step 4200 loss 0.02302
INFO:name:epoch 6 step 4300 loss 0.0203
INFO:name:epoch 6 step 4400 loss 0.02047
INFO:name:epoch 6 step 4500 loss 0.01996
INFO:name:epoch 6 step 4600 loss 0.01743
INFO:name:epoch 6 step 4700 loss 0.01851
INFO:name:epoch 6 step 4800 loss 0.01767
INFO:name:epoch 6 step 4900 loss 0.01695
INFO:name:epoch 6 step 5000 loss 0.01981
INFO:name:epoch 6 step 5100 loss 0.01942
INFO:name:epoch 6 step 5200 loss 0.0213
INFO:name:epoch 6 step 5300 loss 0.01551
INFO:name:epoch 6 step 5400 loss 0.02015
INFO:name:epoch 6 step 5500 loss 0.01428
INFO:name:epoch 6 step 5600 loss 0.01765
INFO:name:epoch 6 step 5700 loss 0.01798
INFO:name:epoch 6 step 5800 loss 0.02253
INFO:name:epoch 6 step 5900 loss 0.02046
INFO:name:epoch 6 step 6000 loss 0.01956
INFO:name:epoch 6 step 6100 loss 0.0196
INFO:name:epoch 6 step 6200 loss 0.02024
INFO:name:epoch 6 step 6300 loss 0.02049
INFO:name:epoch 6 step 6400 loss 0.02576
INFO:name:epoch 6 step 6500 loss 0.01834
INFO:name:epoch 6 step 6600 loss 0.02096
INFO:name:epoch 6 step 6700 loss 0.01818
INFO:name:epoch 6 step 6800 loss 0.01973
INFO:name:epoch 6 step 6900 loss 0.01799
INFO:name:epoch 6 step 7000 loss 0.02303
INFO:name:epoch 6 step 7100 loss 0.02257
INFO:name:epoch 6 step 7200 loss 0.01662
INFO:name:epoch 6 step 7300 loss 0.02261
INFO:name:epoch 6 step 7400 loss 0.02116
INFO:name:epoch 6 step 7500 loss 0.02196
INFO:name:epoch 6 step 7600 loss 0.02036
INFO:name:epoch 6 step 7700 loss 0.02081
INFO:name:epoch 6 step 7800 loss 0.02168
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.382
INFO:name:epoch 7 step 100 loss 0.01725
INFO:name:epoch 7 step 200 loss 0.01648
INFO:name:epoch 7 step 300 loss 0.01739
INFO:name:epoch 7 step 400 loss 0.01551
INFO:name:epoch 7 step 500 loss 0.01381
INFO:name:epoch 7 step 600 loss 0.01618
INFO:name:epoch 7 step 700 loss 0.01813
INFO:name:epoch 7 step 800 loss 0.01316
INFO:name:epoch 7 step 900 loss 0.01502
INFO:name:epoch 7 step 1000 loss 0.01531
INFO:name:epoch 7 step 1100 loss 0.01566
INFO:name:epoch 7 step 1200 loss 0.01648
INFO:name:epoch 7 step 1300 loss 0.01515
INFO:name:epoch 7 step 1400 loss 0.01399
INFO:name:epoch 7 step 1500 loss 0.01413
INFO:name:epoch 7 step 1600 loss 0.01959
INFO:name:epoch 7 step 1700 loss 0.01599
INFO:name:epoch 7 step 1800 loss 0.02198
INFO:name:epoch 7 step 1900 loss 0.01231
INFO:name:epoch 7 step 2000 loss 0.01422
INFO:name:epoch 7 step 2100 loss 0.01455
INFO:name:epoch 7 step 2200 loss 0.01751
INFO:name:epoch 7 step 2300 loss 0.01882
INFO:name:epoch 7 step 2400 loss 0.01757
INFO:name:epoch 7 step 2500 loss 0.01872
INFO:name:epoch 7 step 2600 loss 0.01313
INFO:name:epoch 7 step 2700 loss 0.01679
INFO:name:epoch 7 step 2800 loss 0.01534
INFO:name:epoch 7 step 2900 loss 0.01713
INFO:name:epoch 7 step 3000 loss 0.01689
INFO:name:epoch 7 step 3100 loss 0.0141
INFO:name:epoch 7 step 3200 loss 0.01555
INFO:name:epoch 7 step 3300 loss 0.01664
INFO:name:epoch 7 step 3400 loss 0.01563
INFO:name:epoch 7 step 3500 loss 0.01955
INFO:name:epoch 7 step 3600 loss 0.01615
INFO:name:epoch 7 step 3700 loss 0.01879
INFO:name:epoch 7 step 3800 loss 0.01419
INFO:name:epoch 7 step 3900 loss 0.01776
INFO:name:epoch 7 step 4000 loss 0.01736
INFO:name:epoch 7 step 4100 loss 0.01769
INFO:name:epoch 7 step 4200 loss 0.01765
INFO:name:epoch 7 step 4300 loss 0.01407
INFO:name:epoch 7 step 4400 loss 0.02235
INFO:name:epoch 7 step 4500 loss 0.01933
INFO:name:epoch 7 step 4600 loss 0.0172
INFO:name:epoch 7 step 4700 loss 0.01744
INFO:name:epoch 7 step 4800 loss 0.01491
INFO:name:epoch 7 step 4900 loss 0.01739
INFO:name:epoch 7 step 5000 loss 0.01775
INFO:name:epoch 7 step 5100 loss 0.01668
INFO:name:epoch 7 step 5200 loss 0.0168
INFO:name:epoch 7 step 5300 loss 0.01518
INFO:name:epoch 7 step 5400 loss 0.01539
INFO:name:epoch 7 step 5500 loss 0.01831
INFO:name:epoch 7 step 5600 loss 0.01565
INFO:name:epoch 7 step 5700 loss 0.01789
INFO:name:epoch 7 step 5800 loss 0.01643
INFO:name:epoch 7 step 5900 loss 0.01972
INFO:name:epoch 7 step 6000 loss 0.01779
INFO:name:epoch 7 step 6100 loss 0.01595
INFO:name:epoch 7 step 6200 loss 0.01953
INFO:name:epoch 7 step 6300 loss 0.01636
INFO:name:epoch 7 step 6400 loss 0.01521
INFO:name:epoch 7 step 6500 loss 0.01576
INFO:name:epoch 7 step 6600 loss 0.01464
INFO:name:epoch 7 step 6700 loss 0.0158
INFO:name:epoch 7 step 6800 loss 0.01622
INFO:name:epoch 7 step 6900 loss 0.01541
INFO:name:epoch 7 step 7000 loss 0.01869
INFO:name:epoch 7 step 7100 loss 0.01903
INFO:name:epoch 7 step 7200 loss 0.01611
INFO:name:epoch 7 step 7300 loss 0.01884
INFO:name:epoch 7 step 7400 loss 0.01578
INFO:name:epoch 7 step 7500 loss 0.01569
INFO:name:epoch 7 step 7600 loss 0.01596
INFO:name:epoch 7 step 7700 loss 0.01769
INFO:name:epoch 7 step 7800 loss 0.01796
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3838
INFO:name:epoch 8 step 100 loss 0.01337
INFO:name:epoch 8 step 200 loss 0.01394
INFO:name:epoch 8 step 300 loss 0.01729
INFO:name:epoch 8 step 400 loss 0.01428
INFO:name:epoch 8 step 500 loss 0.01262
INFO:name:epoch 8 step 600 loss 0.01178
INFO:name:epoch 8 step 700 loss 0.01317
INFO:name:epoch 8 step 800 loss 0.01474
INFO:name:epoch 8 step 900 loss 0.01195
INFO:name:epoch 8 step 1000 loss 0.01538
INFO:name:epoch 8 step 1100 loss 0.01285
INFO:name:epoch 8 step 1200 loss 0.0132
INFO:name:epoch 8 step 1300 loss 0.01573
INFO:name:epoch 8 step 1400 loss 0.01356
INFO:name:epoch 8 step 1500 loss 0.01185
INFO:name:epoch 8 step 1600 loss 0.01298
INFO:name:epoch 8 step 1700 loss 0.01447
INFO:name:epoch 8 step 1800 loss 0.01414
INFO:name:epoch 8 step 1900 loss 0.01568
INFO:name:epoch 8 step 2000 loss 0.0108
INFO:name:epoch 8 step 2100 loss 0.01658
INFO:name:epoch 8 step 2200 loss 0.01401
INFO:name:epoch 8 step 2300 loss 0.01171
INFO:name:epoch 8 step 2400 loss 0.01475
INFO:name:epoch 8 step 2500 loss 0.01777
INFO:name:epoch 8 step 2600 loss 0.0142
INFO:name:epoch 8 step 2700 loss 0.01495
INFO:name:epoch 8 step 2800 loss 0.01464
INFO:name:epoch 8 step 2900 loss 0.01755
INFO:name:epoch 8 step 3000 loss 0.01481
INFO:name:epoch 8 step 3100 loss 0.01197
INFO:name:epoch 8 step 3200 loss 0.01618
INFO:name:epoch 8 step 3300 loss 0.01457
INFO:name:epoch 8 step 3400 loss 0.0137
INFO:name:epoch 8 step 3500 loss 0.01519
INFO:name:epoch 8 step 3600 loss 0.01397
INFO:name:epoch 8 step 3700 loss 0.0137
INFO:name:epoch 8 step 3800 loss 0.01346
INFO:name:epoch 8 step 3900 loss 0.01539
INFO:name:epoch 8 step 4000 loss 0.01582
INFO:name:epoch 8 step 4100 loss 0.01424
INFO:name:epoch 8 step 4200 loss 0.01449
INFO:name:epoch 8 step 4300 loss 0.01609
INFO:name:epoch 8 step 4400 loss 0.01565
INFO:name:epoch 8 step 4500 loss 0.01233
INFO:name:epoch 8 step 4600 loss 0.01513
INFO:name:epoch 8 step 4700 loss 0.01355
INFO:name:epoch 8 step 4800 loss 0.01479
INFO:name:epoch 8 step 4900 loss 0.01347
INFO:name:epoch 8 step 5000 loss 0.0121
INFO:name:epoch 8 step 5100 loss 0.01646
INFO:name:epoch 8 step 5200 loss 0.01181
INFO:name:epoch 8 step 5300 loss 0.01398
INFO:name:epoch 8 step 5400 loss 0.01365
INFO:name:epoch 8 step 5500 loss 0.01312
INFO:name:epoch 8 step 5600 loss 0.01419
INFO:name:epoch 8 step 5700 loss 0.01363
INFO:name:epoch 8 step 5800 loss 0.01509
INFO:name:epoch 8 step 5900 loss 0.01512
INFO:name:epoch 8 step 6000 loss 0.01401
INFO:name:epoch 8 step 6100 loss 0.01682
INFO:name:epoch 8 step 6200 loss 0.01431
INFO:name:epoch 8 step 6300 loss 0.01414
INFO:name:epoch 8 step 6400 loss 0.01624
INFO:name:epoch 8 step 6500 loss 0.01114
INFO:name:epoch 8 step 6600 loss 0.01303
INFO:name:epoch 8 step 6700 loss 0.0162
INFO:name:epoch 8 step 6800 loss 0.01506
INFO:name:epoch 8 step 6900 loss 0.01705
INFO:name:epoch 8 step 7000 loss 0.01258
INFO:name:epoch 8 step 7100 loss 0.01307
INFO:name:epoch 8 step 7200 loss 0.01304
INFO:name:epoch 8 step 7300 loss 0.01524
INFO:name:epoch 8 step 7400 loss 0.01482
INFO:name:epoch 8 step 7500 loss 0.01474
INFO:name:epoch 8 step 7600 loss 0.01533
INFO:name:epoch 8 step 7700 loss 0.01354
INFO:name:epoch 8 step 7800 loss 0.01561
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3744
INFO:name:epoch 9 step 100 loss 0.01128
INFO:name:epoch 9 step 200 loss 0.01272
INFO:name:epoch 9 step 300 loss 0.0102
INFO:name:epoch 9 step 400 loss 0.01156
INFO:name:epoch 9 step 500 loss 0.01238
INFO:name:epoch 9 step 600 loss 0.01406
INFO:name:epoch 9 step 700 loss 0.01165
INFO:name:epoch 9 step 800 loss 0.01271
INFO:name:epoch 9 step 900 loss 0.0101
INFO:name:epoch 9 step 1000 loss 0.01095
INFO:name:epoch 9 step 1100 loss 0.01545
INFO:name:epoch 9 step 1200 loss 0.01569
INFO:name:epoch 9 step 1300 loss 0.01623
INFO:name:epoch 9 step 1400 loss 0.01215
INFO:name:epoch 9 step 1500 loss 0.01305
INFO:name:epoch 9 step 1600 loss 0.01202
INFO:name:epoch 9 step 1700 loss 0.01439
INFO:name:epoch 9 step 1800 loss 0.01009
INFO:name:epoch 9 step 1900 loss 0.01248
INFO:name:epoch 9 step 2000 loss 0.01343
INFO:name:epoch 9 step 2100 loss 0.01395
INFO:name:epoch 9 step 2200 loss 0.01054
INFO:name:epoch 9 step 2300 loss 0.01185
INFO:name:epoch 9 step 2400 loss 0.01373
INFO:name:epoch 9 step 2500 loss 0.01139
INFO:name:epoch 9 step 2600 loss 0.01071
INFO:name:epoch 9 step 2700 loss 0.01333
INFO:name:epoch 9 step 2800 loss 0.01409
INFO:name:epoch 9 step 2900 loss 0.01095
INFO:name:epoch 9 step 3000 loss 0.01324
INFO:name:epoch 9 step 3100 loss 0.01261
INFO:name:epoch 9 step 3200 loss 0.01298
INFO:name:epoch 9 step 3300 loss 0.01192
INFO:name:epoch 9 step 3400 loss 0.01231
INFO:name:epoch 9 step 3500 loss 0.01299
INFO:name:epoch 9 step 3600 loss 0.01164
INFO:name:epoch 9 step 3700 loss 0.01046
INFO:name:epoch 9 step 3800 loss 0.00981
INFO:name:epoch 9 step 3900 loss 0.01017
INFO:name:epoch 9 step 4000 loss 0.01277
INFO:name:epoch 9 step 4100 loss 0.00876
INFO:name:epoch 9 step 4200 loss 0.01352
INFO:name:epoch 9 step 4300 loss 0.01251
INFO:name:epoch 9 step 4400 loss 0.0116
INFO:name:epoch 9 step 4500 loss 0.01186
INFO:name:epoch 9 step 4600 loss 0.01299
INFO:name:epoch 9 step 4700 loss 0.00998
INFO:name:epoch 9 step 4800 loss 0.01274
INFO:name:epoch 9 step 4900 loss 0.01286
INFO:name:epoch 9 step 5000 loss 0.0113
INFO:name:epoch 9 step 5100 loss 0.01414
INFO:name:epoch 9 step 5200 loss 0.01358
INFO:name:epoch 9 step 5300 loss 0.01365
INFO:name:epoch 9 step 5400 loss 0.01418
INFO:name:epoch 9 step 5500 loss 0.01144
INFO:name:epoch 9 step 5600 loss 0.01329
INFO:name:epoch 9 step 5700 loss 0.01789
INFO:name:epoch 9 step 5800 loss 0.01335
INFO:name:epoch 9 step 5900 loss 0.01195
INFO:name:epoch 9 step 6000 loss 0.01348
INFO:name:epoch 9 step 6100 loss 0.0147
INFO:name:epoch 9 step 6200 loss 0.01278
INFO:name:epoch 9 step 6300 loss 0.0171
INFO:name:epoch 9 step 6400 loss 0.01351
INFO:name:epoch 9 step 6500 loss 0.0139
INFO:name:epoch 9 step 6600 loss 0.01449
INFO:name:epoch 9 step 6700 loss 0.01763
INFO:name:epoch 9 step 6800 loss 0.01077
INFO:name:epoch 9 step 6900 loss 0.01427
INFO:name:epoch 9 step 7000 loss 0.01403
INFO:name:epoch 9 step 7100 loss 0.01079
INFO:name:epoch 9 step 7200 loss 0.01507
INFO:name:epoch 9 step 7300 loss 0.01377
INFO:name:epoch 9 step 7400 loss 0.01242
INFO:name:epoch 9 step 7500 loss 0.01286
INFO:name:epoch 9 step 7600 loss 0.01404
INFO:name:epoch 9 step 7700 loss 0.01384
INFO:name:epoch 9 step 7800 loss 0.01383
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3729
INFO:name:epoch 10 step 100 loss 0.01284
INFO:name:epoch 10 step 200 loss 0.00991
INFO:name:epoch 10 step 300 loss 0.01128
INFO:name:epoch 10 step 400 loss 0.01389
INFO:name:epoch 10 step 500 loss 0.01258
INFO:name:epoch 10 step 600 loss 0.01139
INFO:name:epoch 10 step 700 loss 0.01066
INFO:name:epoch 10 step 800 loss 0.01068
INFO:name:epoch 10 step 900 loss 0.01091
INFO:name:epoch 10 step 1000 loss 0.01199
INFO:name:epoch 10 step 1100 loss 0.01096
INFO:name:epoch 10 step 1200 loss 0.01297
INFO:name:epoch 10 step 1300 loss 0.01031
INFO:name:epoch 10 step 1400 loss 0.00942
INFO:name:epoch 10 step 1500 loss 0.01231
INFO:name:epoch 10 step 1600 loss 0.01242
INFO:name:epoch 10 step 1700 loss 0.01078
INFO:name:epoch 10 step 1800 loss 0.01292
INFO:name:epoch 10 step 1900 loss 0.01181
INFO:name:epoch 10 step 2000 loss 0.01187
INFO:name:epoch 10 step 2100 loss 0.01282
INFO:name:epoch 10 step 2200 loss 0.00885
INFO:name:epoch 10 step 2300 loss 0.01346
INFO:name:epoch 10 step 2400 loss 0.01232
INFO:name:epoch 10 step 2500 loss 0.01086
INFO:name:epoch 10 step 2600 loss 0.0129
INFO:name:epoch 10 step 2700 loss 0.01397
INFO:name:epoch 10 step 2800 loss 0.01227
INFO:name:epoch 10 step 2900 loss 0.01004
INFO:name:epoch 10 step 3000 loss 0.01237
INFO:name:epoch 10 step 3100 loss 0.01144
INFO:name:epoch 10 step 3200 loss 0.01247
INFO:name:epoch 10 step 3300 loss 0.00877
INFO:name:epoch 10 step 3400 loss 0.01101
INFO:name:epoch 10 step 3500 loss 0.01173
INFO:name:epoch 10 step 3600 loss 0.0117
INFO:name:epoch 10 step 3700 loss 0.00774
INFO:name:epoch 10 step 3800 loss 0.01241
INFO:name:epoch 10 step 3900 loss 0.01059
INFO:name:epoch 10 step 4000 loss 0.01422
INFO:name:epoch 10 step 4100 loss 0.01252
INFO:name:epoch 10 step 4200 loss 0.01421
INFO:name:epoch 10 step 4300 loss 0.01084
INFO:name:epoch 10 step 4400 loss 0.01024
INFO:name:epoch 10 step 4500 loss 0.01263
INFO:name:epoch 10 step 4600 loss 0.01313
INFO:name:epoch 10 step 4700 loss 0.01275
INFO:name:epoch 10 step 4800 loss 0.01045
INFO:name:epoch 10 step 4900 loss 0.01227
INFO:name:epoch 10 step 5000 loss 0.01144
INFO:name:epoch 10 step 5100 loss 0.01215
INFO:name:epoch 10 step 5200 loss 0.00997
INFO:name:epoch 10 step 5300 loss 0.01172
INFO:name:epoch 10 step 5400 loss 0.01018
INFO:name:epoch 10 step 5500 loss 0.01079
INFO:name:epoch 10 step 5600 loss 0.01137
INFO:name:epoch 10 step 5700 loss 0.01377
INFO:name:epoch 10 step 5800 loss 0.01221
INFO:name:epoch 10 step 5900 loss 0.0106
INFO:name:epoch 10 step 6000 loss 0.01535
INFO:name:epoch 10 step 6100 loss 0.01315
INFO:name:epoch 10 step 6200 loss 0.01254
INFO:name:epoch 10 step 6300 loss 0.01034
INFO:name:epoch 10 step 6400 loss 0.00916
INFO:name:epoch 10 step 6500 loss 0.01472
INFO:name:epoch 10 step 6600 loss 0.01231
INFO:name:epoch 10 step 6700 loss 0.01035
INFO:name:epoch 10 step 6800 loss 0.01085
INFO:name:epoch 10 step 6900 loss 0.01152
INFO:name:epoch 10 step 7000 loss 0.01183
INFO:name:epoch 10 step 7100 loss 0.01163
INFO:name:epoch 10 step 7200 loss 0.01131
INFO:name:epoch 10 step 7300 loss 0.01353
INFO:name:epoch 10 step 7400 loss 0.00995
INFO:name:epoch 10 step 7500 loss 0.01069
INFO:name:epoch 10 step 7600 loss 0.01132
INFO:name:epoch 10 step 7700 loss 0.01728
INFO:name:epoch 10 step 7800 loss 0.0128
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3806
INFO:name:epoch 11 step 100 loss 0.01085
INFO:name:epoch 11 step 200 loss 0.01053
INFO:name:epoch 11 step 300 loss 0.01039
INFO:name:epoch 11 step 400 loss 0.0087
INFO:name:epoch 11 step 500 loss 0.00948
INFO:name:epoch 11 step 600 loss 0.00933
INFO:name:epoch 11 step 700 loss 0.00881
INFO:name:epoch 11 step 800 loss 0.01155
INFO:name:epoch 11 step 900 loss 0.00919
INFO:name:epoch 11 step 1000 loss 0.0106
INFO:name:epoch 11 step 1100 loss 0.00991
INFO:name:epoch 11 step 1200 loss 0.00974
INFO:name:epoch 11 step 1300 loss 0.01056
INFO:name:epoch 11 step 1400 loss 0.00932
INFO:name:epoch 11 step 1500 loss 0.00822
INFO:name:epoch 11 step 1600 loss 0.01044
INFO:name:epoch 11 step 1700 loss 0.01287
INFO:name:epoch 11 step 1800 loss 0.01046
INFO:name:epoch 11 step 1900 loss 0.00829
INFO:name:epoch 11 step 2000 loss 0.01166
INFO:name:epoch 11 step 2100 loss 0.01339
INFO:name:epoch 11 step 2200 loss 0.00997
INFO:name:epoch 11 step 2300 loss 0.0126
INFO:name:epoch 11 step 2400 loss 0.01036
INFO:name:epoch 11 step 2500 loss 0.01256
INFO:name:epoch 11 step 2600 loss 0.01109
INFO:name:epoch 11 step 2700 loss 0.01267
INFO:name:epoch 11 step 2800 loss 0.01104
INFO:name:epoch 11 step 2900 loss 0.01008
INFO:name:epoch 11 step 3000 loss 0.01171
INFO:name:epoch 11 step 3100 loss 0.0137
INFO:name:epoch 11 step 3200 loss 0.01212
INFO:name:epoch 11 step 3300 loss 0.01048
INFO:name:epoch 11 step 3400 loss 0.00963
INFO:name:epoch 11 step 3500 loss 0.00904
INFO:name:epoch 11 step 3600 loss 0.01127
INFO:name:epoch 11 step 3700 loss 0.00958
INFO:name:epoch 11 step 3800 loss 0.0078
INFO:name:epoch 11 step 3900 loss 0.00979
INFO:name:epoch 11 step 4000 loss 0.01066
INFO:name:epoch 11 step 4100 loss 0.013
INFO:name:epoch 11 step 4200 loss 0.01025
INFO:name:epoch 11 step 4300 loss 0.01135
INFO:name:epoch 11 step 4400 loss 0.01083
INFO:name:epoch 11 step 4500 loss 0.00795
INFO:name:epoch 11 step 4600 loss 0.00863
INFO:name:epoch 11 step 4700 loss 0.01503
INFO:name:epoch 11 step 4800 loss 0.01098
INFO:name:epoch 11 step 4900 loss 0.00981
INFO:name:epoch 11 step 5000 loss 0.0106
INFO:name:epoch 11 step 5100 loss 0.00961
INFO:name:epoch 11 step 5200 loss 0.01281
INFO:name:epoch 11 step 5300 loss 0.00904
INFO:name:epoch 11 step 5400 loss 0.01009
INFO:name:epoch 11 step 5500 loss 0.01061
INFO:name:epoch 11 step 5600 loss 0.01212
INFO:name:epoch 11 step 5700 loss 0.01012
INFO:name:epoch 11 step 5800 loss 0.01151
INFO:name:epoch 11 step 5900 loss 0.00973
INFO:name:epoch 11 step 6000 loss 0.01175
INFO:name:epoch 11 step 6100 loss 0.00837
INFO:name:epoch 11 step 6200 loss 0.01204
INFO:name:epoch 11 step 6300 loss 0.00882
INFO:name:epoch 11 step 6400 loss 0.01141
INFO:name:epoch 11 step 6500 loss 0.01209
INFO:name:epoch 11 step 6600 loss 0.00999
INFO:name:epoch 11 step 6700 loss 0.01028
INFO:name:epoch 11 step 6800 loss 0.01183
INFO:name:epoch 11 step 6900 loss 0.01242
INFO:name:epoch 11 step 7000 loss 0.0098
INFO:name:epoch 11 step 7100 loss 0.01205
INFO:name:epoch 11 step 7200 loss 0.01239
INFO:name:epoch 11 step 7300 loss 0.01134
INFO:name:epoch 11 step 7400 loss 0.00956
INFO:name:epoch 11 step 7500 loss 0.01099
INFO:name:epoch 11 step 7600 loss 0.00984
INFO:name:epoch 11 step 7700 loss 0.01256
INFO:name:epoch 11 step 7800 loss 0.01219
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3786
INFO:name:epoch 12 step 100 loss 0.0116
INFO:name:epoch 12 step 200 loss 0.00993
INFO:name:epoch 12 step 300 loss 0.00858
INFO:name:epoch 12 step 400 loss 0.0107
INFO:name:epoch 12 step 500 loss 0.00754
INFO:name:epoch 12 step 600 loss 0.00857
INFO:name:epoch 12 step 700 loss 0.00752
INFO:name:epoch 12 step 800 loss 0.00958
INFO:name:epoch 12 step 900 loss 0.00874
INFO:name:epoch 12 step 1000 loss 0.01188
INFO:name:epoch 12 step 1100 loss 0.00994
INFO:name:epoch 12 step 1200 loss 0.00903
INFO:name:epoch 12 step 1300 loss 0.00919
INFO:name:epoch 12 step 1400 loss 0.01119
INFO:name:epoch 12 step 1500 loss 0.01086
INFO:name:epoch 12 step 1600 loss 0.01036
INFO:name:epoch 12 step 1700 loss 0.01012
INFO:name:epoch 12 step 1800 loss 0.00709
INFO:name:epoch 12 step 1900 loss 0.00955
INFO:name:epoch 12 step 2000 loss 0.01046
INFO:name:epoch 12 step 2100 loss 0.00773
INFO:name:epoch 12 step 2200 loss 0.00888
INFO:name:epoch 12 step 2300 loss 0.00859
INFO:name:epoch 12 step 2400 loss 0.00773
INFO:name:epoch 12 step 2500 loss 0.01061
INFO:name:epoch 12 step 2600 loss 0.01172
INFO:name:epoch 12 step 2700 loss 0.00996
INFO:name:epoch 12 step 2800 loss 0.00975
INFO:name:epoch 12 step 2900 loss 0.00709
INFO:name:epoch 12 step 3000 loss 0.00949
INFO:name:epoch 12 step 3100 loss 0.00968
INFO:name:epoch 12 step 3200 loss 0.00825
INFO:name:epoch 12 step 3300 loss 0.00911
INFO:name:epoch 12 step 3400 loss 0.00947
INFO:name:epoch 12 step 3500 loss 0.01025
INFO:name:epoch 12 step 3600 loss 0.00996
INFO:name:epoch 12 step 3700 loss 0.00982
INFO:name:epoch 12 step 3800 loss 0.00859
INFO:name:epoch 12 step 3900 loss 0.00713
INFO:name:epoch 12 step 4000 loss 0.01144
INFO:name:epoch 12 step 4100 loss 0.00885
INFO:name:epoch 12 step 4200 loss 0.00976
INFO:name:epoch 12 step 4300 loss 0.00974
INFO:name:epoch 12 step 4400 loss 0.0069
INFO:name:epoch 12 step 4500 loss 0.00945
INFO:name:epoch 12 step 4600 loss 0.00838
INFO:name:epoch 12 step 4700 loss 0.00919
INFO:name:epoch 12 step 4800 loss 0.00932
INFO:name:epoch 12 step 4900 loss 0.00927
INFO:name:epoch 12 step 5000 loss 0.01092
INFO:name:epoch 12 step 5100 loss 0.01325
INFO:name:epoch 12 step 5200 loss 0.00889
INFO:name:epoch 12 step 5300 loss 0.00642
INFO:name:epoch 12 step 5400 loss 0.00882
INFO:name:epoch 12 step 5500 loss 0.0091
INFO:name:epoch 12 step 5600 loss 0.00863
INFO:name:epoch 12 step 5700 loss 0.01146
INFO:name:epoch 12 step 5800 loss 0.01115
INFO:name:epoch 12 step 5900 loss 0.01117
INFO:name:epoch 12 step 6000 loss 0.0088
INFO:name:epoch 12 step 6100 loss 0.01412
INFO:name:epoch 12 step 6200 loss 0.01007
INFO:name:epoch 12 step 6300 loss 0.00836
INFO:name:epoch 12 step 6400 loss 0.01018
INFO:name:epoch 12 step 6500 loss 0.00847
INFO:name:epoch 12 step 6600 loss 0.01032
INFO:name:epoch 12 step 6700 loss 0.00736
INFO:name:epoch 12 step 6800 loss 0.00971
INFO:name:epoch 12 step 6900 loss 0.0084
INFO:name:epoch 12 step 7000 loss 0.00906
INFO:name:epoch 12 step 7100 loss 0.00711
INFO:name:epoch 12 step 7200 loss 0.00892
INFO:name:epoch 12 step 7300 loss 0.0101
INFO:name:epoch 12 step 7400 loss 0.00775
INFO:name:epoch 12 step 7500 loss 0.01321
INFO:name:epoch 12 step 7600 loss 0.01039
INFO:name:epoch 12 step 7700 loss 0.00746
INFO:name:epoch 12 step 7800 loss 0.00969
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3837
INFO:name:epoch 13 step 100 loss 0.00866
INFO:name:epoch 13 step 200 loss 0.00713
INFO:name:epoch 13 step 300 loss 0.00874
INFO:name:epoch 13 step 400 loss 0.0103
INFO:name:epoch 13 step 500 loss 0.00978
INFO:name:epoch 13 step 600 loss 0.00924
INFO:name:epoch 13 step 700 loss 0.00854
INFO:name:epoch 13 step 800 loss 0.00979
INFO:name:epoch 13 step 900 loss 0.0073
INFO:name:epoch 13 step 1000 loss 0.01069
INFO:name:epoch 13 step 1100 loss 0.01002
INFO:name:epoch 13 step 1200 loss 0.00729
INFO:name:epoch 13 step 1300 loss 0.01031
INFO:name:epoch 13 step 1400 loss 0.008
INFO:name:epoch 13 step 1500 loss 0.00816
INFO:name:epoch 13 step 1600 loss 0.0099
INFO:name:epoch 13 step 1700 loss 0.00671
INFO:name:epoch 13 step 1800 loss 0.0092
INFO:name:epoch 13 step 1900 loss 0.00869
INFO:name:epoch 13 step 2000 loss 0.00942
INFO:name:epoch 13 step 2100 loss 0.00949
INFO:name:epoch 13 step 2200 loss 0.01195
INFO:name:epoch 13 step 2300 loss 0.0071
INFO:name:epoch 13 step 2400 loss 0.00771
INFO:name:epoch 13 step 2500 loss 0.00877
INFO:name:epoch 13 step 2600 loss 0.01005
INFO:name:epoch 13 step 2700 loss 0.00882
INFO:name:epoch 13 step 2800 loss 0.00751
INFO:name:epoch 13 step 2900 loss 0.00684
INFO:name:epoch 13 step 3000 loss 0.00953
INFO:name:epoch 13 step 3100 loss 0.00766
INFO:name:epoch 13 step 3200 loss 0.00861
INFO:name:epoch 13 step 3300 loss 0.00928
INFO:name:epoch 13 step 3400 loss 0.00808
INFO:name:epoch 13 step 3500 loss 0.00861
INFO:name:epoch 13 step 3600 loss 0.00886
INFO:name:epoch 13 step 3700 loss 0.0096
INFO:name:epoch 13 step 3800 loss 0.01124
INFO:name:epoch 13 step 3900 loss 0.01134
INFO:name:epoch 13 step 4000 loss 0.00916
INFO:name:epoch 13 step 4100 loss 0.00768
INFO:name:epoch 13 step 4200 loss 0.00975
INFO:name:epoch 13 step 4300 loss 0.00774
INFO:name:epoch 13 step 4400 loss 0.01008
INFO:name:epoch 13 step 4500 loss 0.00778
INFO:name:epoch 13 step 4600 loss 0.00806
INFO:name:epoch 13 step 4700 loss 0.00864
INFO:name:epoch 13 step 4800 loss 0.01092
INFO:name:epoch 13 step 4900 loss 0.01004
INFO:name:epoch 13 step 5000 loss 0.00861
INFO:name:epoch 13 step 5100 loss 0.00921
INFO:name:epoch 13 step 5200 loss 0.00761
INFO:name:epoch 13 step 5300 loss 0.00844
INFO:name:epoch 13 step 5400 loss 0.00945
INFO:name:epoch 13 step 5500 loss 0.00778
INFO:name:epoch 13 step 5600 loss 0.00987
INFO:name:epoch 13 step 5700 loss 0.00967
INFO:name:epoch 13 step 5800 loss 0.01299
INFO:name:epoch 13 step 5900 loss 0.00925
INFO:name:epoch 13 step 6000 loss 0.00768
INFO:name:epoch 13 step 6100 loss 0.00824
INFO:name:epoch 13 step 6200 loss 0.01077
INFO:name:epoch 13 step 6300 loss 0.00934
INFO:name:epoch 13 step 6400 loss 0.00785
INFO:name:epoch 13 step 6500 loss 0.01013
INFO:name:epoch 13 step 6600 loss 0.00896
INFO:name:epoch 13 step 6700 loss 0.00788
INFO:name:epoch 13 step 6800 loss 0.00894
INFO:name:epoch 13 step 6900 loss 0.00859
INFO:name:epoch 13 step 7000 loss 0.0074
INFO:name:epoch 13 step 7100 loss 0.00832
INFO:name:epoch 13 step 7200 loss 0.00777
INFO:name:epoch 13 step 7300 loss 0.00863
INFO:name:epoch 13 step 7400 loss 0.00835
INFO:name:epoch 13 step 7500 loss 0.01148
INFO:name:epoch 13 step 7600 loss 0.00972
INFO:name:epoch 13 step 7700 loss 0.00704
INFO:name:epoch 13 step 7800 loss 0.0103
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3794
INFO:name:epoch 14 step 100 loss 0.00857
INFO:name:epoch 14 step 200 loss 0.00986
INFO:name:epoch 14 step 300 loss 0.00933
INFO:name:epoch 14 step 400 loss 0.00608
INFO:name:epoch 14 step 500 loss 0.00891
INFO:name:epoch 14 step 600 loss 0.00856
INFO:name:epoch 14 step 700 loss 0.00838
INFO:name:epoch 14 step 800 loss 0.00678
INFO:name:epoch 14 step 900 loss 0.01149
INFO:name:epoch 14 step 1000 loss 0.00824
INFO:name:epoch 14 step 1100 loss 0.0094
INFO:name:epoch 14 step 1200 loss 0.00791
INFO:name:epoch 14 step 1300 loss 0.0123
INFO:name:epoch 14 step 1400 loss 0.00784
INFO:name:epoch 14 step 1500 loss 0.0086
INFO:name:epoch 14 step 1600 loss 0.00963
INFO:name:epoch 14 step 1700 loss 0.00905
INFO:name:epoch 14 step 1800 loss 0.00903
INFO:name:epoch 14 step 1900 loss 0.00985
INFO:name:epoch 14 step 2000 loss 0.00875
INFO:name:epoch 14 step 2100 loss 0.00918
INFO:name:epoch 14 step 2200 loss 0.00965
INFO:name:epoch 14 step 2300 loss 0.00954
INFO:name:epoch 14 step 2400 loss 0.0078
INFO:name:epoch 14 step 2500 loss 0.00814
INFO:name:epoch 14 step 2600 loss 0.00956
INFO:name:epoch 14 step 2700 loss 0.00899
INFO:name:epoch 14 step 2800 loss 0.01023
INFO:name:epoch 14 step 2900 loss 0.00638
INFO:name:epoch 14 step 3000 loss 0.00783
INFO:name:epoch 14 step 3100 loss 0.0071
INFO:name:epoch 14 step 3200 loss 0.00706
INFO:name:epoch 14 step 3300 loss 0.00918
INFO:name:epoch 14 step 3400 loss 0.00731
INFO:name:epoch 14 step 3500 loss 0.00913
INFO:name:epoch 14 step 3600 loss 0.01001
INFO:name:epoch 14 step 3700 loss 0.00803
INFO:name:epoch 14 step 3800 loss 0.0076
INFO:name:epoch 14 step 3900 loss 0.00958
INFO:name:epoch 14 step 4000 loss 0.01043
INFO:name:epoch 14 step 4100 loss 0.01038
INFO:name:epoch 14 step 4200 loss 0.00822
INFO:name:epoch 14 step 4300 loss 0.00814
INFO:name:epoch 14 step 4400 loss 0.00798
INFO:name:epoch 14 step 4500 loss 0.00794
INFO:name:epoch 14 step 4600 loss 0.00661
INFO:name:epoch 14 step 4700 loss 0.00858
INFO:name:epoch 14 step 4800 loss 0.00847
INFO:name:epoch 14 step 4900 loss 0.01086
INFO:name:epoch 14 step 5000 loss 0.0068
INFO:name:epoch 14 step 5100 loss 0.00624
INFO:name:epoch 14 step 5200 loss 0.00816
INFO:name:epoch 14 step 5300 loss 0.00643
INFO:name:epoch 14 step 5400 loss 0.0107
INFO:name:epoch 14 step 5500 loss 0.00865
INFO:name:epoch 14 step 5600 loss 0.00829
INFO:name:epoch 14 step 5700 loss 0.00815
INFO:name:epoch 14 step 5800 loss 0.01004
INFO:name:epoch 14 step 5900 loss 0.00978
INFO:name:epoch 14 step 6000 loss 0.00936
INFO:name:epoch 14 step 6100 loss 0.01001
INFO:name:epoch 14 step 6200 loss 0.01225
INFO:name:epoch 14 step 6300 loss 0.00951
INFO:name:epoch 14 step 6400 loss 0.00906
INFO:name:epoch 14 step 6500 loss 0.01019
INFO:name:epoch 14 step 6600 loss 0.00956
INFO:name:epoch 14 step 6700 loss 0.00763
INFO:name:epoch 14 step 6800 loss 0.00773
INFO:name:epoch 14 step 6900 loss 0.00743
INFO:name:epoch 14 step 7000 loss 0.00711
INFO:name:epoch 14 step 7100 loss 0.00996
INFO:name:epoch 14 step 7200 loss 0.00827
INFO:name:epoch 14 step 7300 loss 0.00906
INFO:name:epoch 14 step 7400 loss 0.00816
INFO:name:epoch 14 step 7500 loss 0.0091
INFO:name:epoch 14 step 7600 loss 0.00793
INFO:name:epoch 14 step 7700 loss 0.00845
INFO:name:epoch 14 step 7800 loss 0.00964
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3784
INFO:name:Saving model checkpoint to ./models/final_model_codeSearch/model.bin
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:[{'insert_modules': ('output',), 'bottleneck_dim': (256,), 'non_linearity': 'relu', 'dropout_rate': 0.2, 'normalization': None, 'skip_connection': True}, 0, 0, 0, {'insert_modules': ('output', 'attention.self', 'attention.output'), 'bottleneck_dim': (128, 32, 32), 'non_linearity': 'relu', 'dropout_rate': 0.15, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.output', 'output', 'intermediate'), 'bottleneck_dim': (64, 128, 64), 'non_linearity': 'leakyrelu', 'dropout_rate': 0.15, 'normalization': None, 'skip_connection': True}, 0, {'insert_modules': ('output', 'attention.self'), 'bottleneck_dim': (256, 16), 'non_linearity': 'swish', 'dropout_rate': 0.2, 'normalization': None, 'skip_connection': True}, 0, {'insert_modules': ('intermediate',), 'bottleneck_dim': (64,), 'non_linearity': 'gelu_new', 'dropout_rate': 0.3, 'normalization': 'layer_norm', 'skip_connection': True}, {'insert_modules': ('intermediate',), 'bottleneck_dim': (64,), 'non_linearity': 'silu', 'dropout_rate': 0.2, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.self', 'attention.output'), 'bottleneck_dim': (16, 64), 'non_linearity': 'gelu', 'dropout_rate': 0.3, 'normalization': 'layer_norm', 'skip_connection': True}]
[INFO|(OpenDelta)basemodel:700]2025-01-10 05:52:11,938 >> Trainable Ratio: 2721728/127367360=2.136912%
[INFO|(OpenDelta)basemodel:702]2025-01-10 05:52:11,938 >> Delta Parameter Ratio: 2721728/127367360=2.136912%
[INFO|(OpenDelta)basemodel:704]2025-01-10 05:52:11,938 >> Static Memory 0.99 GB, Max Memory 8.43 GB
INFO:name:3.1
INFO:name:***** Running training *****
INFO:name:  Num examples = 251820
INFO:name:  Num Epochs = 15
INFO:name:  Instantaneous batch size per GPU = 32
INFO:name:  Total train batch size  = 32
INFO:name:  Total optimization steps = 118050
train results ([0.18482655808862106, 0.06773693281108409, 0.051199344256923865, 0.03850759940484173, 0.02961303926567965, 0.023304258255807807, 0.019397751583417184, 0.016561113766276142, 0.01425770568923992, 0.0128420729468613, 0.011708663448290793, 0.010695753828330254, 0.00947761142299791, 0.008951803858659978, 0.008732759461781363], [0.36042480583562775, 0.38951521023543223, 0.3784751458352865, 0.39118116696838373, 0.37963868576148746, 0.3825668563971859, 0.3820175781401786, 0.38376212060598425, 0.3743846256907754, 0.3728585011013896, 0.3806335328712275, 0.3786390031050628, 0.38371844012822093, 0.37942222883366017, 0.3783721895293047])
INFO:name:epoch 0 step 100 loss 1.58469
INFO:name:epoch 0 step 200 loss 0.33035
INFO:name:epoch 0 step 300 loss 0.28501
INFO:name:epoch 0 step 400 loss 0.22841
INFO:name:epoch 0 step 500 loss 0.23066
INFO:name:epoch 0 step 600 loss 0.19953
INFO:name:epoch 0 step 700 loss 0.19361
INFO:name:epoch 0 step 800 loss 0.20483
INFO:name:epoch 0 step 900 loss 0.18679
INFO:name:epoch 0 step 1000 loss 0.18215
INFO:name:epoch 0 step 1100 loss 0.18121
INFO:name:epoch 0 step 1200 loss 0.18168
INFO:name:epoch 0 step 1300 loss 0.16708
INFO:name:epoch 0 step 1400 loss 0.16471
INFO:name:epoch 0 step 1500 loss 0.16195
INFO:name:epoch 0 step 1600 loss 0.15723
INFO:name:epoch 0 step 1700 loss 0.1535
INFO:name:epoch 0 step 1800 loss 0.14842
INFO:name:epoch 0 step 1900 loss 0.15856
INFO:name:epoch 0 step 2000 loss 0.14976
INFO:name:epoch 0 step 2100 loss 0.14054
INFO:name:epoch 0 step 2200 loss 0.14174
INFO:name:epoch 0 step 2300 loss 0.14474
INFO:name:epoch 0 step 2400 loss 0.14533
INFO:name:epoch 0 step 2500 loss 0.16946
INFO:name:epoch 0 step 2600 loss 0.14418
INFO:name:epoch 0 step 2700 loss 0.14422
INFO:name:epoch 0 step 2800 loss 0.14293
INFO:name:epoch 0 step 2900 loss 0.13148
INFO:name:epoch 0 step 3000 loss 0.13125
INFO:name:epoch 0 step 3100 loss 0.15256
INFO:name:epoch 0 step 3200 loss 0.1496
INFO:name:epoch 0 step 3300 loss 0.13472
INFO:name:epoch 0 step 3400 loss 0.14473
INFO:name:epoch 0 step 3500 loss 0.11402
INFO:name:epoch 0 step 3600 loss 0.13762
INFO:name:epoch 0 step 3700 loss 0.13549
INFO:name:epoch 0 step 3800 loss 0.13686
INFO:name:epoch 0 step 3900 loss 0.13614
INFO:name:epoch 0 step 4000 loss 0.147
INFO:name:epoch 0 step 4100 loss 0.13495
INFO:name:epoch 0 step 4200 loss 0.12615
INFO:name:epoch 0 step 4300 loss 0.15306
INFO:name:epoch 0 step 4400 loss 0.13158
INFO:name:epoch 0 step 4500 loss 0.12253
INFO:name:epoch 0 step 4600 loss 0.12868
INFO:name:epoch 0 step 4700 loss 0.11119
INFO:name:epoch 0 step 4800 loss 0.13865
INFO:name:epoch 0 step 4900 loss 0.13018
INFO:name:epoch 0 step 5000 loss 0.12801
INFO:name:epoch 0 step 5100 loss 0.13615
INFO:name:epoch 0 step 5200 loss 0.13205
INFO:name:epoch 0 step 5300 loss 0.1239
INFO:name:epoch 0 step 5400 loss 0.13388
INFO:name:epoch 0 step 5500 loss 0.12372
INFO:name:epoch 0 step 5600 loss 0.11447
INFO:name:epoch 0 step 5700 loss 0.10383
INFO:name:epoch 0 step 5800 loss 0.11537
INFO:name:epoch 0 step 5900 loss 0.11584
INFO:name:epoch 0 step 6000 loss 0.12409
INFO:name:epoch 0 step 6100 loss 0.09948
INFO:name:epoch 0 step 6200 loss 0.11632
INFO:name:epoch 0 step 6300 loss 0.12314
INFO:name:epoch 0 step 6400 loss 0.12405
INFO:name:epoch 0 step 6500 loss 0.12206
INFO:name:epoch 0 step 6600 loss 0.12019
INFO:name:epoch 0 step 6700 loss 0.12124
INFO:name:epoch 0 step 6800 loss 0.10529
INFO:name:epoch 0 step 6900 loss 0.11349
INFO:name:epoch 0 step 7000 loss 0.13403
INFO:name:epoch 0 step 7100 loss 0.12128
INFO:name:epoch 0 step 7200 loss 0.12107
INFO:name:epoch 0 step 7300 loss 0.10832
INFO:name:epoch 0 step 7400 loss 0.11205
INFO:name:epoch 0 step 7500 loss 0.11457
INFO:name:epoch 0 step 7600 loss 0.1095
INFO:name:epoch 0 step 7700 loss 0.11747
INFO:name:epoch 0 step 7800 loss 0.10956
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3642
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3642
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3031
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 1 step 100 loss 0.0834
INFO:name:epoch 1 step 200 loss 0.07224
INFO:name:epoch 1 step 300 loss 0.06226
INFO:name:epoch 1 step 400 loss 0.06657
INFO:name:epoch 1 step 500 loss 0.07378
INFO:name:epoch 1 step 600 loss 0.05921
INFO:name:epoch 1 step 700 loss 0.07359
INFO:name:epoch 1 step 800 loss 0.07228
INFO:name:epoch 1 step 900 loss 0.06957
INFO:name:epoch 1 step 1000 loss 0.05929
INFO:name:epoch 1 step 1100 loss 0.07073
INFO:name:epoch 1 step 1200 loss 0.07811
INFO:name:epoch 1 step 1300 loss 0.06717
INFO:name:epoch 1 step 1400 loss 0.061
INFO:name:epoch 1 step 1500 loss 0.05783
INFO:name:epoch 1 step 1600 loss 0.0692
INFO:name:epoch 1 step 1700 loss 0.07447
INFO:name:epoch 1 step 1800 loss 0.07005
INFO:name:epoch 1 step 1900 loss 0.08064
INFO:name:epoch 1 step 2000 loss 0.06302
INFO:name:epoch 1 step 2100 loss 0.07021
INFO:name:epoch 1 step 2200 loss 0.0842
INFO:name:epoch 1 step 2300 loss 0.0595
INFO:name:epoch 1 step 2400 loss 0.0725
INFO:name:epoch 1 step 2500 loss 0.07586
INFO:name:epoch 1 step 2600 loss 0.06968
INFO:name:epoch 1 step 2700 loss 0.07788
INFO:name:epoch 1 step 2800 loss 0.07535
INFO:name:epoch 1 step 2900 loss 0.06525
INFO:name:epoch 1 step 3000 loss 0.07108
INFO:name:epoch 1 step 3100 loss 0.07435
INFO:name:epoch 1 step 3200 loss 0.08136
INFO:name:epoch 1 step 3300 loss 0.05739
INFO:name:epoch 1 step 3400 loss 0.08489
INFO:name:epoch 1 step 3500 loss 0.07198
INFO:name:epoch 1 step 3600 loss 0.06615
INFO:name:epoch 1 step 3700 loss 0.06118
INFO:name:epoch 1 step 3800 loss 0.06787
INFO:name:epoch 1 step 3900 loss 0.06504
INFO:name:epoch 1 step 4000 loss 0.06509
INFO:name:epoch 1 step 4100 loss 0.05218
INFO:name:epoch 1 step 4200 loss 0.07988
INFO:name:epoch 1 step 4300 loss 0.05831
INFO:name:epoch 1 step 4400 loss 0.06504
INFO:name:epoch 1 step 4500 loss 0.05729
INFO:name:epoch 1 step 4600 loss 0.07409
INFO:name:epoch 1 step 4700 loss 0.06934
INFO:name:epoch 1 step 4800 loss 0.05778
INFO:name:epoch 1 step 4900 loss 0.07183
INFO:name:epoch 1 step 5000 loss 0.08
INFO:name:epoch 1 step 5100 loss 0.06049
INFO:name:epoch 1 step 5200 loss 0.06502
INFO:name:epoch 1 step 5300 loss 0.05792
INFO:name:epoch 1 step 5400 loss 0.07146
INFO:name:epoch 1 step 5500 loss 0.0646
INFO:name:epoch 1 step 5600 loss 0.05872
INFO:name:epoch 1 step 5700 loss 0.0757
INFO:name:epoch 1 step 5800 loss 0.06757
INFO:name:epoch 1 step 5900 loss 0.06735
INFO:name:epoch 1 step 6000 loss 0.06665
INFO:name:epoch 1 step 6100 loss 0.07644
INFO:name:epoch 1 step 6200 loss 0.06269
INFO:name:epoch 1 step 6300 loss 0.06572
INFO:name:epoch 1 step 6400 loss 0.06133
INFO:name:epoch 1 step 6500 loss 0.05923
INFO:name:epoch 1 step 6600 loss 0.05959
INFO:name:epoch 1 step 6700 loss 0.06025
INFO:name:epoch 1 step 6800 loss 0.06501
INFO:name:epoch 1 step 6900 loss 0.0646
INFO:name:epoch 1 step 7000 loss 0.05015
INFO:name:epoch 1 step 7100 loss 0.05365
INFO:name:epoch 1 step 7200 loss 0.05831
INFO:name:epoch 1 step 7300 loss 0.05685
INFO:name:epoch 1 step 7400 loss 0.06796
INFO:name:epoch 1 step 7500 loss 0.07463
INFO:name:epoch 1 step 7600 loss 0.06585
INFO:name:epoch 1 step 7700 loss 0.0579
INFO:name:epoch 1 step 7800 loss 0.0582
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3881
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3881
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3285
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 2 step 100 loss 0.0556
INFO:name:epoch 2 step 200 loss 0.04387
INFO:name:epoch 2 step 300 loss 0.04373
INFO:name:epoch 2 step 400 loss 0.04985
INFO:name:epoch 2 step 500 loss 0.03721
INFO:name:epoch 2 step 600 loss 0.04919
INFO:name:epoch 2 step 700 loss 0.05406
INFO:name:epoch 2 step 800 loss 0.04973
INFO:name:epoch 2 step 900 loss 0.0446
INFO:name:epoch 2 step 1000 loss 0.06124
INFO:name:epoch 2 step 1100 loss 0.04688
INFO:name:epoch 2 step 1200 loss 0.04428
INFO:name:epoch 2 step 1300 loss 0.04897
INFO:name:epoch 2 step 1400 loss 0.04956
INFO:name:epoch 2 step 1500 loss 0.04878
INFO:name:epoch 2 step 1600 loss 0.04613
INFO:name:epoch 2 step 1700 loss 0.05003
INFO:name:epoch 2 step 1800 loss 0.05115
INFO:name:epoch 2 step 1900 loss 0.04996
INFO:name:epoch 2 step 2000 loss 0.04559
INFO:name:epoch 2 step 2100 loss 0.05306
INFO:name:epoch 2 step 2200 loss 0.04695
INFO:name:epoch 2 step 2300 loss 0.0449
INFO:name:epoch 2 step 2400 loss 0.05087
INFO:name:epoch 2 step 2500 loss 0.05054
INFO:name:epoch 2 step 2600 loss 0.04976
INFO:name:epoch 2 step 2700 loss 0.04485
INFO:name:epoch 2 step 2800 loss 0.05128
INFO:name:epoch 2 step 2900 loss 0.0522
INFO:name:epoch 2 step 3000 loss 0.05604
INFO:name:epoch 2 step 3100 loss 0.0436
INFO:name:epoch 2 step 3200 loss 0.04755
INFO:name:epoch 2 step 3300 loss 0.0485
INFO:name:epoch 2 step 3400 loss 0.05911
INFO:name:epoch 2 step 3500 loss 0.04742
INFO:name:epoch 2 step 3600 loss 0.06072
INFO:name:epoch 2 step 3700 loss 0.05431
INFO:name:epoch 2 step 3800 loss 0.05401
INFO:name:epoch 2 step 3900 loss 0.03652
INFO:name:epoch 2 step 4000 loss 0.05036
INFO:name:epoch 2 step 4100 loss 0.05172
INFO:name:epoch 2 step 4200 loss 0.04955
INFO:name:epoch 2 step 4300 loss 0.04878
INFO:name:epoch 2 step 4400 loss 0.04762
INFO:name:epoch 2 step 4500 loss 0.05064
INFO:name:epoch 2 step 4600 loss 0.0459
INFO:name:epoch 2 step 4700 loss 0.05655
INFO:name:epoch 2 step 4800 loss 0.04357
INFO:name:epoch 2 step 4900 loss 0.0531
INFO:name:epoch 2 step 5000 loss 0.04599
INFO:name:epoch 2 step 5100 loss 0.04902
INFO:name:epoch 2 step 5200 loss 0.04113
INFO:name:epoch 2 step 5300 loss 0.04751
INFO:name:epoch 2 step 5400 loss 0.04474
INFO:name:epoch 2 step 5500 loss 0.05213
INFO:name:epoch 2 step 5600 loss 0.05538
INFO:name:epoch 2 step 5700 loss 0.05264
INFO:name:epoch 2 step 5800 loss 0.05578
INFO:name:epoch 2 step 5900 loss 0.05262
INFO:name:epoch 2 step 6000 loss 0.05098
INFO:name:epoch 2 step 6100 loss 0.0507
INFO:name:epoch 2 step 6200 loss 0.05961
INFO:name:epoch 2 step 6300 loss 0.04882
INFO:name:epoch 2 step 6400 loss 0.04967
INFO:name:epoch 2 step 6500 loss 0.06208
INFO:name:epoch 2 step 6600 loss 0.05353
INFO:name:epoch 2 step 6700 loss 0.04486
INFO:name:epoch 2 step 6800 loss 0.04609
INFO:name:epoch 2 step 6900 loss 0.05433
INFO:name:epoch 2 step 7000 loss 0.04961
INFO:name:epoch 2 step 7100 loss 0.04148
INFO:name:epoch 2 step 7200 loss 0.05358
INFO:name:epoch 2 step 7300 loss 0.04498
INFO:name:epoch 2 step 7400 loss 0.04575
INFO:name:epoch 2 step 7500 loss 0.0486
INFO:name:epoch 2 step 7600 loss 0.06419
INFO:name:epoch 2 step 7700 loss 0.04901
INFO:name:epoch 2 step 7800 loss 0.04193
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3599
INFO:name:epoch 3 step 100 loss 0.04028
INFO:name:epoch 3 step 200 loss 0.03458
INFO:name:epoch 3 step 300 loss 0.02927
INFO:name:epoch 3 step 400 loss 0.03178
INFO:name:epoch 3 step 500 loss 0.04078
INFO:name:epoch 3 step 600 loss 0.03525
INFO:name:epoch 3 step 700 loss 0.04027
INFO:name:epoch 3 step 800 loss 0.03469
INFO:name:epoch 3 step 900 loss 0.04136
INFO:name:epoch 3 step 1000 loss 0.02673
INFO:name:epoch 3 step 1100 loss 0.03311
INFO:name:epoch 3 step 1200 loss 0.03029
INFO:name:epoch 3 step 1300 loss 0.03545
INFO:name:epoch 3 step 1400 loss 0.0388
INFO:name:epoch 3 step 1500 loss 0.03339
INFO:name:epoch 3 step 1600 loss 0.03087
INFO:name:epoch 3 step 1700 loss 0.03125
INFO:name:epoch 3 step 1800 loss 0.03888
INFO:name:epoch 3 step 1900 loss 0.04673
INFO:name:epoch 3 step 2000 loss 0.03688
INFO:name:epoch 3 step 2100 loss 0.04038
INFO:name:epoch 3 step 2200 loss 0.04606
INFO:name:epoch 3 step 2300 loss 0.03912
INFO:name:epoch 3 step 2400 loss 0.04002
INFO:name:epoch 3 step 2500 loss 0.04504
INFO:name:epoch 3 step 2600 loss 0.03552
INFO:name:epoch 3 step 2700 loss 0.03911
INFO:name:epoch 3 step 2800 loss 0.03798
INFO:name:epoch 3 step 2900 loss 0.03147
INFO:name:epoch 3 step 3000 loss 0.0329
INFO:name:epoch 3 step 3100 loss 0.03876
INFO:name:epoch 3 step 3200 loss 0.04697
INFO:name:epoch 3 step 3300 loss 0.04357
INFO:name:epoch 3 step 3400 loss 0.03672
INFO:name:epoch 3 step 3500 loss 0.03613
INFO:name:epoch 3 step 3600 loss 0.03657
INFO:name:epoch 3 step 3700 loss 0.04192
INFO:name:epoch 3 step 3800 loss 0.04674
INFO:name:epoch 3 step 3900 loss 0.03984
INFO:name:epoch 3 step 4000 loss 0.03573
INFO:name:epoch 3 step 4100 loss 0.0368
INFO:name:epoch 3 step 4200 loss 0.03295
INFO:name:epoch 3 step 4300 loss 0.03042
INFO:name:epoch 3 step 4400 loss 0.03153
INFO:name:epoch 3 step 4500 loss 0.0383
INFO:name:epoch 3 step 4600 loss 0.03904
INFO:name:epoch 3 step 4700 loss 0.04156
INFO:name:epoch 3 step 4800 loss 0.03336
INFO:name:epoch 3 step 4900 loss 0.04223
INFO:name:epoch 3 step 5000 loss 0.0388
INFO:name:epoch 3 step 5100 loss 0.03347
INFO:name:epoch 3 step 5200 loss 0.04301
INFO:name:epoch 3 step 5300 loss 0.04466
INFO:name:epoch 3 step 5400 loss 0.03569
INFO:name:epoch 3 step 5500 loss 0.03646
INFO:name:epoch 3 step 5600 loss 0.04502
INFO:name:epoch 3 step 5700 loss 0.03238
INFO:name:epoch 3 step 5800 loss 0.0409
INFO:name:epoch 3 step 5900 loss 0.04012
INFO:name:epoch 3 step 6000 loss 0.03814
INFO:name:epoch 3 step 6100 loss 0.03817
INFO:name:epoch 3 step 6200 loss 0.03986
INFO:name:epoch 3 step 6300 loss 0.03468
INFO:name:epoch 3 step 6400 loss 0.03078
INFO:name:epoch 3 step 6500 loss 0.03139
INFO:name:epoch 3 step 6600 loss 0.03231
INFO:name:epoch 3 step 6700 loss 0.03682
INFO:name:epoch 3 step 6800 loss 0.04305
INFO:name:epoch 3 step 6900 loss 0.03355
INFO:name:epoch 3 step 7000 loss 0.03691
INFO:name:epoch 3 step 7100 loss 0.0424
INFO:name:epoch 3 step 7200 loss 0.03292
INFO:name:epoch 3 step 7300 loss 0.02978
INFO:name:epoch 3 step 7400 loss 0.03687
INFO:name:epoch 3 step 7500 loss 0.0459
INFO:name:epoch 3 step 7600 loss 0.03998
INFO:name:epoch 3 step 7700 loss 0.0305
INFO:name:epoch 3 step 7800 loss 0.04276
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3863
INFO:name:epoch 4 step 100 loss 0.02903
INFO:name:epoch 4 step 200 loss 0.02266
INFO:name:epoch 4 step 300 loss 0.02496
INFO:name:epoch 4 step 400 loss 0.02702
INFO:name:epoch 4 step 500 loss 0.03283
INFO:name:epoch 4 step 600 loss 0.02435
INFO:name:epoch 4 step 700 loss 0.02322
INFO:name:epoch 4 step 800 loss 0.02365
INFO:name:epoch 4 step 900 loss 0.03472
INFO:name:epoch 4 step 1000 loss 0.03007
INFO:name:epoch 4 step 1100 loss 0.02986
INFO:name:epoch 4 step 1200 loss 0.02642
INFO:name:epoch 4 step 1300 loss 0.02295
INFO:name:epoch 4 step 1400 loss 0.02865
INFO:name:epoch 4 step 1500 loss 0.02916
INFO:name:epoch 4 step 1600 loss 0.0273
INFO:name:epoch 4 step 1700 loss 0.0259
INFO:name:epoch 4 step 1800 loss 0.02776
INFO:name:epoch 4 step 1900 loss 0.03051
INFO:name:epoch 4 step 2000 loss 0.02915
INFO:name:epoch 4 step 2100 loss 0.02859
INFO:name:epoch 4 step 2200 loss 0.02851
INFO:name:epoch 4 step 2300 loss 0.0302
INFO:name:epoch 4 step 2400 loss 0.02449
INFO:name:epoch 4 step 2500 loss 0.0302
INFO:name:epoch 4 step 2600 loss 0.03077
INFO:name:epoch 4 step 2700 loss 0.02131
INFO:name:epoch 4 step 2800 loss 0.03069
INFO:name:epoch 4 step 2900 loss 0.02892
INFO:name:epoch 4 step 3000 loss 0.02409
INFO:name:epoch 4 step 3100 loss 0.02929
INFO:name:epoch 4 step 3200 loss 0.0279
INFO:name:epoch 4 step 3300 loss 0.0305
INFO:name:epoch 4 step 3400 loss 0.02318
INFO:name:epoch 4 step 3500 loss 0.03171
INFO:name:epoch 4 step 3600 loss 0.02784
INFO:name:epoch 4 step 3700 loss 0.02996
INFO:name:epoch 4 step 3800 loss 0.03171
INFO:name:epoch 4 step 3900 loss 0.0211
INFO:name:epoch 4 step 4000 loss 0.03385
INFO:name:epoch 4 step 4100 loss 0.02556
INFO:name:epoch 4 step 4200 loss 0.02154
INFO:name:epoch 4 step 4300 loss 0.0309
INFO:name:epoch 4 step 4400 loss 0.02749
INFO:name:epoch 4 step 4500 loss 0.0264
INFO:name:epoch 4 step 4600 loss 0.02535
INFO:name:epoch 4 step 4700 loss 0.02496
INFO:name:epoch 4 step 4800 loss 0.02345
INFO:name:epoch 4 step 4900 loss 0.02575
INFO:name:epoch 4 step 5000 loss 0.03051
INFO:name:epoch 4 step 5100 loss 0.02721
INFO:name:epoch 4 step 5200 loss 0.03455
INFO:name:epoch 4 step 5300 loss 0.02329
INFO:name:epoch 4 step 5400 loss 0.03243
INFO:name:epoch 4 step 5500 loss 0.02686
INFO:name:epoch 4 step 5600 loss 0.02576
INFO:name:epoch 4 step 5700 loss 0.02298
INFO:name:epoch 4 step 5800 loss 0.02918
INFO:name:epoch 4 step 5900 loss 0.02593
INFO:name:epoch 4 step 6000 loss 0.02811
INFO:name:epoch 4 step 6100 loss 0.03172
INFO:name:epoch 4 step 6200 loss 0.02919
INFO:name:epoch 4 step 6300 loss 0.03297
INFO:name:epoch 4 step 6400 loss 0.02867
INFO:name:epoch 4 step 6500 loss 0.02806
INFO:name:epoch 4 step 6600 loss 0.03604
INFO:name:epoch 4 step 6700 loss 0.02827
INFO:name:epoch 4 step 6800 loss 0.03647
INFO:name:epoch 4 step 6900 loss 0.02953
INFO:name:epoch 4 step 7000 loss 0.03041
INFO:name:epoch 4 step 7100 loss 0.032
INFO:name:epoch 4 step 7200 loss 0.02705
INFO:name:epoch 4 step 7300 loss 0.03587
INFO:name:epoch 4 step 7400 loss 0.03082
INFO:name:epoch 4 step 7500 loss 0.03437
INFO:name:epoch 4 step 7600 loss 0.0329
INFO:name:epoch 4 step 7700 loss 0.02652
INFO:name:epoch 4 step 7800 loss 0.03072
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3881
INFO:name:epoch 5 step 100 loss 0.02295
INFO:name:epoch 5 step 200 loss 0.01949
INFO:name:epoch 5 step 300 loss 0.01864
INFO:name:epoch 5 step 400 loss 0.02212
INFO:name:epoch 5 step 500 loss 0.01981
INFO:name:epoch 5 step 600 loss 0.02033
INFO:name:epoch 5 step 700 loss 0.02126
INFO:name:epoch 5 step 800 loss 0.0204
INFO:name:epoch 5 step 900 loss 0.01752
INFO:name:epoch 5 step 1000 loss 0.02134
INFO:name:epoch 5 step 1100 loss 0.02032
INFO:name:epoch 5 step 1200 loss 0.0236
INFO:name:epoch 5 step 1300 loss 0.02025
INFO:name:epoch 5 step 1400 loss 0.02318
INFO:name:epoch 5 step 1500 loss 0.0214
INFO:name:epoch 5 step 1600 loss 0.02354
INFO:name:epoch 5 step 1700 loss 0.01989
INFO:name:epoch 5 step 1800 loss 0.02225
INFO:name:epoch 5 step 1900 loss 0.02061
INFO:name:epoch 5 step 2000 loss 0.02056
INFO:name:epoch 5 step 2100 loss 0.0231
INFO:name:epoch 5 step 2200 loss 0.02186
INFO:name:epoch 5 step 2300 loss 0.02542
INFO:name:epoch 5 step 2400 loss 0.0223
INFO:name:epoch 5 step 2500 loss 0.01841
INFO:name:epoch 5 step 2600 loss 0.02144
INFO:name:epoch 5 step 2700 loss 0.02145
INFO:name:epoch 5 step 2800 loss 0.02245
INFO:name:epoch 5 step 2900 loss 0.02083
INFO:name:epoch 5 step 3000 loss 0.01997
INFO:name:epoch 5 step 3100 loss 0.02125
INFO:name:epoch 5 step 3200 loss 0.02285
INFO:name:epoch 5 step 3300 loss 0.02351
INFO:name:epoch 5 step 3400 loss 0.02155
INFO:name:epoch 5 step 3500 loss 0.02475
INFO:name:epoch 5 step 3600 loss 0.02353
INFO:name:epoch 5 step 3700 loss 0.02119
INFO:name:epoch 5 step 3800 loss 0.02496
INFO:name:epoch 5 step 3900 loss 0.01951
INFO:name:epoch 5 step 4000 loss 0.02121
INFO:name:epoch 5 step 4100 loss 0.01801
INFO:name:epoch 5 step 4200 loss 0.02641
INFO:name:epoch 5 step 4300 loss 0.02263
INFO:name:epoch 5 step 4400 loss 0.02192
INFO:name:epoch 5 step 4500 loss 0.01993
INFO:name:epoch 5 step 4600 loss 0.02067
INFO:name:epoch 5 step 4700 loss 0.02009
INFO:name:epoch 5 step 4800 loss 0.02412
INFO:name:epoch 5 step 4900 loss 0.02394
INFO:name:epoch 5 step 5000 loss 0.02349
INFO:name:epoch 5 step 5100 loss 0.0191
INFO:name:epoch 5 step 5200 loss 0.01827
INFO:name:epoch 5 step 5300 loss 0.02567
INFO:name:epoch 5 step 5400 loss 0.01759
INFO:name:epoch 5 step 5500 loss 0.0246
INFO:name:epoch 5 step 5600 loss 0.02479
INFO:name:epoch 5 step 5700 loss 0.0273
INFO:name:epoch 5 step 5800 loss 0.0247
INFO:name:epoch 5 step 5900 loss 0.01982
INFO:name:epoch 5 step 6000 loss 0.02437
INFO:name:epoch 5 step 6100 loss 0.01703
INFO:name:epoch 5 step 6200 loss 0.02285
INFO:name:epoch 5 step 6300 loss 0.02388
INFO:name:epoch 5 step 6400 loss 0.02445
INFO:name:epoch 5 step 6500 loss 0.02163
INFO:name:epoch 5 step 6600 loss 0.02611
INFO:name:epoch 5 step 6700 loss 0.01915
INFO:name:epoch 5 step 6800 loss 0.01971
INFO:name:epoch 5 step 6900 loss 0.02223
INFO:name:epoch 5 step 7000 loss 0.02181
INFO:name:epoch 5 step 7100 loss 0.0213
INFO:name:epoch 5 step 7200 loss 0.02887
INFO:name:epoch 5 step 7300 loss 0.02117
INFO:name:epoch 5 step 7400 loss 0.02517
INFO:name:epoch 5 step 7500 loss 0.02541
INFO:name:epoch 5 step 7600 loss 0.02088
INFO:name:epoch 5 step 7700 loss 0.02009
INFO:name:epoch 5 step 7800 loss 0.02098
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3846
INFO:name:epoch 6 step 100 loss 0.01984
INFO:name:epoch 6 step 200 loss 0.01902
INFO:name:epoch 6 step 300 loss 0.01634
INFO:name:epoch 6 step 400 loss 0.01621
INFO:name:epoch 6 step 500 loss 0.01901
INFO:name:epoch 6 step 600 loss 0.01642
INFO:name:epoch 6 step 700 loss 0.01997
INFO:name:epoch 6 step 800 loss 0.01672
INFO:name:epoch 6 step 900 loss 0.01866
INFO:name:epoch 6 step 1000 loss 0.01631
INFO:name:epoch 6 step 1100 loss 0.01997
INFO:name:epoch 6 step 1200 loss 0.01413
INFO:name:epoch 6 step 1300 loss 0.01576
INFO:name:epoch 6 step 1400 loss 0.01932
INFO:name:epoch 6 step 1500 loss 0.01819
INFO:name:epoch 6 step 1600 loss 0.01593
INFO:name:epoch 6 step 1700 loss 0.01801
INFO:name:epoch 6 step 1800 loss 0.02123
INFO:name:epoch 6 step 1900 loss 0.02068
INFO:name:epoch 6 step 2000 loss 0.02101
INFO:name:epoch 6 step 2100 loss 0.01465
INFO:name:epoch 6 step 2200 loss 0.01511
INFO:name:epoch 6 step 2300 loss 0.01748
INFO:name:epoch 6 step 2400 loss 0.01623
INFO:name:epoch 6 step 2500 loss 0.01517
INFO:name:epoch 6 step 2600 loss 0.01482
INFO:name:epoch 6 step 2700 loss 0.01761
INFO:name:epoch 6 step 2800 loss 0.01796
INFO:name:epoch 6 step 2900 loss 0.01962
INFO:name:epoch 6 step 3000 loss 0.01714
INFO:name:epoch 6 step 3100 loss 0.01626
INFO:name:epoch 6 step 3200 loss 0.0169
INFO:name:epoch 6 step 3300 loss 0.01822
INFO:name:epoch 6 step 3400 loss 0.01939
INFO:name:epoch 6 step 3500 loss 0.01779
INFO:name:epoch 6 step 3600 loss 0.01984
INFO:name:epoch 6 step 3700 loss 0.01606
INFO:name:epoch 6 step 3800 loss 0.01812
INFO:name:epoch 6 step 3900 loss 0.02026
INFO:name:epoch 6 step 4000 loss 0.01951
INFO:name:epoch 6 step 4100 loss 0.01945
INFO:name:epoch 6 step 4200 loss 0.02539
INFO:name:epoch 6 step 4300 loss 0.01892
INFO:name:epoch 6 step 4400 loss 0.01998
INFO:name:epoch 6 step 4500 loss 0.01582
INFO:name:epoch 6 step 4600 loss 0.01893
INFO:name:epoch 6 step 4700 loss 0.01913
INFO:name:epoch 6 step 4800 loss 0.02151
INFO:name:epoch 6 step 4900 loss 0.02112
INFO:name:epoch 6 step 5000 loss 0.01474
INFO:name:epoch 6 step 5100 loss 0.01956
INFO:name:epoch 6 step 5200 loss 0.018
INFO:name:epoch 6 step 5300 loss 0.01981
INFO:name:epoch 6 step 5400 loss 0.01846
INFO:name:epoch 6 step 5500 loss 0.02481
INFO:name:epoch 6 step 5600 loss 0.01956
INFO:name:epoch 6 step 5700 loss 0.01924
INFO:name:epoch 6 step 5800 loss 0.01635
INFO:name:epoch 6 step 5900 loss 0.01972
INFO:name:epoch 6 step 6000 loss 0.0213
INFO:name:epoch 6 step 6100 loss 0.01629
INFO:name:epoch 6 step 6200 loss 0.01642
INFO:name:epoch 6 step 6300 loss 0.01714
INFO:name:epoch 6 step 6400 loss 0.0188
INFO:name:epoch 6 step 6500 loss 0.01744
INFO:name:epoch 6 step 6600 loss 0.02478
INFO:name:epoch 6 step 6700 loss 0.01777
INFO:name:epoch 6 step 6800 loss 0.02203
INFO:name:epoch 6 step 6900 loss 0.01855
INFO:name:epoch 6 step 7000 loss 0.01831
INFO:name:epoch 6 step 7100 loss 0.02158
INFO:name:epoch 6 step 7200 loss 0.01724
INFO:name:epoch 6 step 7300 loss 0.02273
INFO:name:epoch 6 step 7400 loss 0.01687
INFO:name:epoch 6 step 7500 loss 0.01667
INFO:name:epoch 6 step 7600 loss 0.02214
INFO:name:epoch 6 step 7700 loss 0.01755
INFO:name:epoch 6 step 7800 loss 0.01893
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3734
INFO:name:epoch 7 step 100 loss 0.01548
INFO:name:epoch 7 step 200 loss 0.01255
INFO:name:epoch 7 step 300 loss 0.01261
INFO:name:epoch 7 step 400 loss 0.0119
INFO:name:epoch 7 step 500 loss 0.01317
INFO:name:epoch 7 step 600 loss 0.01863
INFO:name:epoch 7 step 700 loss 0.01595
INFO:name:epoch 7 step 800 loss 0.01653
INFO:name:epoch 7 step 900 loss 0.01269
INFO:name:epoch 7 step 1000 loss 0.01489
INFO:name:epoch 7 step 1100 loss 0.01364
INFO:name:epoch 7 step 1200 loss 0.01241
INFO:name:epoch 7 step 1300 loss 0.01365
INFO:name:epoch 7 step 1400 loss 0.01598
INFO:name:epoch 7 step 1500 loss 0.01425
INFO:name:epoch 7 step 1600 loss 0.012
INFO:name:epoch 7 step 1700 loss 0.01307
INFO:name:epoch 7 step 1800 loss 0.01607
INFO:name:epoch 7 step 1900 loss 0.0148
INFO:name:epoch 7 step 2000 loss 0.02509
INFO:name:epoch 7 step 2100 loss 0.01279
INFO:name:epoch 7 step 2200 loss 0.01563
INFO:name:epoch 7 step 2300 loss 0.01692
INFO:name:epoch 7 step 2400 loss 0.01551
INFO:name:epoch 7 step 2500 loss 0.01541
INFO:name:epoch 7 step 2600 loss 0.01485
INFO:name:epoch 7 step 2700 loss 0.01311
INFO:name:epoch 7 step 2800 loss 0.01439
INFO:name:epoch 7 step 2900 loss 0.0165
INFO:name:epoch 7 step 3000 loss 0.01455
INFO:name:epoch 7 step 3100 loss 0.01409
INFO:name:epoch 7 step 3200 loss 0.01258
INFO:name:epoch 7 step 3300 loss 0.01876
INFO:name:epoch 7 step 3400 loss 0.01868
INFO:name:epoch 7 step 3500 loss 0.01221
INFO:name:epoch 7 step 3600 loss 0.01339
INFO:name:epoch 7 step 3700 loss 0.01583
INFO:name:epoch 7 step 3800 loss 0.01629
INFO:name:epoch 7 step 3900 loss 0.01363
INFO:name:epoch 7 step 4000 loss 0.01568
INFO:name:epoch 7 step 4100 loss 0.01604
INFO:name:epoch 7 step 4200 loss 0.01523
INFO:name:epoch 7 step 4300 loss 0.01444
INFO:name:epoch 7 step 4400 loss 0.01496
INFO:name:epoch 7 step 4500 loss 0.01517
INFO:name:epoch 7 step 4600 loss 0.01431
INFO:name:epoch 7 step 4700 loss 0.02025
INFO:name:epoch 7 step 4800 loss 0.01497
INFO:name:epoch 7 step 4900 loss 0.01466
INFO:name:epoch 7 step 5000 loss 0.01254
INFO:name:epoch 7 step 5100 loss 0.01692
INFO:name:epoch 7 step 5200 loss 0.01376
INFO:name:epoch 7 step 5300 loss 0.0163
INFO:name:epoch 7 step 5400 loss 0.01645
INFO:name:epoch 7 step 5500 loss 0.01625
INFO:name:epoch 7 step 5600 loss 0.01198
INFO:name:epoch 7 step 5700 loss 0.01494
INFO:name:epoch 7 step 5800 loss 0.01717
INFO:name:epoch 7 step 5900 loss 0.01271
INFO:name:epoch 7 step 6000 loss 0.01424
INFO:name:epoch 7 step 6100 loss 0.01696
INFO:name:epoch 7 step 6200 loss 0.01378
INFO:name:epoch 7 step 6300 loss 0.01184
INFO:name:epoch 7 step 6400 loss 0.01476
INFO:name:epoch 7 step 6500 loss 0.01427
INFO:name:epoch 7 step 6600 loss 0.01724
INFO:name:epoch 7 step 6700 loss 0.01717
INFO:name:epoch 7 step 6800 loss 0.01612
INFO:name:epoch 7 step 6900 loss 0.01526
INFO:name:epoch 7 step 7000 loss 0.01533
INFO:name:epoch 7 step 7100 loss 0.01701
INFO:name:epoch 7 step 7200 loss 0.01643
INFO:name:epoch 7 step 7300 loss 0.01644
INFO:name:epoch 7 step 7400 loss 0.01786
INFO:name:epoch 7 step 7500 loss 0.01627
INFO:name:epoch 7 step 7600 loss 0.01261
INFO:name:epoch 7 step 7700 loss 0.02036
INFO:name:epoch 7 step 7800 loss 0.01505
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3815
INFO:name:epoch 8 step 100 loss 0.01272
INFO:name:epoch 8 step 200 loss 0.01091
INFO:name:epoch 8 step 300 loss 0.01211
INFO:name:epoch 8 step 400 loss 0.01251
INFO:name:epoch 8 step 500 loss 0.01587
INFO:name:epoch 8 step 600 loss 0.01384
INFO:name:epoch 8 step 700 loss 0.00927
INFO:name:epoch 8 step 800 loss 0.01209
INFO:name:epoch 8 step 900 loss 0.01049
INFO:name:epoch 8 step 1000 loss 0.01358
INFO:name:epoch 8 step 1100 loss 0.01197
INFO:name:epoch 8 step 1200 loss 0.01571
INFO:name:epoch 8 step 1300 loss 0.01462
INFO:name:epoch 8 step 1400 loss 0.01398
INFO:name:epoch 8 step 1500 loss 0.00928
INFO:name:epoch 8 step 1600 loss 0.01065
INFO:name:epoch 8 step 1700 loss 0.01532
INFO:name:epoch 8 step 1800 loss 0.01262
INFO:name:epoch 8 step 1900 loss 0.01164
INFO:name:epoch 8 step 2000 loss 0.01025
INFO:name:epoch 8 step 2100 loss 0.01375
INFO:name:epoch 8 step 2200 loss 0.01382
INFO:name:epoch 8 step 2300 loss 0.01145
INFO:name:epoch 8 step 2400 loss 0.01636
INFO:name:epoch 8 step 2500 loss 0.01347
INFO:name:epoch 8 step 2600 loss 0.01294
INFO:name:epoch 8 step 2700 loss 0.01323
INFO:name:epoch 8 step 2800 loss 0.01261
INFO:name:epoch 8 step 2900 loss 0.0125
INFO:name:epoch 8 step 3000 loss 0.01208
INFO:name:epoch 8 step 3100 loss 0.01318
INFO:name:epoch 8 step 3200 loss 0.01397
INFO:name:epoch 8 step 3300 loss 0.01396
INFO:name:epoch 8 step 3400 loss 0.01212
INFO:name:epoch 8 step 3500 loss 0.01284
INFO:name:epoch 8 step 3600 loss 0.01662
INFO:name:epoch 8 step 3700 loss 0.01424
INFO:name:epoch 8 step 3800 loss 0.01176
INFO:name:epoch 8 step 3900 loss 0.01122
INFO:name:epoch 8 step 4000 loss 0.01411
INFO:name:epoch 8 step 4100 loss 0.01235
INFO:name:epoch 8 step 4200 loss 0.01152
INFO:name:epoch 8 step 4300 loss 0.0112
INFO:name:epoch 8 step 4400 loss 0.01491
INFO:name:epoch 8 step 4500 loss 0.01859
INFO:name:epoch 8 step 4600 loss 0.01449
INFO:name:epoch 8 step 4700 loss 0.01103
INFO:name:epoch 8 step 4800 loss 0.01787
INFO:name:epoch 8 step 4900 loss 0.016
INFO:name:epoch 8 step 5000 loss 0.01315
INFO:name:epoch 8 step 5100 loss 0.01438
INFO:name:epoch 8 step 5200 loss 0.01525
INFO:name:epoch 8 step 5300 loss 0.01123
INFO:name:epoch 8 step 5400 loss 0.01436
INFO:name:epoch 8 step 5500 loss 0.01285
INFO:name:epoch 8 step 5600 loss 0.01155
INFO:name:epoch 8 step 5700 loss 0.01231
INFO:name:epoch 8 step 5800 loss 0.01283
INFO:name:epoch 8 step 5900 loss 0.01325
INFO:name:epoch 8 step 6000 loss 0.01327
INFO:name:epoch 8 step 6100 loss 0.00979
INFO:name:epoch 8 step 6200 loss 0.0123
INFO:name:epoch 8 step 6300 loss 0.01259
INFO:name:epoch 8 step 6400 loss 0.0118
INFO:name:epoch 8 step 6500 loss 0.01474
INFO:name:epoch 8 step 6600 loss 0.01575
INFO:name:epoch 8 step 6700 loss 0.01284
INFO:name:epoch 8 step 6800 loss 0.01409
INFO:name:epoch 8 step 6900 loss 0.01503
INFO:name:epoch 8 step 7000 loss 0.0107
INFO:name:epoch 8 step 7100 loss 0.01534
INFO:name:epoch 8 step 7200 loss 0.0117
INFO:name:epoch 8 step 7300 loss 0.01243
INFO:name:epoch 8 step 7400 loss 0.01136
INFO:name:epoch 8 step 7500 loss 0.01528
INFO:name:epoch 8 step 7600 loss 0.01374
INFO:name:epoch 8 step 7700 loss 0.0137
INFO:name:epoch 8 step 7800 loss 0.01451
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3805
INFO:name:epoch 9 step 100 loss 0.01152
INFO:name:epoch 9 step 200 loss 0.01282
INFO:name:epoch 9 step 300 loss 0.00966
INFO:name:epoch 9 step 400 loss 0.01489
INFO:name:epoch 9 step 500 loss 0.01284
INFO:name:epoch 9 step 600 loss 0.01292
INFO:name:epoch 9 step 700 loss 0.01063
INFO:name:epoch 9 step 800 loss 0.00967
INFO:name:epoch 9 step 900 loss 0.01259
INFO:name:epoch 9 step 1000 loss 0.00892
INFO:name:epoch 9 step 1100 loss 0.00982
INFO:name:epoch 9 step 1200 loss 0.01229
INFO:name:epoch 9 step 1300 loss 0.01438
INFO:name:epoch 9 step 1400 loss 0.01125
INFO:name:epoch 9 step 1500 loss 0.0101
INFO:name:epoch 9 step 1600 loss 0.01308
INFO:name:epoch 9 step 1700 loss 0.01224
INFO:name:epoch 9 step 1800 loss 0.01313
INFO:name:epoch 9 step 1900 loss 0.00992
INFO:name:epoch 9 step 2000 loss 0.01026
INFO:name:epoch 9 step 2100 loss 0.01009
INFO:name:epoch 9 step 2200 loss 0.00994
INFO:name:epoch 9 step 2300 loss 0.00988
INFO:name:epoch 9 step 2400 loss 0.01099
INFO:name:epoch 9 step 2500 loss 0.01179
INFO:name:epoch 9 step 2600 loss 0.01514
INFO:name:epoch 9 step 2700 loss 0.01166
INFO:name:epoch 9 step 2800 loss 0.01038
INFO:name:epoch 9 step 2900 loss 0.01127
INFO:name:epoch 9 step 3000 loss 0.01283
INFO:name:epoch 9 step 3100 loss 0.01105
INFO:name:epoch 9 step 3200 loss 0.01144
INFO:name:epoch 9 step 3300 loss 0.00881
INFO:name:epoch 9 step 3400 loss 0.01141
INFO:name:epoch 9 step 3500 loss 0.01294
INFO:name:epoch 9 step 3600 loss 0.01402
INFO:name:epoch 9 step 3700 loss 0.0143
INFO:name:epoch 9 step 3800 loss 0.01086
INFO:name:epoch 9 step 3900 loss 0.01309
INFO:name:epoch 9 step 4000 loss 0.01109
INFO:name:epoch 9 step 4100 loss 0.01134
INFO:name:epoch 9 step 4200 loss 0.01027
INFO:name:epoch 9 step 4300 loss 0.013
INFO:name:epoch 9 step 4400 loss 0.01327
INFO:name:epoch 9 step 4500 loss 0.01177
INFO:name:epoch 9 step 4600 loss 0.01293
INFO:name:epoch 9 step 4700 loss 0.01443
INFO:name:epoch 9 step 4800 loss 0.01206
INFO:name:epoch 9 step 4900 loss 0.0097
INFO:name:epoch 9 step 5000 loss 0.01292
INFO:name:epoch 9 step 5100 loss 0.0108
INFO:name:epoch 9 step 5200 loss 0.01366
INFO:name:epoch 9 step 5300 loss 0.01215
INFO:name:epoch 9 step 5400 loss 0.01127
INFO:name:epoch 9 step 5500 loss 0.00799
INFO:name:epoch 9 step 5600 loss 0.01065
INFO:name:epoch 9 step 5700 loss 0.01189
INFO:name:epoch 9 step 5800 loss 0.01042
INFO:name:epoch 9 step 5900 loss 0.0102
INFO:name:epoch 9 step 6000 loss 0.01229
INFO:name:epoch 9 step 6100 loss 0.00968
INFO:name:epoch 9 step 6200 loss 0.00905
INFO:name:epoch 9 step 6300 loss 0.01011
INFO:name:epoch 9 step 6400 loss 0.0129
INFO:name:epoch 9 step 6500 loss 0.00966
INFO:name:epoch 9 step 6600 loss 0.01303
INFO:name:epoch 9 step 6700 loss 0.0138
INFO:name:epoch 9 step 6800 loss 0.01197
INFO:name:epoch 9 step 6900 loss 0.01541
INFO:name:epoch 9 step 7000 loss 0.01089
INFO:name:epoch 9 step 7100 loss 0.01179
INFO:name:epoch 9 step 7200 loss 0.01355
INFO:name:epoch 9 step 7300 loss 0.01038
INFO:name:epoch 9 step 7400 loss 0.01213
INFO:name:epoch 9 step 7500 loss 0.01109
INFO:name:epoch 9 step 7600 loss 0.01156
INFO:name:epoch 9 step 7700 loss 0.01259
INFO:name:epoch 9 step 7800 loss 0.01117
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3906
INFO:name:  ********************
INFO:name:  Best eval mrr:0.3906
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3272
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 10 step 100 loss 0.00986
INFO:name:epoch 10 step 200 loss 0.01109
INFO:name:epoch 10 step 300 loss 0.00914
INFO:name:epoch 10 step 400 loss 0.00859
INFO:name:epoch 10 step 500 loss 0.01053
INFO:name:epoch 10 step 600 loss 0.01074
INFO:name:epoch 10 step 700 loss 0.00987
INFO:name:epoch 10 step 800 loss 0.01079
INFO:name:epoch 10 step 900 loss 0.00885
INFO:name:epoch 10 step 1000 loss 0.00931
INFO:name:epoch 10 step 1100 loss 0.01202
INFO:name:epoch 10 step 1200 loss 0.01145
INFO:name:epoch 10 step 1300 loss 0.01179
INFO:name:epoch 10 step 1400 loss 0.0114
INFO:name:epoch 10 step 1500 loss 0.01239
INFO:name:epoch 10 step 1600 loss 0.01207
INFO:name:epoch 10 step 1700 loss 0.01168
INFO:name:epoch 10 step 1800 loss 0.00879
INFO:name:epoch 10 step 1900 loss 0.01276
INFO:name:epoch 10 step 2000 loss 0.00987
INFO:name:epoch 10 step 2100 loss 0.00917
INFO:name:epoch 10 step 2200 loss 0.01118
INFO:name:epoch 10 step 2300 loss 0.01056
INFO:name:epoch 10 step 2400 loss 0.0125
INFO:name:epoch 10 step 2500 loss 0.01115
INFO:name:epoch 10 step 2600 loss 0.01061
INFO:name:epoch 10 step 2700 loss 0.01033
INFO:name:epoch 10 step 2800 loss 0.01467
INFO:name:epoch 10 step 2900 loss 0.0112
INFO:name:epoch 10 step 3000 loss 0.01098
INFO:name:epoch 10 step 3100 loss 0.00961
INFO:name:epoch 10 step 3200 loss 0.01228
INFO:name:epoch 10 step 3300 loss 0.00999
INFO:name:epoch 10 step 3400 loss 0.01047
INFO:name:epoch 10 step 3500 loss 0.00749
INFO:name:epoch 10 step 3600 loss 0.0141
INFO:name:epoch 10 step 3700 loss 0.00958
INFO:name:epoch 10 step 3800 loss 0.01214
INFO:name:epoch 10 step 3900 loss 0.00833
INFO:name:epoch 10 step 4000 loss 0.0091
INFO:name:epoch 10 step 4100 loss 0.00985
INFO:name:epoch 10 step 4200 loss 0.01
INFO:name:epoch 10 step 4300 loss 0.01151
INFO:name:epoch 10 step 4400 loss 0.00835
INFO:name:epoch 10 step 4500 loss 0.00866
INFO:name:epoch 10 step 4600 loss 0.01054
INFO:name:epoch 10 step 4700 loss 0.0099
INFO:name:epoch 10 step 4800 loss 0.01126
INFO:name:epoch 10 step 4900 loss 0.00923
INFO:name:epoch 10 step 5000 loss 0.01071
INFO:name:epoch 10 step 5100 loss 0.00936
INFO:name:epoch 10 step 5200 loss 0.01243
INFO:name:epoch 10 step 5300 loss 0.01001
INFO:name:epoch 10 step 5400 loss 0.00998
INFO:name:epoch 10 step 5500 loss 0.0094
INFO:name:epoch 10 step 5600 loss 0.01085
INFO:name:epoch 10 step 5700 loss 0.01117
INFO:name:epoch 10 step 5800 loss 0.01259
INFO:name:epoch 10 step 5900 loss 0.00926
INFO:name:epoch 10 step 6000 loss 0.01109
INFO:name:epoch 10 step 6100 loss 0.00707
INFO:name:epoch 10 step 6200 loss 0.00888
INFO:name:epoch 10 step 6300 loss 0.01385
INFO:name:epoch 10 step 6400 loss 0.00832
INFO:name:epoch 10 step 6500 loss 0.01182
INFO:name:epoch 10 step 6600 loss 0.01262
INFO:name:epoch 10 step 6700 loss 0.01013
INFO:name:epoch 10 step 6800 loss 0.00955
INFO:name:epoch 10 step 6900 loss 0.00637
INFO:name:epoch 10 step 7000 loss 0.01038
INFO:name:epoch 10 step 7100 loss 0.01197
INFO:name:epoch 10 step 7200 loss 0.01007
INFO:name:epoch 10 step 7300 loss 0.01156
INFO:name:epoch 10 step 7400 loss 0.01158
INFO:name:epoch 10 step 7500 loss 0.01029
INFO:name:epoch 10 step 7600 loss 0.01112
INFO:name:epoch 10 step 7700 loss 0.0102
INFO:name:epoch 10 step 7800 loss 0.01265
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3731
INFO:name:epoch 11 step 100 loss 0.01002
INFO:name:epoch 11 step 200 loss 0.01077
INFO:name:epoch 11 step 300 loss 0.0093
INFO:name:epoch 11 step 400 loss 0.00876
INFO:name:epoch 11 step 500 loss 0.00947
INFO:name:epoch 11 step 600 loss 0.00988
INFO:name:epoch 11 step 700 loss 0.00946
INFO:name:epoch 11 step 800 loss 0.00768
INFO:name:epoch 11 step 900 loss 0.00974
INFO:name:epoch 11 step 1000 loss 0.01007
INFO:name:epoch 11 step 1100 loss 0.00835
INFO:name:epoch 11 step 1200 loss 0.0115
INFO:name:epoch 11 step 1300 loss 0.00923
INFO:name:epoch 11 step 1400 loss 0.00832
INFO:name:epoch 11 step 1500 loss 0.00978
INFO:name:epoch 11 step 1600 loss 0.00999
INFO:name:epoch 11 step 1700 loss 0.00809
INFO:name:epoch 11 step 1800 loss 0.00973
INFO:name:epoch 11 step 1900 loss 0.00825
INFO:name:epoch 11 step 2000 loss 0.01009
INFO:name:epoch 11 step 2100 loss 0.00742
INFO:name:epoch 11 step 2200 loss 0.01181
INFO:name:epoch 11 step 2300 loss 0.00936
INFO:name:epoch 11 step 2400 loss 0.00965
INFO:name:epoch 11 step 2500 loss 0.012
INFO:name:epoch 11 step 2600 loss 0.009
INFO:name:epoch 11 step 2700 loss 0.00993
INFO:name:epoch 11 step 2800 loss 0.01014
INFO:name:epoch 11 step 2900 loss 0.01136
INFO:name:epoch 11 step 3000 loss 0.01058
INFO:name:epoch 11 step 3100 loss 0.01014
INFO:name:epoch 11 step 3200 loss 0.00856
INFO:name:epoch 11 step 3300 loss 0.00937
INFO:name:epoch 11 step 3400 loss 0.00756
INFO:name:epoch 11 step 3500 loss 0.00996
INFO:name:epoch 11 step 3600 loss 0.01129
INFO:name:epoch 11 step 3700 loss 0.00906
INFO:name:epoch 11 step 3800 loss 0.01048
INFO:name:epoch 11 step 3900 loss 0.00762
INFO:name:epoch 11 step 4000 loss 0.01078
INFO:name:epoch 11 step 4100 loss 0.01292
INFO:name:epoch 11 step 4200 loss 0.00914
INFO:name:epoch 11 step 4300 loss 0.0084
INFO:name:epoch 11 step 4400 loss 0.01158
INFO:name:epoch 11 step 4500 loss 0.00817
INFO:name:epoch 11 step 4600 loss 0.0118
INFO:name:epoch 11 step 4700 loss 0.01024
INFO:name:epoch 11 step 4800 loss 0.00973
INFO:name:epoch 11 step 4900 loss 0.00795
INFO:name:epoch 11 step 5000 loss 0.00999
INFO:name:epoch 11 step 5100 loss 0.00933
INFO:name:epoch 11 step 5200 loss 0.00951
INFO:name:epoch 11 step 5300 loss 0.01241
INFO:name:epoch 11 step 5400 loss 0.01131
INFO:name:epoch 11 step 5500 loss 0.01022
INFO:name:epoch 11 step 5600 loss 0.01001
INFO:name:epoch 11 step 5700 loss 0.00919
INFO:name:epoch 11 step 5800 loss 0.00849
INFO:name:epoch 11 step 5900 loss 0.00879
INFO:name:epoch 11 step 6000 loss 0.00955
INFO:name:epoch 11 step 6100 loss 0.00724
INFO:name:epoch 11 step 6200 loss 0.00802
INFO:name:epoch 11 step 6300 loss 0.00955
INFO:name:epoch 11 step 6400 loss 0.00899
INFO:name:epoch 11 step 6500 loss 0.00922
INFO:name:epoch 11 step 6600 loss 0.01042
INFO:name:epoch 11 step 6700 loss 0.00864
INFO:name:epoch 11 step 6800 loss 0.00922
INFO:name:epoch 11 step 6900 loss 0.00714
INFO:name:epoch 11 step 7000 loss 0.01046
INFO:name:epoch 11 step 7100 loss 0.01051
INFO:name:epoch 11 step 7200 loss 0.01175
INFO:name:epoch 11 step 7300 loss 0.00906
INFO:name:epoch 11 step 7400 loss 0.00926
INFO:name:epoch 11 step 7500 loss 0.00922
INFO:name:epoch 11 step 7600 loss 0.00875
INFO:name:epoch 11 step 7700 loss 0.00836
INFO:name:epoch 11 step 7800 loss 0.00981
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.369
INFO:name:epoch 12 step 100 loss 0.00757
INFO:name:epoch 12 step 200 loss 0.00947
INFO:name:epoch 12 step 300 loss 0.00626
INFO:name:epoch 12 step 400 loss 0.01033
INFO:name:epoch 12 step 500 loss 0.0093
INFO:name:epoch 12 step 600 loss 0.00724
INFO:name:epoch 12 step 700 loss 0.00771
INFO:name:epoch 12 step 800 loss 0.00896
INFO:name:epoch 12 step 900 loss 0.00914
INFO:name:epoch 12 step 1000 loss 0.00686
INFO:name:epoch 12 step 1100 loss 0.00822
INFO:name:epoch 12 step 1200 loss 0.00926
INFO:name:epoch 12 step 1300 loss 0.00993
INFO:name:epoch 12 step 1400 loss 0.00969
INFO:name:epoch 12 step 1500 loss 0.00788
INFO:name:epoch 12 step 1600 loss 0.00962
INFO:name:epoch 12 step 1700 loss 0.01087
INFO:name:epoch 12 step 1800 loss 0.00721
INFO:name:epoch 12 step 1900 loss 0.0073
INFO:name:epoch 12 step 2000 loss 0.00825
INFO:name:epoch 12 step 2100 loss 0.00808
INFO:name:epoch 12 step 2200 loss 0.01157
INFO:name:epoch 12 step 2300 loss 0.00602
INFO:name:epoch 12 step 2400 loss 0.00911
INFO:name:epoch 12 step 2500 loss 0.00898
INFO:name:epoch 12 step 2600 loss 0.0085
INFO:name:epoch 12 step 2700 loss 0.00791
INFO:name:epoch 12 step 2800 loss 0.00864
INFO:name:epoch 12 step 2900 loss 0.01029
INFO:name:epoch 12 step 3000 loss 0.00815
INFO:name:epoch 12 step 3100 loss 0.00984
INFO:name:epoch 12 step 3200 loss 0.01319
INFO:name:epoch 12 step 3300 loss 0.00853
INFO:name:epoch 12 step 3400 loss 0.00936
INFO:name:epoch 12 step 3500 loss 0.00834
INFO:name:epoch 12 step 3600 loss 0.00894
INFO:name:epoch 12 step 3700 loss 0.01143
INFO:name:epoch 12 step 3800 loss 0.01035
INFO:name:epoch 12 step 3900 loss 0.01105
INFO:name:epoch 12 step 4000 loss 0.00907
INFO:name:epoch 12 step 4100 loss 0.00768
INFO:name:epoch 12 step 4200 loss 0.01133
INFO:name:epoch 12 step 4300 loss 0.00974
INFO:name:epoch 12 step 4400 loss 0.00855
INFO:name:epoch 12 step 4500 loss 0.00982
INFO:name:epoch 12 step 4600 loss 0.01188
INFO:name:epoch 12 step 4700 loss 0.00835
INFO:name:epoch 12 step 4800 loss 0.00828
INFO:name:epoch 12 step 4900 loss 0.00844
INFO:name:epoch 12 step 5000 loss 0.00741
INFO:name:epoch 12 step 5100 loss 0.00962
INFO:name:epoch 12 step 5200 loss 0.00739
INFO:name:epoch 12 step 5300 loss 0.00644
INFO:name:epoch 12 step 5400 loss 0.00824
INFO:name:epoch 12 step 5500 loss 0.01077
INFO:name:epoch 12 step 5600 loss 0.00995
INFO:name:epoch 12 step 5700 loss 0.00716
INFO:name:epoch 12 step 5800 loss 0.007
INFO:name:epoch 12 step 5900 loss 0.00743
INFO:name:epoch 12 step 6000 loss 0.00834
INFO:name:epoch 12 step 6100 loss 0.00931
INFO:name:epoch 12 step 6200 loss 0.00943
INFO:name:epoch 12 step 6300 loss 0.0086
INFO:name:epoch 12 step 6400 loss 0.00759
INFO:name:epoch 12 step 6500 loss 0.00863
INFO:name:epoch 12 step 6600 loss 0.00824
INFO:name:epoch 12 step 6700 loss 0.00882
INFO:name:epoch 12 step 6800 loss 0.00865
INFO:name:epoch 12 step 6900 loss 0.01084
INFO:name:epoch 12 step 7000 loss 0.00748
INFO:name:epoch 12 step 7100 loss 0.01149
INFO:name:epoch 12 step 7200 loss 0.00914
INFO:name:epoch 12 step 7300 loss 0.01021
INFO:name:epoch 12 step 7400 loss 0.00707
INFO:name:epoch 12 step 7500 loss 0.0094
INFO:name:epoch 12 step 7600 loss 0.01036
INFO:name:epoch 12 step 7700 loss 0.00776
INFO:name:epoch 12 step 7800 loss 0.00825
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3734
INFO:name:epoch 13 step 100 loss 0.00769
INFO:name:epoch 13 step 200 loss 0.01016
INFO:name:epoch 13 step 300 loss 0.00828
INFO:name:epoch 13 step 400 loss 0.00848
INFO:name:epoch 13 step 500 loss 0.00641
INFO:name:epoch 13 step 600 loss 0.0066
INFO:name:epoch 13 step 700 loss 0.0086
INFO:name:epoch 13 step 800 loss 0.00886
INFO:name:epoch 13 step 900 loss 0.00925
INFO:name:epoch 13 step 1000 loss 0.01002
INFO:name:epoch 13 step 1100 loss 0.00912
INFO:name:epoch 13 step 1200 loss 0.00883
INFO:name:epoch 13 step 1300 loss 0.00821
INFO:name:epoch 13 step 1400 loss 0.00894
INFO:name:epoch 13 step 1500 loss 0.00904
INFO:name:epoch 13 step 1600 loss 0.00741
INFO:name:epoch 13 step 1700 loss 0.00717
INFO:name:epoch 13 step 1800 loss 0.0066
INFO:name:epoch 13 step 1900 loss 0.0123
INFO:name:epoch 13 step 2000 loss 0.00825
INFO:name:epoch 13 step 2100 loss 0.00945
INFO:name:epoch 13 step 2200 loss 0.0089
INFO:name:epoch 13 step 2300 loss 0.00779
INFO:name:epoch 13 step 2400 loss 0.00802
INFO:name:epoch 13 step 2500 loss 0.00969
INFO:name:epoch 13 step 2600 loss 0.00837
INFO:name:epoch 13 step 2700 loss 0.00846
INFO:name:epoch 13 step 2800 loss 0.00907
INFO:name:epoch 13 step 2900 loss 0.00868
INFO:name:epoch 13 step 3000 loss 0.00574
INFO:name:epoch 13 step 3100 loss 0.00761
INFO:name:epoch 13 step 3200 loss 0.00805
INFO:name:epoch 13 step 3300 loss 0.00817
INFO:name:epoch 13 step 3400 loss 0.00728
INFO:name:epoch 13 step 3500 loss 0.00963
INFO:name:epoch 13 step 3600 loss 0.00743
INFO:name:epoch 13 step 3700 loss 0.00851
INFO:name:epoch 13 step 3800 loss 0.00771
INFO:name:epoch 13 step 3900 loss 0.00797
INFO:name:epoch 13 step 4000 loss 0.00808
INFO:name:epoch 13 step 4100 loss 0.00761
INFO:name:epoch 13 step 4200 loss 0.00838
INFO:name:epoch 13 step 4300 loss 0.00823
INFO:name:epoch 13 step 4400 loss 0.00789
INFO:name:epoch 13 step 4500 loss 0.01031
INFO:name:epoch 13 step 4600 loss 0.00747
INFO:name:epoch 13 step 4700 loss 0.00713
INFO:name:epoch 13 step 4800 loss 0.00838
INFO:name:epoch 13 step 4900 loss 0.00646
INFO:name:epoch 13 step 5000 loss 0.01053
INFO:name:epoch 13 step 5100 loss 0.01122
INFO:name:epoch 13 step 5200 loss 0.00683
INFO:name:epoch 13 step 5300 loss 0.00745
INFO:name:epoch 13 step 5400 loss 0.00752
INFO:name:epoch 13 step 5500 loss 0.00654
INFO:name:epoch 13 step 5600 loss 0.00708
INFO:name:epoch 13 step 5700 loss 0.00833
INFO:name:epoch 13 step 5800 loss 0.00793
INFO:name:epoch 13 step 5900 loss 0.00796
INFO:name:epoch 13 step 6000 loss 0.00659
INFO:name:epoch 13 step 6100 loss 0.00725
INFO:name:epoch 13 step 6200 loss 0.00732
INFO:name:epoch 13 step 6300 loss 0.00653
INFO:name:epoch 13 step 6400 loss 0.00925
INFO:name:epoch 13 step 6500 loss 0.00902
INFO:name:epoch 13 step 6600 loss 0.00882
INFO:name:epoch 13 step 6700 loss 0.00774
INFO:name:epoch 13 step 6800 loss 0.00643
INFO:name:epoch 13 step 6900 loss 0.00689
INFO:name:epoch 13 step 7000 loss 0.00736
INFO:name:epoch 13 step 7100 loss 0.00719
INFO:name:epoch 13 step 7200 loss 0.00568
INFO:name:epoch 13 step 7300 loss 0.00639
INFO:name:epoch 13 step 7400 loss 0.00795
INFO:name:epoch 13 step 7500 loss 0.0084
INFO:name:epoch 13 step 7600 loss 0.00769
INFO:name:epoch 13 step 7700 loss 0.0076
INFO:name:epoch 13 step 7800 loss 0.00797
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3787
INFO:name:epoch 14 step 100 loss 0.00867
INFO:name:epoch 14 step 200 loss 0.00766
INFO:name:epoch 14 step 300 loss 0.00775
INFO:name:epoch 14 step 400 loss 0.00808
INFO:name:epoch 14 step 500 loss 0.00893
INFO:name:epoch 14 step 600 loss 0.00723
INFO:name:epoch 14 step 700 loss 0.00753
INFO:name:epoch 14 step 800 loss 0.00872
INFO:name:epoch 14 step 900 loss 0.00763
INFO:name:epoch 14 step 1000 loss 0.00768
INFO:name:epoch 14 step 1100 loss 0.00871
INFO:name:epoch 14 step 1200 loss 0.00649
INFO:name:epoch 14 step 1300 loss 0.01167
INFO:name:epoch 14 step 1400 loss 0.00807
INFO:name:epoch 14 step 1500 loss 0.00995
INFO:name:epoch 14 step 1600 loss 0.00696
INFO:name:epoch 14 step 1700 loss 0.00807
INFO:name:epoch 14 step 1800 loss 0.00851
INFO:name:epoch 14 step 1900 loss 0.00758
INFO:name:epoch 14 step 2000 loss 0.00831
INFO:name:epoch 14 step 2100 loss 0.0066
INFO:name:epoch 14 step 2200 loss 0.00683
INFO:name:epoch 14 step 2300 loss 0.00766
INFO:name:epoch 14 step 2400 loss 0.00864
INFO:name:epoch 14 step 2500 loss 0.00697
INFO:name:epoch 14 step 2600 loss 0.00855
INFO:name:epoch 14 step 2700 loss 0.00707
INFO:name:epoch 14 step 2800 loss 0.00861
INFO:name:epoch 14 step 2900 loss 0.00852
INFO:name:epoch 14 step 3000 loss 0.0065
INFO:name:epoch 14 step 3100 loss 0.00938
INFO:name:epoch 14 step 3200 loss 0.00941
INFO:name:epoch 14 step 3300 loss 0.00672
INFO:name:epoch 14 step 3400 loss 0.00806
INFO:name:epoch 14 step 3500 loss 0.00729
INFO:name:epoch 14 step 3600 loss 0.00652
INFO:name:epoch 14 step 3700 loss 0.00834
INFO:name:epoch 14 step 3800 loss 0.00778
INFO:name:epoch 14 step 3900 loss 0.00714
INFO:name:epoch 14 step 4000 loss 0.00604
INFO:name:epoch 14 step 4100 loss 0.00543
INFO:name:epoch 14 step 4200 loss 0.00756
INFO:name:epoch 14 step 4300 loss 0.0067
INFO:name:epoch 14 step 4400 loss 0.00744
INFO:name:epoch 14 step 4500 loss 0.00786
INFO:name:epoch 14 step 4600 loss 0.00722
INFO:name:epoch 14 step 4700 loss 0.00919
INFO:name:epoch 14 step 4800 loss 0.00675
INFO:name:epoch 14 step 4900 loss 0.00718
INFO:name:epoch 14 step 5000 loss 0.00708
INFO:name:epoch 14 step 5100 loss 0.00826
INFO:name:epoch 14 step 5200 loss 0.00733
INFO:name:epoch 14 step 5300 loss 0.00622
INFO:name:epoch 14 step 5400 loss 0.00855
INFO:name:epoch 14 step 5500 loss 0.00707
INFO:name:epoch 14 step 5600 loss 0.00816
INFO:name:epoch 14 step 5700 loss 0.00804
INFO:name:epoch 14 step 5800 loss 0.0096
INFO:name:epoch 14 step 5900 loss 0.00977
INFO:name:epoch 14 step 6000 loss 0.01049
INFO:name:epoch 14 step 6100 loss 0.00767
INFO:name:epoch 14 step 6200 loss 0.00576
INFO:name:epoch 14 step 6300 loss 0.00612
INFO:name:epoch 14 step 6400 loss 0.00787
INFO:name:epoch 14 step 6500 loss 0.00877
INFO:name:epoch 14 step 6600 loss 0.00687
INFO:name:epoch 14 step 6700 loss 0.00892
INFO:name:epoch 14 step 6800 loss 0.00812
INFO:name:epoch 14 step 6900 loss 0.00971
INFO:name:epoch 14 step 7000 loss 0.00813
INFO:name:epoch 14 step 7100 loss 0.00672
INFO:name:epoch 14 step 7200 loss 0.00878
INFO:name:epoch 14 step 7300 loss 0.00755
INFO:name:epoch 14 step 7400 loss 0.01262
INFO:name:epoch 14 step 7500 loss 0.00947
INFO:name:epoch 14 step 7600 loss 0.00832
INFO:name:epoch 14 step 7700 loss 0.00846
INFO:name:epoch 14 step 7800 loss 0.00762
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3736
INFO:name:Saving model checkpoint to ./models/final_model_codeSearch/model.bin
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
train results ([0.1623247894837747, 0.0669891156670383, 0.04950932996886578, 0.03728227318782126, 0.028333899417332654, 0.02191739182186047, 0.01847137940616058, 0.01514737870813193, 0.01314953780208884, 0.011636456384604517, 0.010558406282940023, 0.009584847217072315, 0.008871482614194235, 0.008072494760897808, 0.007949319285973866], [0.36417969490853724, 0.38814109957552495, 0.3598976022926487, 0.3862661736865832, 0.38805061038232097, 0.3846294529871511, 0.3734199858892002, 0.38150781755303936, 0.38049883917603144, 0.390571932461763, 0.3731202122436501, 0.36896523630343525, 0.37344454728446846, 0.3786567263889116, 0.37359681532231637])
