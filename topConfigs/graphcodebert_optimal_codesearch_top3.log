/opt/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
INFO:name:device: cuda:1, n_gpu: 1
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /microsoft/graphcodebert-base/resolve/main/config.json HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /microsoft/graphcodebert-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
INFO:name:Preparing the code search Dataset...

INFO:name:Preparing the code search Dataset...

INFO:name:Preparing the code search Dataset...

INFO:name:[{'insert_modules': ('attention.output', 'attention.self'), 'bottleneck_dim': (32, 32), 'non_linearity': 'relu', 'dropout_rate': 0.1, 'normalization': 'layer_norm', 'skip_connection': True}, 0, 0, {'insert_modules': ('attention.self',), 'bottleneck_dim': (32,), 'non_linearity': 'gelu_new', 'dropout_rate': 0.0, 'normalization': 'layer_norm', 'skip_connection': True}, 0, {'insert_modules': ('attention.output', 'output', 'attention.self'), 'bottleneck_dim': (32, 256, 32), 'non_linearity': 'gelu_new', 'dropout_rate': 0.25, 'normalization': 'layer_norm', 'skip_connection': True}, 0, 0, 0, {'insert_modules': ('attention.self',), 'bottleneck_dim': (32,), 'non_linearity': 'gelu_new', 'dropout_rate': 0.2, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.output', 'intermediate'), 'bottleneck_dim': (32, 128), 'non_linearity': 'relu', 'dropout_rate': 0.3, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('output',), 'bottleneck_dim': (128,), 'non_linearity': 'leakyrelu', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}]
[INFO|(OpenDelta)basemodel:700]2025-01-06 21:07:36,316 >> Trainable Ratio: 1731872/126377504=1.370396%
[INFO|(OpenDelta)basemodel:702]2025-01-06 21:07:36,316 >> Delta Parameter Ratio: 1731872/126377504=1.370396%
[INFO|(OpenDelta)basemodel:704]2025-01-06 21:07:36,316 >> Static Memory 0.00 GB, Max Memory 0.00 GB
INFO:name:2.0
/opt/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:name:***** Running training *****
INFO:name:  Num examples = 251820
INFO:name:  Num Epochs = 15
INFO:name:  Instantaneous batch size per GPU = 32
INFO:name:  Total train batch size  = 32
INFO:name:  Total optimization steps = 118050
INFO:name:epoch 0 step 100 loss 0.49752
INFO:name:epoch 0 step 200 loss 0.16351
INFO:name:epoch 0 step 300 loss 0.13781
INFO:name:epoch 0 step 400 loss 0.12531
INFO:name:epoch 0 step 500 loss 0.11491
INFO:name:epoch 0 step 600 loss 0.12221
INFO:name:epoch 0 step 700 loss 0.12164
INFO:name:epoch 0 step 800 loss 0.12403
INFO:name:epoch 0 step 900 loss 0.09598
INFO:name:epoch 0 step 1000 loss 0.11508
INFO:name:epoch 0 step 1100 loss 0.11126
INFO:name:epoch 0 step 1200 loss 0.11046
INFO:name:epoch 0 step 1300 loss 0.1021
INFO:name:epoch 0 step 1400 loss 0.107
INFO:name:epoch 0 step 1500 loss 0.10934
INFO:name:epoch 0 step 1600 loss 0.08467
INFO:name:epoch 0 step 1700 loss 0.1062
INFO:name:epoch 0 step 1800 loss 0.09983
INFO:name:epoch 0 step 1900 loss 0.11183
INFO:name:epoch 0 step 2000 loss 0.09555
INFO:name:epoch 0 step 2100 loss 0.10276
INFO:name:epoch 0 step 2200 loss 0.08937
INFO:name:epoch 0 step 2300 loss 0.09279
INFO:name:epoch 0 step 2400 loss 0.1039
INFO:name:epoch 0 step 2500 loss 0.09527
INFO:name:epoch 0 step 2600 loss 0.10864
INFO:name:epoch 0 step 2700 loss 0.10117
INFO:name:epoch 0 step 2800 loss 0.07996
INFO:name:epoch 0 step 2900 loss 0.10189
INFO:name:epoch 0 step 3000 loss 0.10186
INFO:name:epoch 0 step 3100 loss 0.10634
INFO:name:epoch 0 step 3200 loss 0.09681
INFO:name:epoch 0 step 3300 loss 0.089
INFO:name:epoch 0 step 3400 loss 0.08154
INFO:name:epoch 0 step 3500 loss 0.09021
INFO:name:epoch 0 step 3600 loss 0.09394
INFO:name:epoch 0 step 3700 loss 0.10291
INFO:name:epoch 0 step 3800 loss 0.09736
INFO:name:epoch 0 step 3900 loss 0.0832
INFO:name:epoch 0 step 4000 loss 0.07448
INFO:name:epoch 0 step 4100 loss 0.08024
INFO:name:epoch 0 step 4200 loss 0.09458
INFO:name:epoch 0 step 4300 loss 0.07842
INFO:name:epoch 0 step 4400 loss 0.07752
INFO:name:epoch 0 step 4500 loss 0.09816
INFO:name:epoch 0 step 4600 loss 0.07184
INFO:name:epoch 0 step 4700 loss 0.08362
INFO:name:epoch 0 step 4800 loss 0.08075
INFO:name:epoch 0 step 4900 loss 0.08056
INFO:name:epoch 0 step 5000 loss 0.09507
INFO:name:epoch 0 step 5100 loss 0.07807
INFO:name:epoch 0 step 5200 loss 0.08535
INFO:name:epoch 0 step 5300 loss 0.07086
INFO:name:epoch 0 step 5400 loss 0.07015
INFO:name:epoch 0 step 5500 loss 0.08249
INFO:name:epoch 0 step 5600 loss 0.08428
INFO:name:epoch 0 step 5700 loss 0.08038
INFO:name:epoch 0 step 5800 loss 0.07862
INFO:name:epoch 0 step 5900 loss 0.07178
INFO:name:epoch 0 step 6000 loss 0.08159
INFO:name:epoch 0 step 6100 loss 0.08241
INFO:name:epoch 0 step 6200 loss 0.07176
INFO:name:epoch 0 step 6300 loss 0.07348
INFO:name:epoch 0 step 6400 loss 0.07245
INFO:name:epoch 0 step 6500 loss 0.07289
INFO:name:epoch 0 step 6600 loss 0.08095
INFO:name:epoch 0 step 6700 loss 0.07792
INFO:name:epoch 0 step 6800 loss 0.07146
INFO:name:epoch 0 step 6900 loss 0.07872
INFO:name:epoch 0 step 7000 loss 0.07402
INFO:name:epoch 0 step 7100 loss 0.07308
INFO:name:epoch 0 step 7200 loss 0.07849
INFO:name:epoch 0 step 7300 loss 0.09213
INFO:name:epoch 0 step 7400 loss 0.0758
INFO:name:epoch 0 step 7500 loss 0.06762
INFO:name:epoch 0 step 7600 loss 0.0705
INFO:name:epoch 0 step 7700 loss 0.07261
INFO:name:epoch 0 step 7800 loss 0.05892
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4325
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4325
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3662
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 1 step 100 loss 0.05678
INFO:name:epoch 1 step 200 loss 0.04361
INFO:name:epoch 1 step 300 loss 0.05433
INFO:name:epoch 1 step 400 loss 0.04693
INFO:name:epoch 1 step 500 loss 0.04945
INFO:name:epoch 1 step 600 loss 0.05213
INFO:name:epoch 1 step 700 loss 0.05142
INFO:name:epoch 1 step 800 loss 0.0374
INFO:name:epoch 1 step 900 loss 0.041
INFO:name:epoch 1 step 1000 loss 0.03928
INFO:name:epoch 1 step 1100 loss 0.05685
INFO:name:epoch 1 step 1200 loss 0.05174
INFO:name:epoch 1 step 1300 loss 0.04413
INFO:name:epoch 1 step 1400 loss 0.04692
INFO:name:epoch 1 step 1500 loss 0.04563
INFO:name:epoch 1 step 1600 loss 0.04622
INFO:name:epoch 1 step 1700 loss 0.0488
INFO:name:epoch 1 step 1800 loss 0.04792
INFO:name:epoch 1 step 1900 loss 0.05358
INFO:name:epoch 1 step 2000 loss 0.0491
INFO:name:epoch 1 step 2100 loss 0.05272
INFO:name:epoch 1 step 2200 loss 0.05012
INFO:name:epoch 1 step 2300 loss 0.04967
INFO:name:epoch 1 step 2400 loss 0.05637
INFO:name:epoch 1 step 2500 loss 0.04094
INFO:name:epoch 1 step 2600 loss 0.04758
INFO:name:epoch 1 step 2700 loss 0.05117
INFO:name:epoch 1 step 2800 loss 0.03696
INFO:name:epoch 1 step 2900 loss 0.05134
INFO:name:epoch 1 step 3000 loss 0.0544
INFO:name:epoch 1 step 3100 loss 0.04448
INFO:name:epoch 1 step 3200 loss 0.05496
INFO:name:epoch 1 step 3300 loss 0.03637
INFO:name:epoch 1 step 3400 loss 0.03542
INFO:name:epoch 1 step 3500 loss 0.04883
INFO:name:epoch 1 step 3600 loss 0.04537
INFO:name:epoch 1 step 3700 loss 0.04619
INFO:name:epoch 1 step 3800 loss 0.05007
INFO:name:epoch 1 step 3900 loss 0.04066
INFO:name:epoch 1 step 4000 loss 0.04669
INFO:name:epoch 1 step 4100 loss 0.04477
INFO:name:epoch 1 step 4200 loss 0.04269
INFO:name:epoch 1 step 4300 loss 0.04007
INFO:name:epoch 1 step 4400 loss 0.04665
INFO:name:epoch 1 step 4500 loss 0.05142
INFO:name:epoch 1 step 4600 loss 0.03651
INFO:name:epoch 1 step 4700 loss 0.04596
INFO:name:epoch 1 step 4800 loss 0.04486
INFO:name:epoch 1 step 4900 loss 0.0491
INFO:name:epoch 1 step 5000 loss 0.0452
INFO:name:epoch 1 step 5100 loss 0.04433
INFO:name:epoch 1 step 5200 loss 0.04374
INFO:name:epoch 1 step 5300 loss 0.05341
INFO:name:epoch 1 step 5400 loss 0.04761
INFO:name:epoch 1 step 5500 loss 0.05135
INFO:name:epoch 1 step 5600 loss 0.04572
INFO:name:epoch 1 step 5700 loss 0.05432
INFO:name:epoch 1 step 5800 loss 0.04962
INFO:name:epoch 1 step 5900 loss 0.05478
INFO:name:epoch 1 step 6000 loss 0.05254
INFO:name:epoch 1 step 6100 loss 0.04913
INFO:name:epoch 1 step 6200 loss 0.04347
INFO:name:epoch 1 step 6300 loss 0.05644
INFO:name:epoch 1 step 6400 loss 0.03937
INFO:name:epoch 1 step 6500 loss 0.05407
INFO:name:epoch 1 step 6600 loss 0.03922
INFO:name:epoch 1 step 6700 loss 0.03371
INFO:name:epoch 1 step 6800 loss 0.04573
INFO:name:epoch 1 step 6900 loss 0.04915
INFO:name:epoch 1 step 7000 loss 0.05142
INFO:name:epoch 1 step 7100 loss 0.04892
INFO:name:epoch 1 step 7200 loss 0.03668
INFO:name:epoch 1 step 7300 loss 0.04339
INFO:name:epoch 1 step 7400 loss 0.04106
INFO:name:epoch 1 step 7500 loss 0.05007
INFO:name:epoch 1 step 7600 loss 0.04748
INFO:name:epoch 1 step 7700 loss 0.03805
INFO:name:epoch 1 step 7800 loss 0.0484
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4493
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4493
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3826
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 2 step 100 loss 0.04293
INFO:name:epoch 2 step 200 loss 0.03569
INFO:name:epoch 2 step 300 loss 0.03389
INFO:name:epoch 2 step 400 loss 0.03347
INFO:name:epoch 2 step 500 loss 0.03429
INFO:name:epoch 2 step 600 loss 0.03809
INFO:name:epoch 2 step 700 loss 0.03102
INFO:name:epoch 2 step 800 loss 0.04013
INFO:name:epoch 2 step 900 loss 0.03838
INFO:name:epoch 2 step 1000 loss 0.03771
INFO:name:epoch 2 step 1100 loss 0.03347
INFO:name:epoch 2 step 1200 loss 0.03252
INFO:name:epoch 2 step 1300 loss 0.03697
INFO:name:epoch 2 step 1400 loss 0.04129
INFO:name:epoch 2 step 1500 loss 0.0328
INFO:name:epoch 2 step 1600 loss 0.0348
INFO:name:epoch 2 step 1700 loss 0.02974
INFO:name:epoch 2 step 1800 loss 0.03441
INFO:name:epoch 2 step 1900 loss 0.03247
INFO:name:epoch 2 step 2000 loss 0.04029
INFO:name:epoch 2 step 2100 loss 0.02588
INFO:name:epoch 2 step 2200 loss 0.03483
INFO:name:epoch 2 step 2300 loss 0.04061
INFO:name:epoch 2 step 2400 loss 0.03682
INFO:name:epoch 2 step 2500 loss 0.03877
INFO:name:epoch 2 step 2600 loss 0.03126
INFO:name:epoch 2 step 2700 loss 0.03315
INFO:name:epoch 2 step 2800 loss 0.0381
INFO:name:epoch 2 step 2900 loss 0.03149
INFO:name:epoch 2 step 3000 loss 0.04226
INFO:name:epoch 2 step 3100 loss 0.03148
INFO:name:epoch 2 step 3200 loss 0.03455
INFO:name:epoch 2 step 3300 loss 0.03397
INFO:name:epoch 2 step 3400 loss 0.03185
INFO:name:epoch 2 step 3500 loss 0.02623
INFO:name:epoch 2 step 3600 loss 0.03223
INFO:name:epoch 2 step 3700 loss 0.03641
INFO:name:epoch 2 step 3800 loss 0.03486
INFO:name:epoch 2 step 3900 loss 0.04248
INFO:name:epoch 2 step 4000 loss 0.03893
INFO:name:epoch 2 step 4100 loss 0.03267
INFO:name:epoch 2 step 4200 loss 0.03453
INFO:name:epoch 2 step 4300 loss 0.04097
INFO:name:epoch 2 step 4400 loss 0.03608
INFO:name:epoch 2 step 4500 loss 0.03488
INFO:name:epoch 2 step 4600 loss 0.03561
INFO:name:epoch 2 step 4700 loss 0.02904
INFO:name:epoch 2 step 4800 loss 0.03408
INFO:name:epoch 2 step 4900 loss 0.03906
INFO:name:epoch 2 step 5000 loss 0.03672
INFO:name:epoch 2 step 5100 loss 0.04536
INFO:name:epoch 2 step 5200 loss 0.0366
INFO:name:epoch 2 step 5300 loss 0.02802
INFO:name:epoch 2 step 5400 loss 0.04351
INFO:name:epoch 2 step 5500 loss 0.0275
INFO:name:epoch 2 step 5600 loss 0.03758
INFO:name:epoch 2 step 5700 loss 0.03189
INFO:name:epoch 2 step 5800 loss 0.03912
INFO:name:epoch 2 step 5900 loss 0.03546
INFO:name:epoch 2 step 6000 loss 0.03295
INFO:name:epoch 2 step 6100 loss 0.03497
INFO:name:epoch 2 step 6200 loss 0.0389
INFO:name:epoch 2 step 6300 loss 0.03303
INFO:name:epoch 2 step 6400 loss 0.03765
INFO:name:epoch 2 step 6500 loss 0.03007
INFO:name:epoch 2 step 6600 loss 0.03844
INFO:name:epoch 2 step 6700 loss 0.04243
INFO:name:epoch 2 step 6800 loss 0.03452
INFO:name:epoch 2 step 6900 loss 0.03944
INFO:name:epoch 2 step 7000 loss 0.03271
INFO:name:epoch 2 step 7100 loss 0.03693
INFO:name:epoch 2 step 7200 loss 0.02974
INFO:name:epoch 2 step 7300 loss 0.03527
INFO:name:epoch 2 step 7400 loss 0.04691
INFO:name:epoch 2 step 7500 loss 0.03841
INFO:name:epoch 2 step 7600 loss 0.03228
INFO:name:epoch 2 step 7700 loss 0.0373
INFO:name:epoch 2 step 7800 loss 0.03576
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4355
INFO:name:epoch 3 step 100 loss 0.03261
INFO:name:epoch 3 step 200 loss 0.02261
INFO:name:epoch 3 step 300 loss 0.02151
INFO:name:epoch 3 step 400 loss 0.02402
INFO:name:epoch 3 step 500 loss 0.02899
INFO:name:epoch 3 step 600 loss 0.02662
INFO:name:epoch 3 step 700 loss 0.0326
INFO:name:epoch 3 step 800 loss 0.02295
INFO:name:epoch 3 step 900 loss 0.02676
INFO:name:epoch 3 step 1000 loss 0.03618
INFO:name:epoch 3 step 1100 loss 0.03149
INFO:name:epoch 3 step 1200 loss 0.02403
INFO:name:epoch 3 step 1300 loss 0.03069
INFO:name:epoch 3 step 1400 loss 0.02995
INFO:name:epoch 3 step 1500 loss 0.0219
INFO:name:epoch 3 step 1600 loss 0.0252
INFO:name:epoch 3 step 1700 loss 0.03076
INFO:name:epoch 3 step 1800 loss 0.02458
INFO:name:epoch 3 step 1900 loss 0.02826
INFO:name:epoch 3 step 2000 loss 0.02718
INFO:name:epoch 3 step 2100 loss 0.02509
INFO:name:epoch 3 step 2200 loss 0.02281
INFO:name:epoch 3 step 2300 loss 0.03253
INFO:name:epoch 3 step 2400 loss 0.02504
INFO:name:epoch 3 step 2500 loss 0.02982
INFO:name:epoch 3 step 2600 loss 0.02116
INFO:name:epoch 3 step 2700 loss 0.02451
INFO:name:epoch 3 step 2800 loss 0.02779
INFO:name:epoch 3 step 2900 loss 0.0254
INFO:name:epoch 3 step 3000 loss 0.0221
INFO:name:epoch 3 step 3100 loss 0.03344
INFO:name:epoch 3 step 3200 loss 0.03087
INFO:name:epoch 3 step 3300 loss 0.02726
INFO:name:epoch 3 step 3400 loss 0.02637
INFO:name:epoch 3 step 3500 loss 0.02198
INFO:name:epoch 3 step 3600 loss 0.02735
INFO:name:epoch 3 step 3700 loss 0.03908
INFO:name:epoch 3 step 3800 loss 0.02516
INFO:name:epoch 3 step 3900 loss 0.03166
INFO:name:epoch 3 step 4000 loss 0.029
INFO:name:epoch 3 step 4100 loss 0.02861
INFO:name:epoch 3 step 4200 loss 0.0265
INFO:name:epoch 3 step 4300 loss 0.02695
INFO:name:epoch 3 step 4400 loss 0.02464
INFO:name:epoch 3 step 4500 loss 0.03727
INFO:name:epoch 3 step 4600 loss 0.03094
INFO:name:epoch 3 step 4700 loss 0.02522
INFO:name:epoch 3 step 4800 loss 0.02851
INFO:name:epoch 3 step 4900 loss 0.02546
INFO:name:epoch 3 step 5000 loss 0.02276
INFO:name:epoch 3 step 5100 loss 0.02293
INFO:name:epoch 3 step 5200 loss 0.03204
INFO:name:epoch 3 step 5300 loss 0.02189
INFO:name:epoch 3 step 5400 loss 0.02735
INFO:name:epoch 3 step 5500 loss 0.02461
INFO:name:epoch 3 step 5600 loss 0.03328
INFO:name:epoch 3 step 5700 loss 0.03093
INFO:name:epoch 3 step 5800 loss 0.02784
INFO:name:epoch 3 step 5900 loss 0.03758
INFO:name:epoch 3 step 6000 loss 0.03262
INFO:name:epoch 3 step 6100 loss 0.03123
INFO:name:epoch 3 step 6200 loss 0.02956
INFO:name:epoch 3 step 6300 loss 0.02493
INFO:name:epoch 3 step 6400 loss 0.03383
INFO:name:epoch 3 step 6500 loss 0.02613
INFO:name:epoch 3 step 6600 loss 0.02528
INFO:name:epoch 3 step 6700 loss 0.02649
INFO:name:epoch 3 step 6800 loss 0.02982
INFO:name:epoch 3 step 6900 loss 0.02766
INFO:name:epoch 3 step 7000 loss 0.03183
INFO:name:epoch 3 step 7100 loss 0.02347
INFO:name:epoch 3 step 7200 loss 0.02366
INFO:name:epoch 3 step 7300 loss 0.03545
INFO:name:epoch 3 step 7400 loss 0.02356
INFO:name:epoch 3 step 7500 loss 0.0236
INFO:name:epoch 3 step 7600 loss 0.03129
INFO:name:epoch 3 step 7700 loss 0.02411
INFO:name:epoch 3 step 7800 loss 0.03072
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4258
INFO:name:epoch 4 step 100 loss 0.02127
INFO:name:epoch 4 step 200 loss 0.01592
INFO:name:epoch 4 step 300 loss 0.01605
INFO:name:epoch 4 step 400 loss 0.02179
INFO:name:epoch 4 step 500 loss 0.02241
INFO:name:epoch 4 step 600 loss 0.01831
INFO:name:epoch 4 step 700 loss 0.01786
INFO:name:epoch 4 step 800 loss 0.02256
INFO:name:epoch 4 step 900 loss 0.02356
INFO:name:epoch 4 step 1000 loss 0.02345
INFO:name:epoch 4 step 1100 loss 0.01823
INFO:name:epoch 4 step 1200 loss 0.02081
INFO:name:epoch 4 step 1300 loss 0.01691
INFO:name:epoch 4 step 1400 loss 0.0193
INFO:name:epoch 4 step 1500 loss 0.02543
INFO:name:epoch 4 step 1600 loss 0.02456
INFO:name:epoch 4 step 1700 loss 0.02142
INFO:name:epoch 4 step 1800 loss 0.02521
INFO:name:epoch 4 step 1900 loss 0.02001
INFO:name:epoch 4 step 2000 loss 0.0261
INFO:name:epoch 4 step 2100 loss 0.02005
INFO:name:epoch 4 step 2200 loss 0.02035
INFO:name:epoch 4 step 2300 loss 0.02354
INFO:name:epoch 4 step 2400 loss 0.02433
INFO:name:epoch 4 step 2500 loss 0.01633
INFO:name:epoch 4 step 2600 loss 0.02249
INFO:name:epoch 4 step 2700 loss 0.02266
INFO:name:epoch 4 step 2800 loss 0.02234
INFO:name:epoch 4 step 2900 loss 0.0196
INFO:name:epoch 4 step 3000 loss 0.02524
INFO:name:epoch 4 step 3100 loss 0.01727
INFO:name:epoch 4 step 3200 loss 0.02515
INFO:name:epoch 4 step 3300 loss 0.02409
INFO:name:epoch 4 step 3400 loss 0.01993
INFO:name:epoch 4 step 3500 loss 0.01923
INFO:name:epoch 4 step 3600 loss 0.01995
INFO:name:epoch 4 step 3700 loss 0.02069
INFO:name:epoch 4 step 3800 loss 0.02694
INFO:name:epoch 4 step 3900 loss 0.02183
INFO:name:epoch 4 step 4000 loss 0.01891
INFO:name:epoch 4 step 4100 loss 0.02182
INFO:name:epoch 4 step 4200 loss 0.01987
INFO:name:epoch 4 step 4300 loss 0.01905
INFO:name:epoch 4 step 4400 loss 0.0191
INFO:name:epoch 4 step 4500 loss 0.02863
INFO:name:epoch 4 step 4600 loss 0.01985
INFO:name:epoch 4 step 4700 loss 0.02441
INFO:name:epoch 4 step 4800 loss 0.02352
INFO:name:epoch 4 step 4900 loss 0.02049
INFO:name:epoch 4 step 5000 loss 0.02255
INFO:name:epoch 4 step 5100 loss 0.01963
INFO:name:epoch 4 step 5200 loss 0.02433
INFO:name:epoch 4 step 5300 loss 0.02393
INFO:name:epoch 4 step 5400 loss 0.01942
INFO:name:epoch 4 step 5500 loss 0.02727
INFO:name:epoch 4 step 5600 loss 0.02986
INFO:name:epoch 4 step 5700 loss 0.02185
INFO:name:epoch 4 step 5800 loss 0.02444
INFO:name:epoch 4 step 5900 loss 0.02159
INFO:name:epoch 4 step 6000 loss 0.01919
INFO:name:epoch 4 step 6100 loss 0.02004
INFO:name:epoch 4 step 6200 loss 0.01764
INFO:name:epoch 4 step 6300 loss 0.0245
INFO:name:epoch 4 step 6400 loss 0.02558
INFO:name:epoch 4 step 6500 loss 0.02937
INFO:name:epoch 4 step 6600 loss 0.02382
INFO:name:epoch 4 step 6700 loss 0.02352
INFO:name:epoch 4 step 6800 loss 0.0224
INFO:name:epoch 4 step 6900 loss 0.02229
INFO:name:epoch 4 step 7000 loss 0.02019
INFO:name:epoch 4 step 7100 loss 0.0291
INFO:name:epoch 4 step 7200 loss 0.02729
INFO:name:epoch 4 step 7300 loss 0.01684
INFO:name:epoch 4 step 7400 loss 0.02423
INFO:name:epoch 4 step 7500 loss 0.01835
INFO:name:epoch 4 step 7600 loss 0.01937
INFO:name:epoch 4 step 7700 loss 0.02432
INFO:name:epoch 4 step 7800 loss 0.0243
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4271
INFO:name:epoch 5 step 100 loss 0.01846
INFO:name:epoch 5 step 200 loss 0.01562
INFO:name:epoch 5 step 300 loss 0.01536
INFO:name:epoch 5 step 400 loss 0.01692
INFO:name:epoch 5 step 500 loss 0.01614
INFO:name:epoch 5 step 600 loss 0.01727
INFO:name:epoch 5 step 700 loss 0.01603
INFO:name:epoch 5 step 800 loss 0.01514
INFO:name:epoch 5 step 900 loss 0.01735
INFO:name:epoch 5 step 1000 loss 0.02027
INFO:name:epoch 5 step 1100 loss 0.01737
INFO:name:epoch 5 step 1200 loss 0.01826
INFO:name:epoch 5 step 1300 loss 0.01517
INFO:name:epoch 5 step 1400 loss 0.01566
INFO:name:epoch 5 step 1500 loss 0.016
INFO:name:epoch 5 step 1600 loss 0.01729
INFO:name:epoch 5 step 1700 loss 0.01751
INFO:name:epoch 5 step 1800 loss 0.01364
INFO:name:epoch 5 step 1900 loss 0.01646
INFO:name:epoch 5 step 2000 loss 0.0174
INFO:name:epoch 5 step 2100 loss 0.01174
INFO:name:epoch 5 step 2200 loss 0.01661
INFO:name:epoch 5 step 2300 loss 0.01524
INFO:name:epoch 5 step 2400 loss 0.01862
INFO:name:epoch 5 step 2500 loss 0.01589
INFO:name:epoch 5 step 2600 loss 0.01669
INFO:name:epoch 5 step 2700 loss 0.01982
INFO:name:epoch 5 step 2800 loss 0.01887
INFO:name:epoch 5 step 2900 loss 0.0137
INFO:name:epoch 5 step 3000 loss 0.01489
INFO:name:epoch 5 step 3100 loss 0.01663
INFO:name:epoch 5 step 3200 loss 0.0144
INFO:name:epoch 5 step 3300 loss 0.01388
INFO:name:epoch 5 step 3400 loss 0.02208
INFO:name:epoch 5 step 3500 loss 0.02384
INFO:name:epoch 5 step 3600 loss 0.01765
INFO:name:epoch 5 step 3700 loss 0.0154
INFO:name:epoch 5 step 3800 loss 0.01824
INFO:name:epoch 5 step 3900 loss 0.01874
INFO:name:epoch 5 step 4000 loss 0.01511
INFO:name:epoch 5 step 4100 loss 0.01763
INFO:name:epoch 5 step 4200 loss 0.01719
INFO:name:epoch 5 step 4300 loss 0.01791
INFO:name:epoch 5 step 4400 loss 0.01395
INFO:name:epoch 5 step 4500 loss 0.01978
INFO:name:epoch 5 step 4600 loss 0.01403
INFO:name:epoch 5 step 4700 loss 0.01731
INFO:name:epoch 5 step 4800 loss 0.01955
INFO:name:epoch 5 step 4900 loss 0.02418
INFO:name:epoch 5 step 5000 loss 0.0184
INFO:name:epoch 5 step 5100 loss 0.01615
INFO:name:epoch 5 step 5200 loss 0.0188
INFO:name:epoch 5 step 5300 loss 0.01816
INFO:name:epoch 5 step 5400 loss 0.01762
INFO:name:epoch 5 step 5500 loss 0.01555
INFO:name:epoch 5 step 5600 loss 0.01666
INFO:name:epoch 5 step 5700 loss 0.01902
INFO:name:epoch 5 step 5800 loss 0.01647
INFO:name:epoch 5 step 5900 loss 0.01839
INFO:name:epoch 5 step 6000 loss 0.02171
INFO:name:epoch 5 step 6100 loss 0.01701
INFO:name:epoch 5 step 6200 loss 0.01764
INFO:name:epoch 5 step 6300 loss 0.01854
INFO:name:epoch 5 step 6400 loss 0.01633
INFO:name:epoch 5 step 6500 loss 0.01937
INFO:name:epoch 5 step 6600 loss 0.01766
INFO:name:epoch 5 step 6700 loss 0.02128
INFO:name:epoch 5 step 6800 loss 0.01933
INFO:name:epoch 5 step 6900 loss 0.01662
INFO:name:epoch 5 step 7000 loss 0.02298
INFO:name:epoch 5 step 7100 loss 0.01897
INFO:name:epoch 5 step 7200 loss 0.02347
INFO:name:epoch 5 step 7300 loss 0.02253
INFO:name:epoch 5 step 7400 loss 0.01746
INFO:name:epoch 5 step 7500 loss 0.02622
INFO:name:epoch 5 step 7600 loss 0.01928
INFO:name:epoch 5 step 7700 loss 0.02165
INFO:name:epoch 5 step 7800 loss 0.01624
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4276
INFO:name:epoch 6 step 100 loss 0.01522
INFO:name:epoch 6 step 200 loss 0.01667
INFO:name:epoch 6 step 300 loss 0.01478
INFO:name:epoch 6 step 400 loss 0.01362
INFO:name:epoch 6 step 500 loss 0.01189
INFO:name:epoch 6 step 600 loss 0.01371
INFO:name:epoch 6 step 700 loss 0.01251
INFO:name:epoch 6 step 800 loss 0.01492
INFO:name:epoch 6 step 900 loss 0.01351
INFO:name:epoch 6 step 1000 loss 0.01353
INFO:name:epoch 6 step 1100 loss 0.01381
INFO:name:epoch 6 step 1200 loss 0.01372
INFO:name:epoch 6 step 1300 loss 0.01335
INFO:name:epoch 6 step 1400 loss 0.01171
INFO:name:epoch 6 step 1500 loss 0.01277
INFO:name:epoch 6 step 1600 loss 0.01439
INFO:name:epoch 6 step 1700 loss 0.01702
INFO:name:epoch 6 step 1800 loss 0.01308
INFO:name:epoch 6 step 1900 loss 0.01252
INFO:name:epoch 6 step 2000 loss 0.01679
INFO:name:epoch 6 step 2100 loss 0.01325
INFO:name:epoch 6 step 2200 loss 0.01048
INFO:name:epoch 6 step 2300 loss 0.01192
INFO:name:epoch 6 step 2400 loss 0.01089
INFO:name:epoch 6 step 2500 loss 0.01246
INFO:name:epoch 6 step 2600 loss 0.01844
INFO:name:epoch 6 step 2700 loss 0.01431
INFO:name:epoch 6 step 2800 loss 0.01782
INFO:name:epoch 6 step 2900 loss 0.01386
INFO:name:epoch 6 step 3000 loss 0.01745
INFO:name:epoch 6 step 3100 loss 0.01579
INFO:name:epoch 6 step 3200 loss 0.01305
INFO:name:epoch 6 step 3300 loss 0.01456
INFO:name:epoch 6 step 3400 loss 0.01259
INFO:name:epoch 6 step 3500 loss 0.01347
INFO:name:epoch 6 step 3600 loss 0.01314
INFO:name:epoch 6 step 3700 loss 0.0145
INFO:name:epoch 6 step 3800 loss 0.01491
INFO:name:epoch 6 step 3900 loss 0.01654
INFO:name:epoch 6 step 4000 loss 0.01705
INFO:name:epoch 6 step 4100 loss 0.01471
INFO:name:epoch 6 step 4200 loss 0.01724
INFO:name:epoch 6 step 4300 loss 0.01335
INFO:name:epoch 6 step 4400 loss 0.01555
INFO:name:epoch 6 step 4500 loss 0.01449
INFO:name:epoch 6 step 4600 loss 0.01416
INFO:name:epoch 6 step 4700 loss 0.01449
INFO:name:epoch 6 step 4800 loss 0.01717
INFO:name:epoch 6 step 4900 loss 0.01399
INFO:name:epoch 6 step 5000 loss 0.01488
INFO:name:epoch 6 step 5100 loss 0.01339
INFO:name:epoch 6 step 5200 loss 0.01359
INFO:name:epoch 6 step 5300 loss 0.01319
INFO:name:epoch 6 step 5400 loss 0.01559
INFO:name:epoch 6 step 5500 loss 0.01207
INFO:name:epoch 6 step 5600 loss 0.01447
INFO:name:epoch 6 step 5700 loss 0.01152
INFO:name:epoch 6 step 5800 loss 0.01433
INFO:name:epoch 6 step 5900 loss 0.01763
INFO:name:epoch 6 step 6000 loss 0.01274
INFO:name:epoch 6 step 6100 loss 0.01818
INFO:name:epoch 6 step 6200 loss 0.01562
INFO:name:epoch 6 step 6300 loss 0.01567
INFO:name:epoch 6 step 6400 loss 0.01294
INFO:name:epoch 6 step 6500 loss 0.01127
INFO:name:epoch 6 step 6600 loss 0.01348
INFO:name:epoch 6 step 6700 loss 0.01747
INFO:name:epoch 6 step 6800 loss 0.01506
INFO:name:epoch 6 step 6900 loss 0.01686
INFO:name:epoch 6 step 7000 loss 0.01189
INFO:name:epoch 6 step 7100 loss 0.01373
INFO:name:epoch 6 step 7200 loss 0.01697
INFO:name:epoch 6 step 7300 loss 0.01425
INFO:name:epoch 6 step 7400 loss 0.01485
INFO:name:epoch 6 step 7500 loss 0.0118
INFO:name:epoch 6 step 7600 loss 0.01707
INFO:name:epoch 6 step 7700 loss 0.01159
INFO:name:epoch 6 step 7800 loss 0.01446
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.423
INFO:name:epoch 7 step 100 loss 0.01233
INFO:name:epoch 7 step 200 loss 0.01599
INFO:name:epoch 7 step 300 loss 0.01248
INFO:name:epoch 7 step 400 loss 0.01276
INFO:name:epoch 7 step 500 loss 0.01622
INFO:name:epoch 7 step 600 loss 0.01255
INFO:name:epoch 7 step 700 loss 0.01106
INFO:name:epoch 7 step 800 loss 0.01152
INFO:name:epoch 7 step 900 loss 0.0119
INFO:name:epoch 7 step 1000 loss 0.01189
INFO:name:epoch 7 step 1100 loss 0.01476
INFO:name:epoch 7 step 1200 loss 0.0119
INFO:name:epoch 7 step 1300 loss 0.00964
INFO:name:epoch 7 step 1400 loss 0.01196
INFO:name:epoch 7 step 1500 loss 0.01127
INFO:name:epoch 7 step 1600 loss 0.01136
INFO:name:epoch 7 step 1700 loss 0.00956
INFO:name:epoch 7 step 1800 loss 0.01288
INFO:name:epoch 7 step 1900 loss 0.01213
INFO:name:epoch 7 step 2000 loss 0.0132
INFO:name:epoch 7 step 2100 loss 0.01297
INFO:name:epoch 7 step 2200 loss 0.01099
INFO:name:epoch 7 step 2300 loss 0.01102
INFO:name:epoch 7 step 2400 loss 0.01261
INFO:name:epoch 7 step 2500 loss 0.00968
INFO:name:epoch 7 step 2600 loss 0.01241
INFO:name:epoch 7 step 2700 loss 0.01362
INFO:name:epoch 7 step 2800 loss 0.0108
INFO:name:epoch 7 step 2900 loss 0.00843
INFO:name:epoch 7 step 3000 loss 0.01063
INFO:name:epoch 7 step 3100 loss 0.01501
INFO:name:epoch 7 step 3200 loss 0.01301
INFO:name:epoch 7 step 3300 loss 0.0105
INFO:name:epoch 7 step 3400 loss 0.01312
INFO:name:epoch 7 step 3500 loss 0.01219
INFO:name:epoch 7 step 3600 loss 0.01186
INFO:name:epoch 7 step 3700 loss 0.01248
INFO:name:epoch 7 step 3800 loss 0.01236
INFO:name:epoch 7 step 3900 loss 0.01306
INFO:name:epoch 7 step 4000 loss 0.01258
INFO:name:epoch 7 step 4100 loss 0.00945
INFO:name:epoch 7 step 4200 loss 0.01335
INFO:name:epoch 7 step 4300 loss 0.01311
INFO:name:epoch 7 step 4400 loss 0.01711
INFO:name:epoch 7 step 4500 loss 0.00934
INFO:name:epoch 7 step 4600 loss 0.01236
INFO:name:epoch 7 step 4700 loss 0.01467
INFO:name:epoch 7 step 4800 loss 0.01367
INFO:name:epoch 7 step 4900 loss 0.01377
INFO:name:epoch 7 step 5000 loss 0.01182
INFO:name:epoch 7 step 5100 loss 0.01135
INFO:name:epoch 7 step 5200 loss 0.01145
INFO:name:epoch 7 step 5300 loss 0.01634
INFO:name:epoch 7 step 5400 loss 0.01655
INFO:name:epoch 7 step 5500 loss 0.01089
INFO:name:epoch 7 step 5600 loss 0.01011
INFO:name:epoch 7 step 5700 loss 0.01154
INFO:name:epoch 7 step 5800 loss 0.01364
INFO:name:epoch 7 step 5900 loss 0.01283
INFO:name:epoch 7 step 6000 loss 0.01188
INFO:name:epoch 7 step 6100 loss 0.01066
INFO:name:epoch 7 step 6200 loss 0.01389
INFO:name:epoch 7 step 6300 loss 0.01191
INFO:name:epoch 7 step 6400 loss 0.0152
INFO:name:epoch 7 step 6500 loss 0.01101
INFO:name:epoch 7 step 6600 loss 0.01253
INFO:name:epoch 7 step 6700 loss 0.01296
INFO:name:epoch 7 step 6800 loss 0.01203
INFO:name:epoch 7 step 6900 loss 0.01048
INFO:name:epoch 7 step 7000 loss 0.01192
INFO:name:epoch 7 step 7100 loss 0.01392
INFO:name:epoch 7 step 7200 loss 0.01386
INFO:name:epoch 7 step 7300 loss 0.01213
INFO:name:epoch 7 step 7400 loss 0.01345
INFO:name:epoch 7 step 7500 loss 0.01623
INFO:name:epoch 7 step 7600 loss 0.01123
INFO:name:epoch 7 step 7700 loss 0.0137
INFO:name:epoch 7 step 7800 loss 0.01481
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4165
INFO:name:epoch 8 step 100 loss 0.0115
INFO:name:epoch 8 step 200 loss 0.0097
INFO:name:epoch 8 step 300 loss 0.01216
INFO:name:epoch 8 step 400 loss 0.01234
INFO:name:epoch 8 step 500 loss 0.01042
INFO:name:epoch 8 step 600 loss 0.00808
INFO:name:epoch 8 step 700 loss 0.00967
INFO:name:epoch 8 step 800 loss 0.0136
INFO:name:epoch 8 step 900 loss 0.00953
INFO:name:epoch 8 step 1000 loss 0.01083
INFO:name:epoch 8 step 1100 loss 0.01109
INFO:name:epoch 8 step 1200 loss 0.01237
INFO:name:epoch 8 step 1300 loss 0.01113
INFO:name:epoch 8 step 1400 loss 0.01264
INFO:name:epoch 8 step 1500 loss 0.01341
INFO:name:epoch 8 step 1600 loss 0.01015
INFO:name:epoch 8 step 1700 loss 0.0117
INFO:name:epoch 8 step 1800 loss 0.00825
INFO:name:epoch 8 step 1900 loss 0.01229
INFO:name:epoch 8 step 2000 loss 0.01668
INFO:name:epoch 8 step 2100 loss 0.0111
INFO:name:epoch 8 step 2200 loss 0.00975
INFO:name:epoch 8 step 2300 loss 0.00861
INFO:name:epoch 8 step 2400 loss 0.01087
INFO:name:epoch 8 step 2500 loss 0.01166
INFO:name:epoch 8 step 2600 loss 0.01238
INFO:name:epoch 8 step 2700 loss 0.01124
INFO:name:epoch 8 step 2800 loss 0.00962
INFO:name:epoch 8 step 2900 loss 0.01227
INFO:name:epoch 8 step 3000 loss 0.01326
INFO:name:epoch 8 step 3100 loss 0.01159
INFO:name:epoch 8 step 3200 loss 0.01216
INFO:name:epoch 8 step 3300 loss 0.01107
INFO:name:epoch 8 step 3400 loss 0.01011
INFO:name:epoch 8 step 3500 loss 0.01006
INFO:name:epoch 8 step 3600 loss 0.00942
INFO:name:epoch 8 step 3700 loss 0.00902
INFO:name:epoch 8 step 3800 loss 0.01013
INFO:name:epoch 8 step 3900 loss 0.00896
INFO:name:epoch 8 step 4000 loss 0.01259
INFO:name:epoch 8 step 4100 loss 0.01283
INFO:name:epoch 8 step 4200 loss 0.01495
INFO:name:epoch 8 step 4300 loss 0.01292
INFO:name:epoch 8 step 4400 loss 0.0114
INFO:name:epoch 8 step 4500 loss 0.01048
INFO:name:epoch 8 step 4600 loss 0.01337
INFO:name:epoch 8 step 4700 loss 0.01299
INFO:name:epoch 8 step 4800 loss 0.00978
INFO:name:epoch 8 step 4900 loss 0.0115
INFO:name:epoch 8 step 5000 loss 0.01254
INFO:name:epoch 8 step 5100 loss 0.00847
INFO:name:epoch 8 step 5200 loss 0.01071
INFO:name:epoch 8 step 5300 loss 0.01308
INFO:name:epoch 8 step 5400 loss 0.01085
INFO:name:epoch 8 step 5500 loss 0.01275
INFO:name:epoch 8 step 5600 loss 0.01051
INFO:name:epoch 8 step 5700 loss 0.01486
INFO:name:epoch 8 step 5800 loss 0.01207
INFO:name:epoch 8 step 5900 loss 0.01378
INFO:name:epoch 8 step 6000 loss 0.01011
INFO:name:epoch 8 step 6100 loss 0.01032
INFO:name:epoch 8 step 6200 loss 0.01122
INFO:name:epoch 8 step 6300 loss 0.00792
INFO:name:epoch 8 step 6400 loss 0.00923
INFO:name:epoch 8 step 6500 loss 0.01354
INFO:name:epoch 8 step 6600 loss 0.01042
INFO:name:epoch 8 step 6700 loss 0.01343
INFO:name:epoch 8 step 6800 loss 0.01318
INFO:name:epoch 8 step 6900 loss 0.01304
INFO:name:epoch 8 step 7000 loss 0.00943
INFO:name:epoch 8 step 7100 loss 0.01599
INFO:name:epoch 8 step 7200 loss 0.01094
INFO:name:epoch 8 step 7300 loss 0.01028
INFO:name:epoch 8 step 7400 loss 0.01102
INFO:name:epoch 8 step 7500 loss 0.01091
INFO:name:epoch 8 step 7600 loss 0.0104
INFO:name:epoch 8 step 7700 loss 0.00939
INFO:name:epoch 8 step 7800 loss 0.01258
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4192
INFO:name:epoch 9 step 100 loss 0.01061
INFO:name:epoch 9 step 200 loss 0.00868
INFO:name:epoch 9 step 300 loss 0.01116
INFO:name:epoch 9 step 400 loss 0.01085
INFO:name:epoch 9 step 500 loss 0.01146
INFO:name:epoch 9 step 600 loss 0.00865
INFO:name:epoch 9 step 700 loss 0.01176
INFO:name:epoch 9 step 800 loss 0.0097
INFO:name:epoch 9 step 900 loss 0.00921
INFO:name:epoch 9 step 1000 loss 0.0112
INFO:name:epoch 9 step 1100 loss 0.01294
INFO:name:epoch 9 step 1200 loss 0.00837
INFO:name:epoch 9 step 1300 loss 0.01029
INFO:name:epoch 9 step 1400 loss 0.01245
INFO:name:epoch 9 step 1500 loss 0.01206
INFO:name:epoch 9 step 1600 loss 0.00805
INFO:name:epoch 9 step 1700 loss 0.0086
INFO:name:epoch 9 step 1800 loss 0.01104
INFO:name:epoch 9 step 1900 loss 0.01073
INFO:name:epoch 9 step 2000 loss 0.00852
INFO:name:epoch 9 step 2100 loss 0.00841
INFO:name:epoch 9 step 2200 loss 0.01148
INFO:name:epoch 9 step 2300 loss 0.01032
INFO:name:epoch 9 step 2400 loss 0.00844
INFO:name:epoch 9 step 2500 loss 0.01091
INFO:name:epoch 9 step 2600 loss 0.00907
INFO:name:epoch 9 step 2700 loss 0.01031
INFO:name:epoch 9 step 2800 loss 0.01071
INFO:name:epoch 9 step 2900 loss 0.01277
INFO:name:epoch 9 step 3000 loss 0.00953
INFO:name:epoch 9 step 3100 loss 0.00768
INFO:name:epoch 9 step 3200 loss 0.00964
INFO:name:epoch 9 step 3300 loss 0.01315
INFO:name:epoch 9 step 3400 loss 0.0084
INFO:name:epoch 9 step 3500 loss 0.01015
INFO:name:epoch 9 step 3600 loss 0.01048
INFO:name:epoch 9 step 3700 loss 0.0099
INFO:name:epoch 9 step 3800 loss 0.01175
INFO:name:epoch 9 step 3900 loss 0.00853
INFO:name:epoch 9 step 4000 loss 0.01243
INFO:name:epoch 9 step 4100 loss 0.00848
INFO:name:epoch 9 step 4200 loss 0.01067
INFO:name:epoch 9 step 4300 loss 0.01019
INFO:name:epoch 9 step 4400 loss 0.01013
INFO:name:epoch 9 step 4500 loss 0.0089
INFO:name:epoch 9 step 4600 loss 0.00942
INFO:name:epoch 9 step 4700 loss 0.0107
INFO:name:epoch 9 step 4800 loss 0.01113
INFO:name:epoch 9 step 4900 loss 0.01077
INFO:name:epoch 9 step 5000 loss 0.01048
INFO:name:epoch 9 step 5100 loss 0.01148
INFO:name:epoch 9 step 5200 loss 0.01174
INFO:name:epoch 9 step 5300 loss 0.01044
INFO:name:epoch 9 step 5400 loss 0.00798
INFO:name:epoch 9 step 5500 loss 0.00902
INFO:name:epoch 9 step 5600 loss 0.00929
INFO:name:epoch 9 step 5700 loss 0.01011
INFO:name:epoch 9 step 5800 loss 0.00989
INFO:name:epoch 9 step 5900 loss 0.00962
INFO:name:epoch 9 step 6000 loss 0.01036
INFO:name:epoch 9 step 6100 loss 0.01039
INFO:name:epoch 9 step 6200 loss 0.00969
INFO:name:epoch 9 step 6300 loss 0.01028
INFO:name:epoch 9 step 6400 loss 0.01211
INFO:name:epoch 9 step 6500 loss 0.00846
INFO:name:epoch 9 step 6600 loss 0.00972
INFO:name:epoch 9 step 6700 loss 0.009
INFO:name:epoch 9 step 6800 loss 0.01172
INFO:name:epoch 9 step 6900 loss 0.01093
INFO:name:epoch 9 step 7000 loss 0.01014
INFO:name:epoch 9 step 7100 loss 0.00981
INFO:name:epoch 9 step 7200 loss 0.01081
INFO:name:epoch 9 step 7300 loss 0.01044
INFO:name:epoch 9 step 7400 loss 0.00992
INFO:name:epoch 9 step 7500 loss 0.00929
INFO:name:epoch 9 step 7600 loss 0.01372
INFO:name:epoch 9 step 7700 loss 0.01034
INFO:name:epoch 9 step 7800 loss 0.00961
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4277
INFO:name:epoch 10 step 100 loss 0.00908
INFO:name:epoch 10 step 200 loss 0.01089
INFO:name:epoch 10 step 300 loss 0.00946
INFO:name:epoch 10 step 400 loss 0.00938
INFO:name:epoch 10 step 500 loss 0.00852
INFO:name:epoch 10 step 600 loss 0.0081
INFO:name:epoch 10 step 700 loss 0.00899
INFO:name:epoch 10 step 800 loss 0.00797
INFO:name:epoch 10 step 900 loss 0.01
INFO:name:epoch 10 step 1000 loss 0.00834
INFO:name:epoch 10 step 1100 loss 0.01113
INFO:name:epoch 10 step 1200 loss 0.00955
INFO:name:epoch 10 step 1300 loss 0.01087
INFO:name:epoch 10 step 1400 loss 0.01096
INFO:name:epoch 10 step 1500 loss 0.00777
INFO:name:epoch 10 step 1600 loss 0.00797
INFO:name:epoch 10 step 1700 loss 0.00896
INFO:name:epoch 10 step 1800 loss 0.00956
INFO:name:epoch 10 step 1900 loss 0.00924
INFO:name:epoch 10 step 2000 loss 0.00877
INFO:name:epoch 10 step 2100 loss 0.00909
INFO:name:epoch 10 step 2200 loss 0.0058
INFO:name:epoch 10 step 2300 loss 0.00841
INFO:name:epoch 10 step 2400 loss 0.01113
INFO:name:epoch 10 step 2500 loss 0.00822
INFO:name:epoch 10 step 2600 loss 0.00718
INFO:name:epoch 10 step 2700 loss 0.0088
INFO:name:epoch 10 step 2800 loss 0.0088
INFO:name:epoch 10 step 2900 loss 0.00847
INFO:name:epoch 10 step 3000 loss 0.00755
INFO:name:epoch 10 step 3100 loss 0.00981
INFO:name:epoch 10 step 3200 loss 0.00958
INFO:name:epoch 10 step 3300 loss 0.01528
INFO:name:epoch 10 step 3400 loss 0.00928
INFO:name:epoch 10 step 3500 loss 0.01254
INFO:name:epoch 10 step 3600 loss 0.00759
INFO:name:epoch 10 step 3700 loss 0.01006
INFO:name:epoch 10 step 3800 loss 0.00939
INFO:name:epoch 10 step 3900 loss 0.00866
INFO:name:epoch 10 step 4000 loss 0.00864
INFO:name:epoch 10 step 4100 loss 0.00997
INFO:name:epoch 10 step 4200 loss 0.00918
INFO:name:epoch 10 step 4300 loss 0.00988
INFO:name:epoch 10 step 4400 loss 0.00985
INFO:name:epoch 10 step 4500 loss 0.01176
INFO:name:epoch 10 step 4600 loss 0.01006
INFO:name:epoch 10 step 4700 loss 0.00865
INFO:name:epoch 10 step 4800 loss 0.0111
INFO:name:epoch 10 step 4900 loss 0.01015
INFO:name:epoch 10 step 5000 loss 0.00851
INFO:name:epoch 10 step 5100 loss 0.00851
INFO:name:epoch 10 step 5200 loss 0.00901
INFO:name:epoch 10 step 5300 loss 0.01206
INFO:name:epoch 10 step 5400 loss 0.00975
INFO:name:epoch 10 step 5500 loss 0.00976
INFO:name:epoch 10 step 5600 loss 0.00669
INFO:name:epoch 10 step 5700 loss 0.01095
INFO:name:epoch 10 step 5800 loss 0.00778
INFO:name:epoch 10 step 5900 loss 0.01057
INFO:name:epoch 10 step 6000 loss 0.00859
INFO:name:epoch 10 step 6100 loss 0.00929
INFO:name:epoch 10 step 6200 loss 0.0082
INFO:name:epoch 10 step 6300 loss 0.00798
INFO:name:epoch 10 step 6400 loss 0.0131
INFO:name:epoch 10 step 6500 loss 0.00845
INFO:name:epoch 10 step 6600 loss 0.00912
INFO:name:epoch 10 step 6700 loss 0.00869
INFO:name:epoch 10 step 6800 loss 0.00788
INFO:name:epoch 10 step 6900 loss 0.00882
INFO:name:epoch 10 step 7000 loss 0.01156
INFO:name:epoch 10 step 7100 loss 0.00853
INFO:name:epoch 10 step 7200 loss 0.0088
INFO:name:epoch 10 step 7300 loss 0.00996
INFO:name:epoch 10 step 7400 loss 0.0082
INFO:name:epoch 10 step 7500 loss 0.00738
INFO:name:epoch 10 step 7600 loss 0.00783
INFO:name:epoch 10 step 7700 loss 0.0084
INFO:name:epoch 10 step 7800 loss 0.01052
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4221
INFO:name:epoch 11 step 100 loss 0.00816
INFO:name:epoch 11 step 200 loss 0.00825
INFO:name:epoch 11 step 300 loss 0.01062
INFO:name:epoch 11 step 400 loss 0.00699
INFO:name:epoch 11 step 500 loss 0.00752
INFO:name:epoch 11 step 600 loss 0.00673
INFO:name:epoch 11 step 700 loss 0.00904
INFO:name:epoch 11 step 800 loss 0.00685
INFO:name:epoch 11 step 900 loss 0.00705
INFO:name:epoch 11 step 1000 loss 0.00958
INFO:name:epoch 11 step 1100 loss 0.00824
INFO:name:epoch 11 step 1200 loss 0.00814
INFO:name:epoch 11 step 1300 loss 0.0075
INFO:name:epoch 11 step 1400 loss 0.00926
INFO:name:epoch 11 step 1500 loss 0.00803
INFO:name:epoch 11 step 1600 loss 0.00969
INFO:name:epoch 11 step 1700 loss 0.00771
INFO:name:epoch 11 step 1800 loss 0.00729
INFO:name:epoch 11 step 1900 loss 0.00871
INFO:name:epoch 11 step 2000 loss 0.00735
INFO:name:epoch 11 step 2100 loss 0.00701
INFO:name:epoch 11 step 2200 loss 0.0098
INFO:name:epoch 11 step 2300 loss 0.00732
INFO:name:epoch 11 step 2400 loss 0.00601
INFO:name:epoch 11 step 2500 loss 0.01011
INFO:name:epoch 11 step 2600 loss 0.00678
INFO:name:epoch 11 step 2700 loss 0.00945
INFO:name:epoch 11 step 2800 loss 0.00795
INFO:name:epoch 11 step 2900 loss 0.00691
INFO:name:epoch 11 step 3000 loss 0.00773
INFO:name:epoch 11 step 3100 loss 0.01039
INFO:name:epoch 11 step 3200 loss 0.01009
INFO:name:epoch 11 step 3300 loss 0.00974
INFO:name:epoch 11 step 3400 loss 0.00961
INFO:name:epoch 11 step 3500 loss 0.00986
INFO:name:epoch 11 step 3600 loss 0.00985
INFO:name:epoch 11 step 3700 loss 0.00729
INFO:name:epoch 11 step 3800 loss 0.00942
INFO:name:epoch 11 step 3900 loss 0.00964
INFO:name:epoch 11 step 4000 loss 0.00658
INFO:name:epoch 11 step 4100 loss 0.00689
INFO:name:epoch 11 step 4200 loss 0.01023
INFO:name:epoch 11 step 4300 loss 0.00978
INFO:name:epoch 11 step 4400 loss 0.00827
INFO:name:epoch 11 step 4500 loss 0.00851
INFO:name:epoch 11 step 4600 loss 0.0099
INFO:name:epoch 11 step 4700 loss 0.0105
INFO:name:epoch 11 step 4800 loss 0.01071
INFO:name:epoch 11 step 4900 loss 0.01039
INFO:name:epoch 11 step 5000 loss 0.00967
INFO:name:epoch 11 step 5100 loss 0.00757
INFO:name:epoch 11 step 5200 loss 0.00593
INFO:name:epoch 11 step 5300 loss 0.00856
INFO:name:epoch 11 step 5400 loss 0.00685
INFO:name:epoch 11 step 5500 loss 0.00778
INFO:name:epoch 11 step 5600 loss 0.00667
INFO:name:epoch 11 step 5700 loss 0.00707
INFO:name:epoch 11 step 5800 loss 0.00934
INFO:name:epoch 11 step 5900 loss 0.00861
INFO:name:epoch 11 step 6000 loss 0.01004
INFO:name:epoch 11 step 6100 loss 0.01013
INFO:name:epoch 11 step 6200 loss 0.0084
INFO:name:epoch 11 step 6300 loss 0.00774
INFO:name:epoch 11 step 6400 loss 0.00764
INFO:name:epoch 11 step 6500 loss 0.00748
INFO:name:epoch 11 step 6600 loss 0.00805
INFO:name:epoch 11 step 6700 loss 0.00704
INFO:name:epoch 11 step 6800 loss 0.00899
INFO:name:epoch 11 step 6900 loss 0.00947
INFO:name:epoch 11 step 7000 loss 0.0104
INFO:name:epoch 11 step 7100 loss 0.00876
INFO:name:epoch 11 step 7200 loss 0.0076
INFO:name:epoch 11 step 7300 loss 0.00704
INFO:name:epoch 11 step 7400 loss 0.00896
INFO:name:epoch 11 step 7500 loss 0.0087
INFO:name:epoch 11 step 7600 loss 0.00696
INFO:name:epoch 11 step 7700 loss 0.00936
INFO:name:epoch 11 step 7800 loss 0.00776
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4124
INFO:name:epoch 12 step 100 loss 0.00732
INFO:name:epoch 12 step 200 loss 0.00691
INFO:name:epoch 12 step 300 loss 0.00585
INFO:name:epoch 12 step 400 loss 0.007
INFO:name:epoch 12 step 500 loss 0.00731
INFO:name:epoch 12 step 600 loss 0.00537
INFO:name:epoch 12 step 700 loss 0.01057
INFO:name:epoch 12 step 800 loss 0.00773
INFO:name:epoch 12 step 900 loss 0.00615
INFO:name:epoch 12 step 1000 loss 0.00617
INFO:name:epoch 12 step 1100 loss 0.008
INFO:name:epoch 12 step 1200 loss 0.00634
INFO:name:epoch 12 step 1300 loss 0.00764
INFO:name:epoch 12 step 1400 loss 0.00711
INFO:name:epoch 12 step 1500 loss 0.00764
INFO:name:epoch 12 step 1600 loss 0.00705
INFO:name:epoch 12 step 1700 loss 0.00774
INFO:name:epoch 12 step 1800 loss 0.00608
INFO:name:epoch 12 step 1900 loss 0.00915
INFO:name:epoch 12 step 2000 loss 0.00763
INFO:name:epoch 12 step 2100 loss 0.0073
INFO:name:epoch 12 step 2200 loss 0.00651
INFO:name:epoch 12 step 2300 loss 0.00887
INFO:name:epoch 12 step 2400 loss 0.00632
INFO:name:epoch 12 step 2500 loss 0.00784
INFO:name:epoch 12 step 2600 loss 0.00832
INFO:name:epoch 12 step 2700 loss 0.00778
INFO:name:epoch 12 step 2800 loss 0.00798
INFO:name:epoch 12 step 2900 loss 0.00955
INFO:name:epoch 12 step 3000 loss 0.00791
INFO:name:epoch 12 step 3100 loss 0.00779
INFO:name:epoch 12 step 3200 loss 0.00766
INFO:name:epoch 12 step 3300 loss 0.00773
INFO:name:epoch 12 step 3400 loss 0.00927
INFO:name:epoch 12 step 3500 loss 0.0088
INFO:name:epoch 12 step 3600 loss 0.00834
INFO:name:epoch 12 step 3700 loss 0.00528
INFO:name:epoch 12 step 3800 loss 0.00703
INFO:name:epoch 12 step 3900 loss 0.00745
INFO:name:epoch 12 step 4000 loss 0.00795
INFO:name:epoch 12 step 4100 loss 0.00654
INFO:name:epoch 12 step 4200 loss 0.00682
INFO:name:epoch 12 step 4300 loss 0.0073
INFO:name:epoch 12 step 4400 loss 0.00826
INFO:name:epoch 12 step 4500 loss 0.0068
INFO:name:epoch 12 step 4600 loss 0.00625
INFO:name:epoch 12 step 4700 loss 0.00794
INFO:name:epoch 12 step 4800 loss 0.00818
INFO:name:epoch 12 step 4900 loss 0.01055
INFO:name:epoch 12 step 5000 loss 0.00896
INFO:name:epoch 12 step 5100 loss 0.00916
INFO:name:epoch 12 step 5200 loss 0.0081
INFO:name:epoch 12 step 5300 loss 0.0067
INFO:name:epoch 12 step 5400 loss 0.00821
INFO:name:epoch 12 step 5500 loss 0.00769
INFO:name:epoch 12 step 5600 loss 0.0083
INFO:name:epoch 12 step 5700 loss 0.00807
INFO:name:epoch 12 step 5800 loss 0.00612
INFO:name:epoch 12 step 5900 loss 0.00618
INFO:name:epoch 12 step 6000 loss 0.00856
INFO:name:epoch 12 step 6100 loss 0.00666
INFO:name:epoch 12 step 6200 loss 0.00766
INFO:name:epoch 12 step 6300 loss 0.00632
INFO:name:epoch 12 step 6400 loss 0.0081
INFO:name:epoch 12 step 6500 loss 0.00615
INFO:name:epoch 12 step 6600 loss 0.01314
INFO:name:epoch 12 step 6700 loss 0.00733
INFO:name:epoch 12 step 6800 loss 0.0079
INFO:name:epoch 12 step 6900 loss 0.0067
INFO:name:epoch 12 step 7000 loss 0.00748
INFO:name:epoch 12 step 7100 loss 0.00853
INFO:name:epoch 12 step 7200 loss 0.0077
INFO:name:epoch 12 step 7300 loss 0.01006
INFO:name:epoch 12 step 7400 loss 0.00636
INFO:name:epoch 12 step 7500 loss 0.00731
INFO:name:epoch 12 step 7600 loss 0.00871
INFO:name:epoch 12 step 7700 loss 0.00712
INFO:name:epoch 12 step 7800 loss 0.0073
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4093
INFO:name:epoch 13 step 100 loss 0.00639
INFO:name:epoch 13 step 200 loss 0.00711
INFO:name:epoch 13 step 300 loss 0.00675
INFO:name:epoch 13 step 400 loss 0.00782
INFO:name:epoch 13 step 500 loss 0.00742
INFO:name:epoch 13 step 600 loss 0.007
INFO:name:epoch 13 step 700 loss 0.00934
INFO:name:epoch 13 step 800 loss 0.00727
INFO:name:epoch 13 step 900 loss 0.00739
INFO:name:epoch 13 step 1000 loss 0.01191
INFO:name:epoch 13 step 1100 loss 0.00852
INFO:name:epoch 13 step 1200 loss 0.0062
INFO:name:epoch 13 step 1300 loss 0.00754
INFO:name:epoch 13 step 1400 loss 0.00627
INFO:name:epoch 13 step 1500 loss 0.00562
INFO:name:epoch 13 step 1600 loss 0.00773
INFO:name:epoch 13 step 1700 loss 0.00738
INFO:name:epoch 13 step 1800 loss 0.00851
INFO:name:epoch 13 step 1900 loss 0.00797
INFO:name:epoch 13 step 2000 loss 0.00672
INFO:name:epoch 13 step 2100 loss 0.00807
INFO:name:epoch 13 step 2200 loss 0.00679
INFO:name:epoch 13 step 2300 loss 0.00874
INFO:name:epoch 13 step 2400 loss 0.00684
INFO:name:epoch 13 step 2500 loss 0.00789
INFO:name:epoch 13 step 2600 loss 0.00653
INFO:name:epoch 13 step 2700 loss 0.00729
INFO:name:epoch 13 step 2800 loss 0.00689
INFO:name:epoch 13 step 2900 loss 0.00908
INFO:name:epoch 13 step 3000 loss 0.00812
INFO:name:epoch 13 step 3100 loss 0.00565
INFO:name:epoch 13 step 3200 loss 0.00951
INFO:name:epoch 13 step 3300 loss 0.0074
INFO:name:epoch 13 step 3400 loss 0.00955
INFO:name:epoch 13 step 3500 loss 0.00969
INFO:name:epoch 13 step 3600 loss 0.00818
INFO:name:epoch 13 step 3700 loss 0.0068
INFO:name:epoch 13 step 3800 loss 0.0061
INFO:name:epoch 13 step 3900 loss 0.00565
INFO:name:epoch 13 step 4000 loss 0.0068
INFO:name:epoch 13 step 4100 loss 0.00707
INFO:name:epoch 13 step 4200 loss 0.00853
INFO:name:epoch 13 step 4300 loss 0.00786
INFO:name:epoch 13 step 4400 loss 0.00562
INFO:name:epoch 13 step 4500 loss 0.01024
INFO:name:epoch 13 step 4600 loss 0.0075
INFO:name:epoch 13 step 4700 loss 0.00817
INFO:name:epoch 13 step 4800 loss 0.00696
INFO:name:epoch 13 step 4900 loss 0.00539
INFO:name:epoch 13 step 5000 loss 0.00955
INFO:name:epoch 13 step 5100 loss 0.00626
INFO:name:epoch 13 step 5200 loss 0.00708
INFO:name:epoch 13 step 5300 loss 0.00651
INFO:name:epoch 13 step 5400 loss 0.00789
INFO:name:epoch 13 step 5500 loss 0.00887
INFO:name:epoch 13 step 5600 loss 0.00743
INFO:name:epoch 13 step 5700 loss 0.00748
INFO:name:epoch 13 step 5800 loss 0.00787
INFO:name:epoch 13 step 5900 loss 0.00592
INFO:name:epoch 13 step 6000 loss 0.00606
INFO:name:epoch 13 step 6100 loss 0.00736
INFO:name:epoch 13 step 6200 loss 0.00713
INFO:name:epoch 13 step 6300 loss 0.00691
INFO:name:epoch 13 step 6400 loss 0.005
INFO:name:epoch 13 step 6500 loss 0.00819
INFO:name:epoch 13 step 6600 loss 0.00674
INFO:name:epoch 13 step 6700 loss 0.00944
INFO:name:epoch 13 step 6800 loss 0.00755
INFO:name:epoch 13 step 6900 loss 0.01272
INFO:name:epoch 13 step 7000 loss 0.00762
INFO:name:epoch 13 step 7100 loss 0.00646
INFO:name:epoch 13 step 7200 loss 0.00591
INFO:name:epoch 13 step 7300 loss 0.00814
INFO:name:epoch 13 step 7400 loss 0.00752
INFO:name:epoch 13 step 7500 loss 0.0095
INFO:name:epoch 13 step 7600 loss 0.00631
INFO:name:epoch 13 step 7700 loss 0.00822
INFO:name:epoch 13 step 7800 loss 0.00782
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.411
INFO:name:epoch 14 step 100 loss 0.00674
INFO:name:epoch 14 step 200 loss 0.00693
INFO:name:epoch 14 step 300 loss 0.00799
INFO:name:epoch 14 step 400 loss 0.00717
INFO:name:epoch 14 step 500 loss 0.00761
INFO:name:epoch 14 step 600 loss 0.0078
INFO:name:epoch 14 step 700 loss 0.00824
INFO:name:epoch 14 step 800 loss 0.00592
INFO:name:epoch 14 step 900 loss 0.00839
INFO:name:epoch 14 step 1000 loss 0.00698
INFO:name:epoch 14 step 1100 loss 0.00818
INFO:name:epoch 14 step 1200 loss 0.00693
INFO:name:epoch 14 step 1300 loss 0.00635
INFO:name:epoch 14 step 1400 loss 0.00674
INFO:name:epoch 14 step 1500 loss 0.00569
INFO:name:epoch 14 step 1600 loss 0.00616
INFO:name:epoch 14 step 1700 loss 0.00725
INFO:name:epoch 14 step 1800 loss 0.0066
INFO:name:epoch 14 step 1900 loss 0.00629
INFO:name:epoch 14 step 2000 loss 0.00833
INFO:name:epoch 14 step 2100 loss 0.00647
INFO:name:epoch 14 step 2200 loss 0.00667
INFO:name:epoch 14 step 2300 loss 0.00548
INFO:name:epoch 14 step 2400 loss 0.00776
INFO:name:epoch 14 step 2500 loss 0.00692
INFO:name:epoch 14 step 2600 loss 0.00783
INFO:name:epoch 14 step 2700 loss 0.00654
INFO:name:epoch 14 step 2800 loss 0.00716
INFO:name:epoch 14 step 2900 loss 0.00636
INFO:name:epoch 14 step 3000 loss 0.00626
INFO:name:epoch 14 step 3100 loss 0.007
INFO:name:epoch 14 step 3200 loss 0.00726
INFO:name:epoch 14 step 3300 loss 0.00783
INFO:name:epoch 14 step 3400 loss 0.00625
INFO:name:epoch 14 step 3500 loss 0.00867
INFO:name:epoch 14 step 3600 loss 0.0072
INFO:name:epoch 14 step 3700 loss 0.0072
INFO:name:epoch 14 step 3800 loss 0.00652
INFO:name:epoch 14 step 3900 loss 0.00685
INFO:name:epoch 14 step 4000 loss 0.00689
INFO:name:epoch 14 step 4100 loss 0.00768
INFO:name:epoch 14 step 4200 loss 0.00714
INFO:name:epoch 14 step 4300 loss 0.00963
INFO:name:epoch 14 step 4400 loss 0.00854
INFO:name:epoch 14 step 4500 loss 0.00564
INFO:name:epoch 14 step 4600 loss 0.00633
INFO:name:epoch 14 step 4700 loss 0.0059
INFO:name:epoch 14 step 4800 loss 0.00732
INFO:name:epoch 14 step 4900 loss 0.00667
INFO:name:epoch 14 step 5000 loss 0.0056
INFO:name:epoch 14 step 5100 loss 0.00693
INFO:name:epoch 14 step 5200 loss 0.00625
INFO:name:epoch 14 step 5300 loss 0.00657
INFO:name:epoch 14 step 5400 loss 0.00608
INFO:name:epoch 14 step 5500 loss 0.00593
INFO:name:epoch 14 step 5600 loss 0.00637
INFO:name:epoch 14 step 5700 loss 0.00686
INFO:name:epoch 14 step 5800 loss 0.00574
INFO:name:epoch 14 step 5900 loss 0.00654
INFO:name:epoch 14 step 6000 loss 0.00729
INFO:name:epoch 14 step 6100 loss 0.0055
INFO:name:epoch 14 step 6200 loss 0.00576
INFO:name:epoch 14 step 6300 loss 0.00924
INFO:name:epoch 14 step 6400 loss 0.00541
INFO:name:epoch 14 step 6500 loss 0.00593
INFO:name:epoch 14 step 6600 loss 0.00799
INFO:name:epoch 14 step 6700 loss 0.00647
INFO:name:epoch 14 step 6800 loss 0.00565
INFO:name:epoch 14 step 6900 loss 0.00805
INFO:name:epoch 14 step 7000 loss 0.00517
INFO:name:epoch 14 step 7100 loss 0.00496
INFO:name:epoch 14 step 7200 loss 0.00572
INFO:name:epoch 14 step 7300 loss 0.00775
INFO:name:epoch 14 step 7400 loss 0.00558
INFO:name:epoch 14 step 7500 loss 0.00572
INFO:name:epoch 14 step 7600 loss 0.0079
INFO:name:epoch 14 step 7700 loss 0.00656
INFO:name:epoch 14 step 7800 loss 0.00563
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4099
INFO:name:Saving model checkpoint to ./models/final_model_codeSearch/model.bin
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:[{'insert_modules': ('attention.output', 'attention.self'), 'bottleneck_dim': (32, 32), 'non_linearity': 'relu', 'dropout_rate': 0.1, 'normalization': 'layer_norm', 'skip_connection': True}, 0, {'insert_modules': ('attention.self',), 'bottleneck_dim': (16,), 'non_linearity': 'silu', 'dropout_rate': 0.3, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.output', 'output', 'attention.self'), 'bottleneck_dim': (32, 256, 32), 'non_linearity': 'gelu_new', 'dropout_rate': 0.25, 'normalization': 'layer_norm', 'skip_connection': True}, {'insert_modules': ('output',), 'bottleneck_dim': (128,), 'non_linearity': 'leakyrelu', 'dropout_rate': 0.0, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.self',), 'bottleneck_dim': (32,), 'non_linearity': 'gelu_new', 'dropout_rate': 0.0, 'normalization': 'layer_norm', 'skip_connection': True}, 0, 0, 0, {'insert_modules': ('attention.output', 'intermediate'), 'bottleneck_dim': (32, 128), 'non_linearity': 'relu', 'dropout_rate': 0.3, 'normalization': None, 'skip_connection': True}, {'insert_modules': ('attention.output', 'output', 'attention.self'), 'bottleneck_dim': (32, 256, 32), 'non_linearity': 'gelu_new', 'dropout_rate': 0.25, 'normalization': 'layer_norm', 'skip_connection': True}, 0]
[INFO|(OpenDelta)basemodel:700]2025-01-07 09:19:59,701 >> Trainable Ratio: 2202064/126847696=1.735991%
[INFO|(OpenDelta)basemodel:702]2025-01-07 09:19:59,701 >> Delta Parameter Ratio: 2202064/126847696=1.735991%
[INFO|(OpenDelta)basemodel:704]2025-01-07 09:19:59,701 >> Static Memory 0.49 GB, Max Memory 8.02 GB
INFO:name:2.52
/opt/miniconda3/envs/adapter/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:name:***** Running training *****
INFO:name:  Num examples = 251820
INFO:name:  Num Epochs = 15
INFO:name:  Instantaneous batch size per GPU = 32
INFO:name:  Total train batch size  = 32
INFO:name:  Total optimization steps = 118050
INFO:name:epoch 0 step 100 loss 0.4951
INFO:name:epoch 0 step 200 loss 0.18965
INFO:name:epoch 0 step 300 loss 0.16048
INFO:name:epoch 0 step 400 loss 0.15719
INFO:name:epoch 0 step 500 loss 0.15042
INFO:name:epoch 0 step 600 loss 0.13935
INFO:name:epoch 0 step 700 loss 0.13753
INFO:name:epoch 0 step 800 loss 0.13914
INFO:name:epoch 0 step 900 loss 0.12808
INFO:name:epoch 0 step 1000 loss 0.13799
INFO:name:epoch 0 step 1100 loss 0.12486
INFO:name:epoch 0 step 1200 loss 0.12554
INFO:name:epoch 0 step 1300 loss 0.11349
INFO:name:epoch 0 step 1400 loss 0.12073
INFO:name:epoch 0 step 1500 loss 0.12353
INFO:name:epoch 0 step 1600 loss 0.11261
INFO:name:epoch 0 step 1700 loss 0.10765
INFO:name:epoch 0 step 1800 loss 0.10404
INFO:name:epoch 0 step 1900 loss 0.1148
INFO:name:epoch 0 step 2000 loss 0.10704
INFO:name:epoch 0 step 2100 loss 0.1071
INFO:name:epoch 0 step 2200 loss 0.1071
INFO:name:epoch 0 step 2300 loss 0.1116
INFO:name:epoch 0 step 2400 loss 0.11739
INFO:name:epoch 0 step 2500 loss 0.10589
INFO:name:epoch 0 step 2600 loss 0.1206
INFO:name:epoch 0 step 2700 loss 0.09646
INFO:name:epoch 0 step 2800 loss 0.10009
INFO:name:epoch 0 step 2900 loss 0.10906
INFO:name:epoch 0 step 3000 loss 0.10038
INFO:name:epoch 0 step 3100 loss 0.11308
INFO:name:epoch 0 step 3200 loss 0.09559
INFO:name:epoch 0 step 3300 loss 0.09875
INFO:name:epoch 0 step 3400 loss 0.11302
INFO:name:epoch 0 step 3500 loss 0.09296
INFO:name:epoch 0 step 3600 loss 0.10046
INFO:name:epoch 0 step 3700 loss 0.09953
INFO:name:epoch 0 step 3800 loss 0.09301
INFO:name:epoch 0 step 3900 loss 0.10743
INFO:name:epoch 0 step 4000 loss 0.09621
INFO:name:epoch 0 step 4100 loss 0.09763
INFO:name:epoch 0 step 4200 loss 0.09022
INFO:name:epoch 0 step 4300 loss 0.09274
INFO:name:epoch 0 step 4400 loss 0.10704
INFO:name:epoch 0 step 4500 loss 0.0975
INFO:name:epoch 0 step 4600 loss 0.08182
INFO:name:epoch 0 step 4700 loss 0.10325
INFO:name:epoch 0 step 4800 loss 0.08509
INFO:name:epoch 0 step 4900 loss 0.08218
INFO:name:epoch 0 step 5000 loss 0.08997
INFO:name:epoch 0 step 5100 loss 0.08047
INFO:name:epoch 0 step 5200 loss 0.07313
INFO:name:epoch 0 step 5300 loss 0.08821
INFO:name:epoch 0 step 5400 loss 0.09719
INFO:name:epoch 0 step 5500 loss 0.10426
INFO:name:epoch 0 step 5600 loss 0.10179
INFO:name:epoch 0 step 5700 loss 0.10991
INFO:name:epoch 0 step 5800 loss 0.08689
INFO:name:epoch 0 step 5900 loss 0.08786
INFO:name:epoch 0 step 6000 loss 0.09959
INFO:name:epoch 0 step 6100 loss 0.07862
INFO:name:epoch 0 step 6200 loss 0.07951
INFO:name:epoch 0 step 6300 loss 0.08
INFO:name:epoch 0 step 6400 loss 0.08126
INFO:name:epoch 0 step 6500 loss 0.09883
INFO:name:epoch 0 step 6600 loss 0.08491
INFO:name:epoch 0 step 6700 loss 0.0898
INFO:name:epoch 0 step 6800 loss 0.08243
INFO:name:epoch 0 step 6900 loss 0.08828
INFO:name:epoch 0 step 7000 loss 0.07873
INFO:name:epoch 0 step 7100 loss 0.0798
INFO:name:epoch 0 step 7200 loss 0.07506
INFO:name:epoch 0 step 7300 loss 0.07504
INFO:name:epoch 0 step 7400 loss 0.07929
INFO:name:epoch 0 step 7500 loss 0.07765
INFO:name:epoch 0 step 7600 loss 0.07024
INFO:name:epoch 0 step 7700 loss 0.0883
INFO:name:epoch 0 step 7800 loss 0.08258
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.393
INFO:name:  ********************
INFO:name:  Best eval mrr:0.393
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3306
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 1 step 100 loss 0.06306
INFO:name:epoch 1 step 200 loss 0.05217
INFO:name:epoch 1 step 300 loss 0.04372
INFO:name:epoch 1 step 400 loss 0.04274
INFO:name:epoch 1 step 500 loss 0.04475
INFO:name:epoch 1 step 600 loss 0.06164
INFO:name:epoch 1 step 700 loss 0.05139
INFO:name:epoch 1 step 800 loss 0.05308
INFO:name:epoch 1 step 900 loss 0.04724
INFO:name:epoch 1 step 1000 loss 0.04221
INFO:name:epoch 1 step 1100 loss 0.04685
INFO:name:epoch 1 step 1200 loss 0.04503
INFO:name:epoch 1 step 1300 loss 0.05186
INFO:name:epoch 1 step 1400 loss 0.05728
INFO:name:epoch 1 step 1500 loss 0.06418
INFO:name:epoch 1 step 1600 loss 0.04164
INFO:name:epoch 1 step 1700 loss 0.04858
INFO:name:epoch 1 step 1800 loss 0.04383
INFO:name:epoch 1 step 1900 loss 0.05445
INFO:name:epoch 1 step 2000 loss 0.05079
INFO:name:epoch 1 step 2100 loss 0.05708
INFO:name:epoch 1 step 2200 loss 0.04383
INFO:name:epoch 1 step 2300 loss 0.05497
INFO:name:epoch 1 step 2400 loss 0.04572
INFO:name:epoch 1 step 2500 loss 0.04387
INFO:name:epoch 1 step 2600 loss 0.06032
INFO:name:epoch 1 step 2700 loss 0.04845
INFO:name:epoch 1 step 2800 loss 0.05146
INFO:name:epoch 1 step 2900 loss 0.06973
INFO:name:epoch 1 step 3000 loss 0.0509
INFO:name:epoch 1 step 3100 loss 0.05351
INFO:name:epoch 1 step 3200 loss 0.05725
INFO:name:epoch 1 step 3300 loss 0.05353
INFO:name:epoch 1 step 3400 loss 0.04347
INFO:name:epoch 1 step 3500 loss 0.04798
INFO:name:epoch 1 step 3600 loss 0.04461
INFO:name:epoch 1 step 3700 loss 0.04974
INFO:name:epoch 1 step 3800 loss 0.05102
INFO:name:epoch 1 step 3900 loss 0.05188
INFO:name:epoch 1 step 4000 loss 0.05505
INFO:name:epoch 1 step 4100 loss 0.05176
INFO:name:epoch 1 step 4200 loss 0.05093
INFO:name:epoch 1 step 4300 loss 0.05347
INFO:name:epoch 1 step 4400 loss 0.04875
INFO:name:epoch 1 step 4500 loss 0.04492
INFO:name:epoch 1 step 4600 loss 0.06455
INFO:name:epoch 1 step 4700 loss 0.0456
INFO:name:epoch 1 step 4800 loss 0.05035
INFO:name:epoch 1 step 4900 loss 0.05968
INFO:name:epoch 1 step 5000 loss 0.05289
INFO:name:epoch 1 step 5100 loss 0.04592
INFO:name:epoch 1 step 5200 loss 0.04661
INFO:name:epoch 1 step 5300 loss 0.04106
INFO:name:epoch 1 step 5400 loss 0.05814
INFO:name:epoch 1 step 5500 loss 0.05454
INFO:name:epoch 1 step 5600 loss 0.05416
INFO:name:epoch 1 step 5700 loss 0.0438
INFO:name:epoch 1 step 5800 loss 0.05044
INFO:name:epoch 1 step 5900 loss 0.04542
INFO:name:epoch 1 step 6000 loss 0.05468
INFO:name:epoch 1 step 6100 loss 0.04209
INFO:name:epoch 1 step 6200 loss 0.04483
INFO:name:epoch 1 step 6300 loss 0.04416
INFO:name:epoch 1 step 6400 loss 0.04589
INFO:name:epoch 1 step 6500 loss 0.05779
INFO:name:epoch 1 step 6600 loss 0.04118
INFO:name:epoch 1 step 6700 loss 0.05281
INFO:name:epoch 1 step 6800 loss 0.05136
INFO:name:epoch 1 step 6900 loss 0.05571
INFO:name:epoch 1 step 7000 loss 0.04537
INFO:name:epoch 1 step 7100 loss 0.04994
INFO:name:epoch 1 step 7200 loss 0.04263
INFO:name:epoch 1 step 7300 loss 0.04794
INFO:name:epoch 1 step 7400 loss 0.03958
INFO:name:epoch 1 step 7500 loss 0.0457
INFO:name:epoch 1 step 7600 loss 0.0429
INFO:name:epoch 1 step 7700 loss 0.05814
INFO:name:epoch 1 step 7800 loss 0.0457
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4275
INFO:name:  ********************
INFO:name:  Best eval mrr:0.4275
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3601
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 2 step 100 loss 0.03814
INFO:name:epoch 2 step 200 loss 0.03246
INFO:name:epoch 2 step 300 loss 0.02973
INFO:name:epoch 2 step 400 loss 0.0341
INFO:name:epoch 2 step 500 loss 0.03218
INFO:name:epoch 2 step 600 loss 0.03215
INFO:name:epoch 2 step 700 loss 0.0323
INFO:name:epoch 2 step 800 loss 0.03277
INFO:name:epoch 2 step 900 loss 0.04126
INFO:name:epoch 2 step 1000 loss 0.0251
INFO:name:epoch 2 step 1100 loss 0.03248
INFO:name:epoch 2 step 1200 loss 0.03371
INFO:name:epoch 2 step 1300 loss 0.03579
INFO:name:epoch 2 step 1400 loss 0.04203
INFO:name:epoch 2 step 1500 loss 0.03734
INFO:name:epoch 2 step 1600 loss 0.04216
INFO:name:epoch 2 step 1700 loss 0.04645
INFO:name:epoch 2 step 1800 loss 0.03305
INFO:name:epoch 2 step 1900 loss 0.03239
INFO:name:epoch 2 step 2000 loss 0.04656
INFO:name:epoch 2 step 2100 loss 0.04142
INFO:name:epoch 2 step 2200 loss 0.04009
INFO:name:epoch 2 step 2300 loss 0.03991
INFO:name:epoch 2 step 2400 loss 0.02933
INFO:name:epoch 2 step 2500 loss 0.03378
INFO:name:epoch 2 step 2600 loss 0.03385
INFO:name:epoch 2 step 2700 loss 0.03405
INFO:name:epoch 2 step 2800 loss 0.0406
INFO:name:epoch 2 step 2900 loss 0.03331
INFO:name:epoch 2 step 3000 loss 0.03308
INFO:name:epoch 2 step 3100 loss 0.0379
INFO:name:epoch 2 step 3200 loss 0.02809
INFO:name:epoch 2 step 3300 loss 0.03067
INFO:name:epoch 2 step 3400 loss 0.04815
INFO:name:epoch 2 step 3500 loss 0.03828
INFO:name:epoch 2 step 3600 loss 0.04458
INFO:name:epoch 2 step 3700 loss 0.03581
INFO:name:epoch 2 step 3800 loss 0.03648
INFO:name:epoch 2 step 3900 loss 0.03345
INFO:name:epoch 2 step 4000 loss 0.04031
INFO:name:epoch 2 step 4100 loss 0.03372
INFO:name:epoch 2 step 4200 loss 0.02993
INFO:name:epoch 2 step 4300 loss 0.03637
INFO:name:epoch 2 step 4400 loss 0.03891
INFO:name:epoch 2 step 4500 loss 0.04376
INFO:name:epoch 2 step 4600 loss 0.03021
INFO:name:epoch 2 step 4700 loss 0.03145
INFO:name:epoch 2 step 4800 loss 0.03845
INFO:name:epoch 2 step 4900 loss 0.04395
INFO:name:epoch 2 step 5000 loss 0.04379
INFO:name:epoch 2 step 5100 loss 0.04228
INFO:name:epoch 2 step 5200 loss 0.03807
INFO:name:epoch 2 step 5300 loss 0.04629
INFO:name:epoch 2 step 5400 loss 0.03336
INFO:name:epoch 2 step 5500 loss 0.04568
INFO:name:epoch 2 step 5600 loss 0.03444
INFO:name:epoch 2 step 5700 loss 0.03304
INFO:name:epoch 2 step 5800 loss 0.0405
INFO:name:epoch 2 step 5900 loss 0.04394
INFO:name:epoch 2 step 6000 loss 0.04254
INFO:name:epoch 2 step 6100 loss 0.04182
INFO:name:epoch 2 step 6200 loss 0.03249
INFO:name:epoch 2 step 6300 loss 0.03536
INFO:name:epoch 2 step 6400 loss 0.04338
INFO:name:epoch 2 step 6500 loss 0.04482
INFO:name:epoch 2 step 6600 loss 0.04174
INFO:name:epoch 2 step 6700 loss 0.03984
INFO:name:epoch 2 step 6800 loss 0.03705
INFO:name:epoch 2 step 6900 loss 0.02769
INFO:name:epoch 2 step 7000 loss 0.04649
INFO:name:epoch 2 step 7100 loss 0.0394
INFO:name:epoch 2 step 7200 loss 0.04096
INFO:name:epoch 2 step 7300 loss 0.02756
INFO:name:epoch 2 step 7400 loss 0.03536
INFO:name:epoch 2 step 7500 loss 0.03427
INFO:name:epoch 2 step 7600 loss 0.03266
INFO:name:epoch 2 step 7700 loss 0.04414
INFO:name:epoch 2 step 7800 loss 0.03694
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4222
INFO:name:epoch 3 step 100 loss 0.03075
INFO:name:epoch 3 step 200 loss 0.02028
INFO:name:epoch 3 step 300 loss 0.02138
INFO:name:epoch 3 step 400 loss 0.02516
INFO:name:epoch 3 step 500 loss 0.02568
INFO:name:epoch 3 step 600 loss 0.02851
INFO:name:epoch 3 step 700 loss 0.02855
INFO:name:epoch 3 step 800 loss 0.02702
INFO:name:epoch 3 step 900 loss 0.02706
INFO:name:epoch 3 step 1000 loss 0.02307
INFO:name:epoch 3 step 1100 loss 0.02454
INFO:name:epoch 3 step 1200 loss 0.02538
INFO:name:epoch 3 step 1300 loss 0.02975
INFO:name:epoch 3 step 1400 loss 0.02787
INFO:name:epoch 3 step 1500 loss 0.02776
INFO:name:epoch 3 step 1600 loss 0.02579
INFO:name:epoch 3 step 1700 loss 0.02608
INFO:name:epoch 3 step 1800 loss 0.02327
INFO:name:epoch 3 step 1900 loss 0.03193
INFO:name:epoch 3 step 2000 loss 0.03191
INFO:name:epoch 3 step 2100 loss 0.03438
INFO:name:epoch 3 step 2200 loss 0.03221
INFO:name:epoch 3 step 2300 loss 0.02461
INFO:name:epoch 3 step 2400 loss 0.02698
INFO:name:epoch 3 step 2500 loss 0.02371
INFO:name:epoch 3 step 2600 loss 0.02441
INFO:name:epoch 3 step 2700 loss 0.02684
INFO:name:epoch 3 step 2800 loss 0.0236
INFO:name:epoch 3 step 2900 loss 0.02277
INFO:name:epoch 3 step 3000 loss 0.03
INFO:name:epoch 3 step 3100 loss 0.03094
INFO:name:epoch 3 step 3200 loss 0.02592
INFO:name:epoch 3 step 3300 loss 0.02958
INFO:name:epoch 3 step 3400 loss 0.0287
INFO:name:epoch 3 step 3500 loss 0.03414
INFO:name:epoch 3 step 3600 loss 0.02904
INFO:name:epoch 3 step 3700 loss 0.0224
INFO:name:epoch 3 step 3800 loss 0.02898
INFO:name:epoch 3 step 3900 loss 0.02337
INFO:name:epoch 3 step 4000 loss 0.03508
INFO:name:epoch 3 step 4100 loss 0.02372
INFO:name:epoch 3 step 4200 loss 0.02688
INFO:name:epoch 3 step 4300 loss 0.02575
INFO:name:epoch 3 step 4400 loss 0.02597
INFO:name:epoch 3 step 4500 loss 0.02424
INFO:name:epoch 3 step 4600 loss 0.02669
INFO:name:epoch 3 step 4700 loss 0.04035
INFO:name:epoch 3 step 4800 loss 0.02305
INFO:name:epoch 3 step 4900 loss 0.02571
INFO:name:epoch 3 step 5000 loss 0.03236
INFO:name:epoch 3 step 5100 loss 0.02433
INFO:name:epoch 3 step 5200 loss 0.03188
INFO:name:epoch 3 step 5300 loss 0.02705
INFO:name:epoch 3 step 5400 loss 0.02636
INFO:name:epoch 3 step 5500 loss 0.02183
INFO:name:epoch 3 step 5600 loss 0.02815
INFO:name:epoch 3 step 5700 loss 0.02385
INFO:name:epoch 3 step 5800 loss 0.02261
INFO:name:epoch 3 step 5900 loss 0.02462
INFO:name:epoch 3 step 6000 loss 0.02792
INFO:name:epoch 3 step 6100 loss 0.02921
INFO:name:epoch 3 step 6200 loss 0.02921
INFO:name:epoch 3 step 6300 loss 0.02733
INFO:name:epoch 3 step 6400 loss 0.02303
INFO:name:epoch 3 step 6500 loss 0.03088
INFO:name:epoch 3 step 6600 loss 0.02033
INFO:name:epoch 3 step 6700 loss 0.02494
INFO:name:epoch 3 step 6800 loss 0.02879
INFO:name:epoch 3 step 6900 loss 0.02734
INFO:name:epoch 3 step 7000 loss 0.02467
INFO:name:epoch 3 step 7100 loss 0.03181
INFO:name:epoch 3 step 7200 loss 0.02724
INFO:name:epoch 3 step 7300 loss 0.02454
INFO:name:epoch 3 step 7400 loss 0.0299
INFO:name:epoch 3 step 7500 loss 0.01999
INFO:name:epoch 3 step 7600 loss 0.02708
INFO:name:epoch 3 step 7700 loss 0.02422
INFO:name:epoch 3 step 7800 loss 0.03277
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3988
INFO:name:epoch 4 step 100 loss 0.02135
INFO:name:epoch 4 step 200 loss 0.01835
INFO:name:epoch 4 step 300 loss 0.01869
INFO:name:epoch 4 step 400 loss 0.01562
INFO:name:epoch 4 step 500 loss 0.02113
INFO:name:epoch 4 step 600 loss 0.02375
INFO:name:epoch 4 step 700 loss 0.01763
INFO:name:epoch 4 step 800 loss 0.02137
INFO:name:epoch 4 step 900 loss 0.01479
INFO:name:epoch 4 step 1000 loss 0.02075
INFO:name:epoch 4 step 1100 loss 0.01751
INFO:name:epoch 4 step 1200 loss 0.02172
INFO:name:epoch 4 step 1300 loss 0.01561
INFO:name:epoch 4 step 1400 loss 0.01831
INFO:name:epoch 4 step 1500 loss 0.02442
INFO:name:epoch 4 step 1600 loss 0.02578
INFO:name:epoch 4 step 1700 loss 0.02212
INFO:name:epoch 4 step 1800 loss 0.01955
INFO:name:epoch 4 step 1900 loss 0.0223
INFO:name:epoch 4 step 2000 loss 0.01965
INFO:name:epoch 4 step 2100 loss 0.02521
INFO:name:epoch 4 step 2200 loss 0.01941
INFO:name:epoch 4 step 2300 loss 0.01851
INFO:name:epoch 4 step 2400 loss 0.01959
INFO:name:epoch 4 step 2500 loss 0.0203
INFO:name:epoch 4 step 2600 loss 0.01946
INFO:name:epoch 4 step 2700 loss 0.02083
INFO:name:epoch 4 step 2800 loss 0.0214
INFO:name:epoch 4 step 2900 loss 0.02049
INFO:name:epoch 4 step 3000 loss 0.02308
INFO:name:epoch 4 step 3100 loss 0.01918
INFO:name:epoch 4 step 3200 loss 0.01869
INFO:name:epoch 4 step 3300 loss 0.01915
INFO:name:epoch 4 step 3400 loss 0.02133
INFO:name:epoch 4 step 3500 loss 0.02536
INFO:name:epoch 4 step 3600 loss 0.01728
INFO:name:epoch 4 step 3700 loss 0.01581
INFO:name:epoch 4 step 3800 loss 0.02317
INFO:name:epoch 4 step 3900 loss 0.01704
INFO:name:epoch 4 step 4000 loss 0.02034
INFO:name:epoch 4 step 4100 loss 0.01841
INFO:name:epoch 4 step 4200 loss 0.01725
INFO:name:epoch 4 step 4300 loss 0.02242
INFO:name:epoch 4 step 4400 loss 0.0187
INFO:name:epoch 4 step 4500 loss 0.02006
INFO:name:epoch 4 step 4600 loss 0.01951
INFO:name:epoch 4 step 4700 loss 0.02115
INFO:name:epoch 4 step 4800 loss 0.01451
INFO:name:epoch 4 step 4900 loss 0.02032
INFO:name:epoch 4 step 5000 loss 0.02234
INFO:name:epoch 4 step 5100 loss 0.02162
INFO:name:epoch 4 step 5200 loss 0.02564
INFO:name:epoch 4 step 5300 loss 0.02198
INFO:name:epoch 4 step 5400 loss 0.02127
INFO:name:epoch 4 step 5500 loss 0.02507
INFO:name:epoch 4 step 5600 loss 0.02132
INFO:name:epoch 4 step 5700 loss 0.01825
INFO:name:epoch 4 step 5800 loss 0.01931
INFO:name:epoch 4 step 5900 loss 0.021
INFO:name:epoch 4 step 6000 loss 0.02251
INFO:name:epoch 4 step 6100 loss 0.02768
INFO:name:epoch 4 step 6200 loss 0.02397
INFO:name:epoch 4 step 6300 loss 0.02019
INFO:name:epoch 4 step 6400 loss 0.02004
INFO:name:epoch 4 step 6500 loss 0.02402
INFO:name:epoch 4 step 6600 loss 0.02456
INFO:name:epoch 4 step 6700 loss 0.02292
INFO:name:epoch 4 step 6800 loss 0.01899
INFO:name:epoch 4 step 6900 loss 0.02068
INFO:name:epoch 4 step 7000 loss 0.02326
INFO:name:epoch 4 step 7100 loss 0.02205
INFO:name:epoch 4 step 7200 loss 0.02001
INFO:name:epoch 4 step 7300 loss 0.02556
INFO:name:epoch 4 step 7400 loss 0.01685
INFO:name:epoch 4 step 7500 loss 0.01885
INFO:name:epoch 4 step 7600 loss 0.02178
INFO:name:epoch 4 step 7700 loss 0.01944
INFO:name:epoch 4 step 7800 loss 0.02474
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4048
INFO:name:epoch 5 step 100 loss 0.01846
INFO:name:epoch 5 step 200 loss 0.01416
INFO:name:epoch 5 step 300 loss 0.01359
INFO:name:epoch 5 step 400 loss 0.01199
INFO:name:epoch 5 step 500 loss 0.01377
INFO:name:epoch 5 step 600 loss 0.01337
INFO:name:epoch 5 step 700 loss 0.01644
INFO:name:epoch 5 step 800 loss 0.01459
INFO:name:epoch 5 step 900 loss 0.01676
INFO:name:epoch 5 step 1000 loss 0.01535
INFO:name:epoch 5 step 1100 loss 0.01337
INFO:name:epoch 5 step 1200 loss 0.01406
INFO:name:epoch 5 step 1300 loss 0.01747
INFO:name:epoch 5 step 1400 loss 0.01447
INFO:name:epoch 5 step 1500 loss 0.01169
INFO:name:epoch 5 step 1600 loss 0.01835
INFO:name:epoch 5 step 1700 loss 0.01763
INFO:name:epoch 5 step 1800 loss 0.0179
INFO:name:epoch 5 step 1900 loss 0.01563
INFO:name:epoch 5 step 2000 loss 0.01927
INFO:name:epoch 5 step 2100 loss 0.01652
INFO:name:epoch 5 step 2200 loss 0.01461
INFO:name:epoch 5 step 2300 loss 0.02187
INFO:name:epoch 5 step 2400 loss 0.01804
INFO:name:epoch 5 step 2500 loss 0.01246
INFO:name:epoch 5 step 2600 loss 0.01775
INFO:name:epoch 5 step 2700 loss 0.01759
INFO:name:epoch 5 step 2800 loss 0.01665
INFO:name:epoch 5 step 2900 loss 0.01703
INFO:name:epoch 5 step 3000 loss 0.01374
INFO:name:epoch 5 step 3100 loss 0.01563
INFO:name:epoch 5 step 3200 loss 0.01399
INFO:name:epoch 5 step 3300 loss 0.01493
INFO:name:epoch 5 step 3400 loss 0.01879
INFO:name:epoch 5 step 3500 loss 0.02019
INFO:name:epoch 5 step 3600 loss 0.01685
INFO:name:epoch 5 step 3700 loss 0.01773
INFO:name:epoch 5 step 3800 loss 0.01739
INFO:name:epoch 5 step 3900 loss 0.01638
INFO:name:epoch 5 step 4000 loss 0.01412
INFO:name:epoch 5 step 4100 loss 0.01407
INFO:name:epoch 5 step 4200 loss 0.01895
INFO:name:epoch 5 step 4300 loss 0.01641
INFO:name:epoch 5 step 4400 loss 0.01381
INFO:name:epoch 5 step 4500 loss 0.01651
INFO:name:epoch 5 step 4600 loss 0.01752
INFO:name:epoch 5 step 4700 loss 0.01739
INFO:name:epoch 5 step 4800 loss 0.01485
INFO:name:epoch 5 step 4900 loss 0.01614
INFO:name:epoch 5 step 5000 loss 0.01502
INFO:name:epoch 5 step 5100 loss 0.02
INFO:name:epoch 5 step 5200 loss 0.01946
INFO:name:epoch 5 step 5300 loss 0.01794
INFO:name:epoch 5 step 5400 loss 0.01432
INFO:name:epoch 5 step 5500 loss 0.01525
INFO:name:epoch 5 step 5600 loss 0.01806
INFO:name:epoch 5 step 5700 loss 0.0139
INFO:name:epoch 5 step 5800 loss 0.01424
INFO:name:epoch 5 step 5900 loss 0.01478
INFO:name:epoch 5 step 6000 loss 0.01496
INFO:name:epoch 5 step 6100 loss 0.01426
INFO:name:epoch 5 step 6200 loss 0.01401
INFO:name:epoch 5 step 6300 loss 0.01671
INFO:name:epoch 5 step 6400 loss 0.01615
INFO:name:epoch 5 step 6500 loss 0.01644
INFO:name:epoch 5 step 6600 loss 0.02
INFO:name:epoch 5 step 6700 loss 0.01658
INFO:name:epoch 5 step 6800 loss 0.0182
INFO:name:epoch 5 step 6900 loss 0.01578
INFO:name:epoch 5 step 7000 loss 0.01956
INFO:name:epoch 5 step 7100 loss 0.01405
INFO:name:epoch 5 step 7200 loss 0.02049
INFO:name:epoch 5 step 7300 loss 0.01546
INFO:name:epoch 5 step 7400 loss 0.01499
INFO:name:epoch 5 step 7500 loss 0.01672
INFO:name:epoch 5 step 7600 loss 0.01942
INFO:name:epoch 5 step 7700 loss 0.01627
INFO:name:epoch 5 step 7800 loss 0.01948
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4191
INFO:name:epoch 6 step 100 loss 0.01308
INFO:name:epoch 6 step 200 loss 0.00988
INFO:name:epoch 6 step 300 loss 0.01294
INFO:name:epoch 6 step 400 loss 0.01127
INFO:name:epoch 6 step 500 loss 0.01531
INFO:name:epoch 6 step 600 loss 0.01409
INFO:name:epoch 6 step 700 loss 0.01044
INFO:name:epoch 6 step 800 loss 0.01223
INFO:name:epoch 6 step 900 loss 0.01427
INFO:name:epoch 6 step 1000 loss 0.01091
INFO:name:epoch 6 step 1100 loss 0.01497
INFO:name:epoch 6 step 1200 loss 0.01359
INFO:name:epoch 6 step 1300 loss 0.0128
INFO:name:epoch 6 step 1400 loss 0.01311
INFO:name:epoch 6 step 1500 loss 0.01244
INFO:name:epoch 6 step 1600 loss 0.01307
INFO:name:epoch 6 step 1700 loss 0.01218
INFO:name:epoch 6 step 1800 loss 0.01249
INFO:name:epoch 6 step 1900 loss 0.01178
INFO:name:epoch 6 step 2000 loss 0.01241
INFO:name:epoch 6 step 2100 loss 0.01373
INFO:name:epoch 6 step 2200 loss 0.01222
INFO:name:epoch 6 step 2300 loss 0.01387
INFO:name:epoch 6 step 2400 loss 0.01599
INFO:name:epoch 6 step 2500 loss 0.01514
INFO:name:epoch 6 step 2600 loss 0.01374
INFO:name:epoch 6 step 2700 loss 0.01824
INFO:name:epoch 6 step 2800 loss 0.01442
INFO:name:epoch 6 step 2900 loss 0.01375
INFO:name:epoch 6 step 3000 loss 0.01393
INFO:name:epoch 6 step 3100 loss 0.01291
INFO:name:epoch 6 step 3200 loss 0.01622
INFO:name:epoch 6 step 3300 loss 0.01239
INFO:name:epoch 6 step 3400 loss 0.01274
INFO:name:epoch 6 step 3500 loss 0.01421
INFO:name:epoch 6 step 3600 loss 0.01236
INFO:name:epoch 6 step 3700 loss 0.01236
INFO:name:epoch 6 step 3800 loss 0.01363
INFO:name:epoch 6 step 3900 loss 0.01468
INFO:name:epoch 6 step 4000 loss 0.01424
INFO:name:epoch 6 step 4100 loss 0.01175
INFO:name:epoch 6 step 4200 loss 0.01186
INFO:name:epoch 6 step 4300 loss 0.01618
INFO:name:epoch 6 step 4400 loss 0.01547
INFO:name:epoch 6 step 4500 loss 0.01326
INFO:name:epoch 6 step 4600 loss 0.01235
INFO:name:epoch 6 step 4700 loss 0.01154
INFO:name:epoch 6 step 4800 loss 0.01347
INFO:name:epoch 6 step 4900 loss 0.01274
INFO:name:epoch 6 step 5000 loss 0.01615
INFO:name:epoch 6 step 5100 loss 0.0171
INFO:name:epoch 6 step 5200 loss 0.01389
INFO:name:epoch 6 step 5300 loss 0.01209
INFO:name:epoch 6 step 5400 loss 0.01449
INFO:name:epoch 6 step 5500 loss 0.01535
INFO:name:epoch 6 step 5600 loss 0.01506
INFO:name:epoch 6 step 5700 loss 0.01494
INFO:name:epoch 6 step 5800 loss 0.01525
INFO:name:epoch 6 step 5900 loss 0.01088
INFO:name:epoch 6 step 6000 loss 0.01473
INFO:name:epoch 6 step 6100 loss 0.0119
INFO:name:epoch 6 step 6200 loss 0.01436
INFO:name:epoch 6 step 6300 loss 0.01462
INFO:name:epoch 6 step 6400 loss 0.0166
INFO:name:epoch 6 step 6500 loss 0.01288
INFO:name:epoch 6 step 6600 loss 0.01336
INFO:name:epoch 6 step 6700 loss 0.01317
INFO:name:epoch 6 step 6800 loss 0.0119
INFO:name:epoch 6 step 6900 loss 0.01191
INFO:name:epoch 6 step 7000 loss 0.01485
INFO:name:epoch 6 step 7100 loss 0.01198
INFO:name:epoch 6 step 7200 loss 0.01473
INFO:name:epoch 6 step 7300 loss 0.01869
INFO:name:epoch 6 step 7400 loss 0.01574
INFO:name:epoch 6 step 7500 loss 0.01227
INFO:name:epoch 6 step 7600 loss 0.01647
INFO:name:epoch 6 step 7700 loss 0.01545
INFO:name:epoch 6 step 7800 loss 0.01544
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3981
INFO:name:epoch 7 step 100 loss 0.01222
INFO:name:epoch 7 step 200 loss 0.01289
INFO:name:epoch 7 step 300 loss 0.01119
INFO:name:epoch 7 step 400 loss 0.01361
INFO:name:epoch 7 step 500 loss 0.01299
INFO:name:epoch 7 step 600 loss 0.00872
INFO:name:epoch 7 step 700 loss 0.01355
INFO:name:epoch 7 step 800 loss 0.01065
INFO:name:epoch 7 step 900 loss 0.00949
INFO:name:epoch 7 step 1000 loss 0.01016
INFO:name:epoch 7 step 1100 loss 0.00917
INFO:name:epoch 7 step 1200 loss 0.00991
INFO:name:epoch 7 step 1300 loss 0.00844
INFO:name:epoch 7 step 1400 loss 0.01314
INFO:name:epoch 7 step 1500 loss 0.01126
INFO:name:epoch 7 step 1600 loss 0.00893
INFO:name:epoch 7 step 1700 loss 0.00848
INFO:name:epoch 7 step 1800 loss 0.00902
INFO:name:epoch 7 step 1900 loss 0.01343
INFO:name:epoch 7 step 2000 loss 0.01232
INFO:name:epoch 7 step 2100 loss 0.0123
INFO:name:epoch 7 step 2200 loss 0.00983
INFO:name:epoch 7 step 2300 loss 0.01138
INFO:name:epoch 7 step 2400 loss 0.01262
INFO:name:epoch 7 step 2500 loss 0.01062
INFO:name:epoch 7 step 2600 loss 0.00972
INFO:name:epoch 7 step 2700 loss 0.0101
INFO:name:epoch 7 step 2800 loss 0.01013
INFO:name:epoch 7 step 2900 loss 0.01209
INFO:name:epoch 7 step 3000 loss 0.012
INFO:name:epoch 7 step 3100 loss 0.01285
INFO:name:epoch 7 step 3200 loss 0.00918
INFO:name:epoch 7 step 3300 loss 0.01305
INFO:name:epoch 7 step 3400 loss 0.00941
INFO:name:epoch 7 step 3500 loss 0.01343
INFO:name:epoch 7 step 3600 loss 0.01076
INFO:name:epoch 7 step 3700 loss 0.01254
INFO:name:epoch 7 step 3800 loss 0.01116
INFO:name:epoch 7 step 3900 loss 0.0128
INFO:name:epoch 7 step 4000 loss 0.01055
INFO:name:epoch 7 step 4100 loss 0.0137
INFO:name:epoch 7 step 4200 loss 0.01132
INFO:name:epoch 7 step 4300 loss 0.01162
INFO:name:epoch 7 step 4400 loss 0.0143
INFO:name:epoch 7 step 4500 loss 0.01319
INFO:name:epoch 7 step 4600 loss 0.01278
INFO:name:epoch 7 step 4700 loss 0.0124
INFO:name:epoch 7 step 4800 loss 0.01392
INFO:name:epoch 7 step 4900 loss 0.01063
INFO:name:epoch 7 step 5000 loss 0.01375
INFO:name:epoch 7 step 5100 loss 0.0094
INFO:name:epoch 7 step 5200 loss 0.01313
INFO:name:epoch 7 step 5300 loss 0.00953
INFO:name:epoch 7 step 5400 loss 0.01163
INFO:name:epoch 7 step 5500 loss 0.01201
INFO:name:epoch 7 step 5600 loss 0.0119
INFO:name:epoch 7 step 5700 loss 0.0114
INFO:name:epoch 7 step 5800 loss 0.01309
INFO:name:epoch 7 step 5900 loss 0.00703
INFO:name:epoch 7 step 6000 loss 0.01145
INFO:name:epoch 7 step 6100 loss 0.01219
INFO:name:epoch 7 step 6200 loss 0.01567
INFO:name:epoch 7 step 6300 loss 0.01185
INFO:name:epoch 7 step 6400 loss 0.01418
INFO:name:epoch 7 step 6500 loss 0.01014
INFO:name:epoch 7 step 6600 loss 0.01195
INFO:name:epoch 7 step 6700 loss 0.01202
INFO:name:epoch 7 step 6800 loss 0.01788
INFO:name:epoch 7 step 6900 loss 0.01519
INFO:name:epoch 7 step 7000 loss 0.01086
INFO:name:epoch 7 step 7100 loss 0.01149
INFO:name:epoch 7 step 7200 loss 0.01285
INFO:name:epoch 7 step 7300 loss 0.01032
INFO:name:epoch 7 step 7400 loss 0.011
INFO:name:epoch 7 step 7500 loss 0.01001
INFO:name:epoch 7 step 7600 loss 0.01355
INFO:name:epoch 7 step 7700 loss 0.01213
INFO:name:epoch 7 step 7800 loss 0.01224
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4006
INFO:name:epoch 8 step 100 loss 0.0106
INFO:name:epoch 8 step 200 loss 0.00913
INFO:name:epoch 8 step 300 loss 0.00868
INFO:name:epoch 8 step 400 loss 0.01085
INFO:name:epoch 8 step 500 loss 0.00873
INFO:name:epoch 8 step 600 loss 0.00855
INFO:name:epoch 8 step 700 loss 0.00904
INFO:name:epoch 8 step 800 loss 0.01089
INFO:name:epoch 8 step 900 loss 0.0106
INFO:name:epoch 8 step 1000 loss 0.00911
INFO:name:epoch 8 step 1100 loss 0.00975
INFO:name:epoch 8 step 1200 loss 0.01117
INFO:name:epoch 8 step 1300 loss 0.01055
INFO:name:epoch 8 step 1400 loss 0.00896
INFO:name:epoch 8 step 1500 loss 0.01094
INFO:name:epoch 8 step 1600 loss 0.01016
INFO:name:epoch 8 step 1700 loss 0.00763
INFO:name:epoch 8 step 1800 loss 0.00986
INFO:name:epoch 8 step 1900 loss 0.0112
INFO:name:epoch 8 step 2000 loss 0.00978
INFO:name:epoch 8 step 2100 loss 0.01066
INFO:name:epoch 8 step 2200 loss 0.00896
INFO:name:epoch 8 step 2300 loss 0.00955
INFO:name:epoch 8 step 2400 loss 0.01148
INFO:name:epoch 8 step 2500 loss 0.01158
INFO:name:epoch 8 step 2600 loss 0.00943
INFO:name:epoch 8 step 2700 loss 0.00908
INFO:name:epoch 8 step 2800 loss 0.00957
INFO:name:epoch 8 step 2900 loss 0.00963
INFO:name:epoch 8 step 3000 loss 0.01185
INFO:name:epoch 8 step 3100 loss 0.0093
INFO:name:epoch 8 step 3200 loss 0.00785
INFO:name:epoch 8 step 3300 loss 0.01204
INFO:name:epoch 8 step 3400 loss 0.01011
INFO:name:epoch 8 step 3500 loss 0.00931
INFO:name:epoch 8 step 3600 loss 0.00796
INFO:name:epoch 8 step 3700 loss 0.01071
INFO:name:epoch 8 step 3800 loss 0.01196
INFO:name:epoch 8 step 3900 loss 0.00679
INFO:name:epoch 8 step 4000 loss 0.00933
INFO:name:epoch 8 step 4100 loss 0.0086
INFO:name:epoch 8 step 4200 loss 0.0103
INFO:name:epoch 8 step 4300 loss 0.00864
INFO:name:epoch 8 step 4400 loss 0.00937
INFO:name:epoch 8 step 4500 loss 0.00874
INFO:name:epoch 8 step 4600 loss 0.00959
INFO:name:epoch 8 step 4700 loss 0.01099
INFO:name:epoch 8 step 4800 loss 0.00844
INFO:name:epoch 8 step 4900 loss 0.01031
INFO:name:epoch 8 step 5000 loss 0.01017
INFO:name:epoch 8 step 5100 loss 0.01136
INFO:name:epoch 8 step 5200 loss 0.00917
INFO:name:epoch 8 step 5300 loss 0.01041
INFO:name:epoch 8 step 5400 loss 0.00816
INFO:name:epoch 8 step 5500 loss 0.01254
INFO:name:epoch 8 step 5600 loss 0.01265
INFO:name:epoch 8 step 5700 loss 0.01127
INFO:name:epoch 8 step 5800 loss 0.01082
INFO:name:epoch 8 step 5900 loss 0.01284
INFO:name:epoch 8 step 6000 loss 0.00981
INFO:name:epoch 8 step 6100 loss 0.00984
INFO:name:epoch 8 step 6200 loss 0.00874
INFO:name:epoch 8 step 6300 loss 0.01226
INFO:name:epoch 8 step 6400 loss 0.01217
INFO:name:epoch 8 step 6500 loss 0.01174
INFO:name:epoch 8 step 6600 loss 0.01146
INFO:name:epoch 8 step 6700 loss 0.01238
INFO:name:epoch 8 step 6800 loss 0.01176
INFO:name:epoch 8 step 6900 loss 0.00998
INFO:name:epoch 8 step 7000 loss 0.01069
INFO:name:epoch 8 step 7100 loss 0.01213
INFO:name:epoch 8 step 7200 loss 0.01371
INFO:name:epoch 8 step 7300 loss 0.01017
INFO:name:epoch 8 step 7400 loss 0.00932
INFO:name:epoch 8 step 7500 loss 0.01129
INFO:name:epoch 8 step 7600 loss 0.01027
INFO:name:epoch 8 step 7700 loss 0.01054
INFO:name:epoch 8 step 7800 loss 0.01042
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.4078
INFO:name:epoch 9 step 100 loss 0.00836
INFO:name:epoch 9 step 200 loss 0.00832
INFO:name:epoch 9 step 300 loss 0.00889
INFO:name:epoch 9 step 400 loss 0.01038
INFO:name:epoch 9 step 500 loss 0.00754
INFO:name:epoch 9 step 600 loss 0.00727
INFO:name:epoch 9 step 700 loss 0.00905
INFO:name:epoch 9 step 800 loss 0.00776
INFO:name:epoch 9 step 900 loss 0.00647
INFO:name:epoch 9 step 1000 loss 0.01098
INFO:name:epoch 9 step 1100 loss 0.00885
INFO:name:epoch 9 step 1200 loss 0.00862
INFO:name:epoch 9 step 1300 loss 0.00835
INFO:name:epoch 9 step 1400 loss 0.00996
INFO:name:epoch 9 step 1500 loss 0.00849
INFO:name:epoch 9 step 1600 loss 0.00808
INFO:name:epoch 9 step 1700 loss 0.01029
INFO:name:epoch 9 step 1800 loss 0.00665
INFO:name:epoch 9 step 1900 loss 0.01111
INFO:name:epoch 9 step 2000 loss 0.00755
INFO:name:epoch 9 step 2100 loss 0.00959
INFO:name:epoch 9 step 2200 loss 0.0082
INFO:name:epoch 9 step 2300 loss 0.00808
INFO:name:epoch 9 step 2400 loss 0.0075
INFO:name:epoch 9 step 2500 loss 0.00819
INFO:name:epoch 9 step 2600 loss 0.01026
INFO:name:epoch 9 step 2700 loss 0.00965
INFO:name:epoch 9 step 2800 loss 0.00857
INFO:name:epoch 9 step 2900 loss 0.00946
INFO:name:epoch 9 step 3000 loss 0.00857
INFO:name:epoch 9 step 3100 loss 0.01234
INFO:name:epoch 9 step 3200 loss 0.01065
INFO:name:epoch 9 step 3300 loss 0.00888
INFO:name:epoch 9 step 3400 loss 0.00923
INFO:name:epoch 9 step 3500 loss 0.00658
INFO:name:epoch 9 step 3600 loss 0.00818
INFO:name:epoch 9 step 3700 loss 0.0074
INFO:name:epoch 9 step 3800 loss 0.01063
INFO:name:epoch 9 step 3900 loss 0.01049
INFO:name:epoch 9 step 4000 loss 0.00959
INFO:name:epoch 9 step 4100 loss 0.01001
INFO:name:epoch 9 step 4200 loss 0.00796
INFO:name:epoch 9 step 4300 loss 0.01236
INFO:name:epoch 9 step 4400 loss 0.00935
INFO:name:epoch 9 step 4500 loss 0.00909
INFO:name:epoch 9 step 4600 loss 0.01079
INFO:name:epoch 9 step 4700 loss 0.00928
INFO:name:epoch 9 step 4800 loss 0.00883
INFO:name:epoch 9 step 4900 loss 0.01171
INFO:name:epoch 9 step 5000 loss 0.00761
INFO:name:epoch 9 step 5100 loss 0.0111
INFO:name:epoch 9 step 5200 loss 0.0098
INFO:name:epoch 9 step 5300 loss 0.00742
INFO:name:epoch 9 step 5400 loss 0.00874
INFO:name:epoch 9 step 5500 loss 0.00938
INFO:name:epoch 9 step 5600 loss 0.00759
INFO:name:epoch 9 step 5700 loss 0.00933
INFO:name:epoch 9 step 5800 loss 0.00793
INFO:name:epoch 9 step 5900 loss 0.01005
INFO:name:epoch 9 step 6000 loss 0.01114
INFO:name:epoch 9 step 6100 loss 0.01068
INFO:name:epoch 9 step 6200 loss 0.00783
INFO:name:epoch 9 step 6300 loss 0.00728
INFO:name:epoch 9 step 6400 loss 0.01156
INFO:name:epoch 9 step 6500 loss 0.00948
INFO:name:epoch 9 step 6600 loss 0.01018
INFO:name:epoch 9 step 6700 loss 0.00715
INFO:name:epoch 9 step 6800 loss 0.01078
INFO:name:epoch 9 step 6900 loss 0.01011
INFO:name:epoch 9 step 7000 loss 0.00747
INFO:name:epoch 9 step 7100 loss 0.0102
INFO:name:epoch 9 step 7200 loss 0.01059
INFO:name:epoch 9 step 7300 loss 0.00824
INFO:name:epoch 9 step 7400 loss 0.0072
INFO:name:epoch 9 step 7500 loss 0.01057
INFO:name:epoch 9 step 7600 loss 0.00808
INFO:name:epoch 9 step 7700 loss 0.00772
INFO:name:epoch 9 step 7800 loss 0.00861
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3887
INFO:name:epoch 10 step 100 loss 0.00819
INFO:name:epoch 10 step 200 loss 0.0085
INFO:name:epoch 10 step 300 loss 0.00683
INFO:name:epoch 10 step 400 loss 0.00928
INFO:name:epoch 10 step 500 loss 0.00527
INFO:name:epoch 10 step 600 loss 0.00835
INFO:name:epoch 10 step 700 loss 0.00715
INFO:name:epoch 10 step 800 loss 0.0092
INFO:name:epoch 10 step 900 loss 0.00752
INFO:name:epoch 10 step 1000 loss 0.00917
INFO:name:epoch 10 step 1100 loss 0.00926
INFO:name:epoch 10 step 1200 loss 0.00777
INFO:name:epoch 10 step 1300 loss 0.00552
INFO:name:epoch 10 step 1400 loss 0.00661
INFO:name:epoch 10 step 1500 loss 0.00942
INFO:name:epoch 10 step 1600 loss 0.00855
INFO:name:epoch 10 step 1700 loss 0.00759
INFO:name:epoch 10 step 1800 loss 0.00825
INFO:name:epoch 10 step 1900 loss 0.00697
INFO:name:epoch 10 step 2000 loss 0.0089
INFO:name:epoch 10 step 2100 loss 0.00654
INFO:name:epoch 10 step 2200 loss 0.00909
INFO:name:epoch 10 step 2300 loss 0.00859
INFO:name:epoch 10 step 2400 loss 0.0082
INFO:name:epoch 10 step 2500 loss 0.00805
INFO:name:epoch 10 step 2600 loss 0.00823
INFO:name:epoch 10 step 2700 loss 0.00697
INFO:name:epoch 10 step 2800 loss 0.00767
INFO:name:epoch 10 step 2900 loss 0.00778
INFO:name:epoch 10 step 3000 loss 0.00802
INFO:name:epoch 10 step 3100 loss 0.00814
INFO:name:epoch 10 step 3200 loss 0.00849
INFO:name:epoch 10 step 3300 loss 0.00866
INFO:name:epoch 10 step 3400 loss 0.01032
INFO:name:epoch 10 step 3500 loss 0.0107
INFO:name:epoch 10 step 3600 loss 0.00659
INFO:name:epoch 10 step 3700 loss 0.00842
INFO:name:epoch 10 step 3800 loss 0.00965
INFO:name:epoch 10 step 3900 loss 0.00865
INFO:name:epoch 10 step 4000 loss 0.00928
INFO:name:epoch 10 step 4100 loss 0.0092
INFO:name:epoch 10 step 4200 loss 0.00997
INFO:name:epoch 10 step 4300 loss 0.00752
INFO:name:epoch 10 step 4400 loss 0.00624
INFO:name:epoch 10 step 4500 loss 0.00694
INFO:name:epoch 10 step 4600 loss 0.00768
INFO:name:epoch 10 step 4700 loss 0.0078
INFO:name:epoch 10 step 4800 loss 0.00678
INFO:name:epoch 10 step 4900 loss 0.00695
INFO:name:epoch 10 step 5000 loss 0.01152
INFO:name:epoch 10 step 5100 loss 0.00728
INFO:name:epoch 10 step 5200 loss 0.00653
INFO:name:epoch 10 step 5300 loss 0.00644
INFO:name:epoch 10 step 5400 loss 0.00888
INFO:name:epoch 10 step 5500 loss 0.00944
INFO:name:epoch 10 step 5600 loss 0.0124
INFO:name:epoch 10 step 5700 loss 0.00841
INFO:name:epoch 10 step 5800 loss 0.00609
INFO:name:epoch 10 step 5900 loss 0.00872
INFO:name:epoch 10 step 6000 loss 0.00908
INFO:name:epoch 10 step 6100 loss 0.00926
INFO:name:epoch 10 step 6200 loss 0.00687
INFO:name:epoch 10 step 6300 loss 0.00824
INFO:name:epoch 10 step 6400 loss 0.00777
INFO:name:epoch 10 step 6500 loss 0.00891
INFO:name:epoch 10 step 6600 loss 0.00854
INFO:name:epoch 10 step 6700 loss 0.00785
INFO:name:epoch 10 step 6800 loss 0.01167
INFO:name:epoch 10 step 6900 loss 0.00649
INFO:name:epoch 10 step 7000 loss 0.0074
INFO:name:epoch 10 step 7100 loss 0.00954
INFO:name:epoch 10 step 7200 loss 0.00623
INFO:name:epoch 10 step 7300 loss 0.00881
INFO:name:epoch 10 step 7400 loss 0.00741
INFO:name:epoch 10 step 7500 loss 0.00642
INFO:name:epoch 10 step 7600 loss 0.00771
INFO:name:epoch 10 step 7700 loss 0.00878
INFO:name:epoch 10 step 7800 loss 0.007
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3911
INFO:name:epoch 11 step 100 loss 0.00684
INFO:name:epoch 11 step 200 loss 0.00592
INFO:name:epoch 11 step 300 loss 0.00868
INFO:name:epoch 11 step 400 loss 0.00617
INFO:name:epoch 11 step 500 loss 0.00791
INFO:name:epoch 11 step 600 loss 0.00708
INFO:name:epoch 11 step 700 loss 0.00716
INFO:name:epoch 11 step 800 loss 0.00611
INFO:name:epoch 11 step 900 loss 0.00598
INFO:name:epoch 11 step 1000 loss 0.00901
INFO:name:epoch 11 step 1100 loss 0.00799
INFO:name:epoch 11 step 1200 loss 0.00706
INFO:name:epoch 11 step 1300 loss 0.008
INFO:name:epoch 11 step 1400 loss 0.00552
INFO:name:epoch 11 step 1500 loss 0.00792
INFO:name:epoch 11 step 1600 loss 0.00923
INFO:name:epoch 11 step 1700 loss 0.00748
INFO:name:epoch 11 step 1800 loss 0.00718
INFO:name:epoch 11 step 1900 loss 0.00862
INFO:name:epoch 11 step 2000 loss 0.00536
INFO:name:epoch 11 step 2100 loss 0.00725
INFO:name:epoch 11 step 2200 loss 0.008
INFO:name:epoch 11 step 2300 loss 0.00758
INFO:name:epoch 11 step 2400 loss 0.0068
INFO:name:epoch 11 step 2500 loss 0.0063
INFO:name:epoch 11 step 2600 loss 0.00758
INFO:name:epoch 11 step 2700 loss 0.00674
INFO:name:epoch 11 step 2800 loss 0.00717
INFO:name:epoch 11 step 2900 loss 0.00732
INFO:name:epoch 11 step 3000 loss 0.00918
INFO:name:epoch 11 step 3100 loss 0.00819
INFO:name:epoch 11 step 3200 loss 0.00806
INFO:name:epoch 11 step 3300 loss 0.00652
INFO:name:epoch 11 step 3400 loss 0.0072
INFO:name:epoch 11 step 3500 loss 0.00774
INFO:name:epoch 11 step 3600 loss 0.00682
INFO:name:epoch 11 step 3700 loss 0.01012
INFO:name:epoch 11 step 3800 loss 0.00596
INFO:name:epoch 11 step 3900 loss 0.00608
INFO:name:epoch 11 step 4000 loss 0.01193
INFO:name:epoch 11 step 4100 loss 0.00721
INFO:name:epoch 11 step 4200 loss 0.0097
INFO:name:epoch 11 step 4300 loss 0.00672
INFO:name:epoch 11 step 4400 loss 0.00795
INFO:name:epoch 11 step 4500 loss 0.00645
INFO:name:epoch 11 step 4600 loss 0.00778
INFO:name:epoch 11 step 4700 loss 0.00678
INFO:name:epoch 11 step 4800 loss 0.00658
INFO:name:epoch 11 step 4900 loss 0.00502
INFO:name:epoch 11 step 5000 loss 0.00865
INFO:name:epoch 11 step 5100 loss 0.00544
INFO:name:epoch 11 step 5200 loss 0.00926
INFO:name:epoch 11 step 5300 loss 0.00559
INFO:name:epoch 11 step 5400 loss 0.00671
INFO:name:epoch 11 step 5500 loss 0.00693
INFO:name:epoch 11 step 5600 loss 0.00707
INFO:name:epoch 11 step 5700 loss 0.00856
INFO:name:epoch 11 step 5800 loss 0.00796
INFO:name:epoch 11 step 5900 loss 0.00751
INFO:name:epoch 11 step 6000 loss 0.00615
INFO:name:epoch 11 step 6100 loss 0.00757
INFO:name:epoch 11 step 6200 loss 0.00755
INFO:name:epoch 11 step 6300 loss 0.00738
INFO:name:epoch 11 step 6400 loss 0.00936
INFO:name:epoch 11 step 6500 loss 0.00559
INFO:name:epoch 11 step 6600 loss 0.00659
INFO:name:epoch 11 step 6700 loss 0.00707
INFO:name:epoch 11 step 6800 loss 0.00954
INFO:name:epoch 11 step 6900 loss 0.00526
INFO:name:epoch 11 step 7000 loss 0.00952
INFO:name:epoch 11 step 7100 loss 0.00631
INFO:name:epoch 11 step 7200 loss 0.00683
INFO:name:epoch 11 step 7300 loss 0.00704
INFO:name:epoch 11 step 7400 loss 0.00831
INFO:name:epoch 11 step 7500 loss 0.00734
INFO:name:epoch 11 step 7600 loss 0.00663
INFO:name:epoch 11 step 7700 loss 0.00582
INFO:name:epoch 11 step 7800 loss 0.00697
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3826
INFO:name:epoch 12 step 100 loss 0.00751
INFO:name:epoch 12 step 200 loss 0.00559
INFO:name:epoch 12 step 300 loss 0.00666
INFO:name:epoch 12 step 400 loss 0.00639
INFO:name:epoch 12 step 500 loss 0.00582
INFO:name:epoch 12 step 600 loss 0.00653
INFO:name:epoch 12 step 700 loss 0.00635
INFO:name:epoch 12 step 800 loss 0.00558
INFO:name:epoch 12 step 900 loss 0.00857
INFO:name:epoch 12 step 1000 loss 0.00699
INFO:name:epoch 12 step 1100 loss 0.00735
INFO:name:epoch 12 step 1200 loss 0.00678
INFO:name:epoch 12 step 1300 loss 0.00576
INFO:name:epoch 12 step 1400 loss 0.00778
INFO:name:epoch 12 step 1500 loss 0.00699
INFO:name:epoch 12 step 1600 loss 0.00635
INFO:name:epoch 12 step 1700 loss 0.00821
INFO:name:epoch 12 step 1800 loss 0.00872
INFO:name:epoch 12 step 1900 loss 0.00574
INFO:name:epoch 12 step 2000 loss 0.00547
INFO:name:epoch 12 step 2100 loss 0.00626
INFO:name:epoch 12 step 2200 loss 0.00536
INFO:name:epoch 12 step 2300 loss 0.00707
INFO:name:epoch 12 step 2400 loss 0.00438
INFO:name:epoch 12 step 2500 loss 0.00601
INFO:name:epoch 12 step 2600 loss 0.01032
INFO:name:epoch 12 step 2700 loss 0.00767
INFO:name:epoch 12 step 2800 loss 0.00651
INFO:name:epoch 12 step 2900 loss 0.00661
INFO:name:epoch 12 step 3000 loss 0.0071
INFO:name:epoch 12 step 3100 loss 0.0062
INFO:name:epoch 12 step 3200 loss 0.00698
INFO:name:epoch 12 step 3300 loss 0.00703
INFO:name:epoch 12 step 3400 loss 0.00861
INFO:name:epoch 12 step 3500 loss 0.00702
INFO:name:epoch 12 step 3600 loss 0.00537
INFO:name:epoch 12 step 3700 loss 0.00855
INFO:name:epoch 12 step 3800 loss 0.00671
INFO:name:epoch 12 step 3900 loss 0.00537
INFO:name:epoch 12 step 4000 loss 0.00798
INFO:name:epoch 12 step 4100 loss 0.00671
INFO:name:epoch 12 step 4200 loss 0.00868
INFO:name:epoch 12 step 4300 loss 0.00517
INFO:name:epoch 12 step 4400 loss 0.00555
INFO:name:epoch 12 step 4500 loss 0.00773
INFO:name:epoch 12 step 4600 loss 0.00761
INFO:name:epoch 12 step 4700 loss 0.00663
INFO:name:epoch 12 step 4800 loss 0.00579
INFO:name:epoch 12 step 4900 loss 0.0066
INFO:name:epoch 12 step 5000 loss 0.00751
INFO:name:epoch 12 step 5100 loss 0.00557
INFO:name:epoch 12 step 5200 loss 0.00859
INFO:name:epoch 12 step 5300 loss 0.00556
INFO:name:epoch 12 step 5400 loss 0.00872
INFO:name:epoch 12 step 5500 loss 0.0075
INFO:name:epoch 12 step 5600 loss 0.00627
INFO:name:epoch 12 step 5700 loss 0.00591
INFO:name:epoch 12 step 5800 loss 0.00853
INFO:name:epoch 12 step 5900 loss 0.00795
INFO:name:epoch 12 step 6000 loss 0.00525
INFO:name:epoch 12 step 6100 loss 0.00705
INFO:name:epoch 12 step 6200 loss 0.00485
INFO:name:epoch 12 step 6300 loss 0.00615
INFO:name:epoch 12 step 6400 loss 0.00628
INFO:name:epoch 12 step 6500 loss 0.00631
INFO:name:epoch 12 step 6600 loss 0.00646
INFO:name:epoch 12 step 6700 loss 0.00534
INFO:name:epoch 12 step 6800 loss 0.00575
INFO:name:epoch 12 step 6900 loss 0.00646
INFO:name:epoch 12 step 7000 loss 0.00474
INFO:name:epoch 12 step 7100 loss 0.00601
INFO:name:epoch 12 step 7200 loss 0.00619
INFO:name:epoch 12 step 7300 loss 0.00533
INFO:name:epoch 12 step 7400 loss 0.00829
INFO:name:epoch 12 step 7500 loss 0.00867
INFO:name:epoch 12 step 7600 loss 0.00713
INFO:name:epoch 12 step 7700 loss 0.00618
INFO:name:epoch 12 step 7800 loss 0.00513
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3872
INFO:name:epoch 13 step 100 loss 0.00717
INFO:name:epoch 13 step 200 loss 0.00513
INFO:name:epoch 13 step 300 loss 0.00584
INFO:name:epoch 13 step 400 loss 0.00614
INFO:name:epoch 13 step 500 loss 0.00635
INFO:name:epoch 13 step 600 loss 0.00616
INFO:name:epoch 13 step 700 loss 0.0065
INFO:name:epoch 13 step 800 loss 0.00557
INFO:name:epoch 13 step 900 loss 0.00748
INFO:name:epoch 13 step 1000 loss 0.00676
INFO:name:epoch 13 step 1100 loss 0.00652
INFO:name:epoch 13 step 1200 loss 0.00694
INFO:name:epoch 13 step 1300 loss 0.00641
INFO:name:epoch 13 step 1400 loss 0.00513
INFO:name:epoch 13 step 1500 loss 0.00657
INFO:name:epoch 13 step 1600 loss 0.00447
INFO:name:epoch 13 step 1700 loss 0.0067
INFO:name:epoch 13 step 1800 loss 0.00698
INFO:name:epoch 13 step 1900 loss 0.0054
INFO:name:epoch 13 step 2000 loss 0.00467
INFO:name:epoch 13 step 2100 loss 0.00546
INFO:name:epoch 13 step 2200 loss 0.00794
INFO:name:epoch 13 step 2300 loss 0.00577
INFO:name:epoch 13 step 2400 loss 0.00567
INFO:name:epoch 13 step 2500 loss 0.00659
INFO:name:epoch 13 step 2600 loss 0.0086
INFO:name:epoch 13 step 2700 loss 0.00827
INFO:name:epoch 13 step 2800 loss 0.00573
INFO:name:epoch 13 step 2900 loss 0.00844
INFO:name:epoch 13 step 3000 loss 0.00637
INFO:name:epoch 13 step 3100 loss 0.00496
INFO:name:epoch 13 step 3200 loss 0.00596
INFO:name:epoch 13 step 3300 loss 0.0071
INFO:name:epoch 13 step 3400 loss 0.00701
INFO:name:epoch 13 step 3500 loss 0.00541
INFO:name:epoch 13 step 3600 loss 0.00554
INFO:name:epoch 13 step 3700 loss 0.00618
INFO:name:epoch 13 step 3800 loss 0.00633
INFO:name:epoch 13 step 3900 loss 0.00745
INFO:name:epoch 13 step 4000 loss 0.00524
INFO:name:epoch 13 step 4100 loss 0.00527
INFO:name:epoch 13 step 4200 loss 0.00612
INFO:name:epoch 13 step 4300 loss 0.00633
INFO:name:epoch 13 step 4400 loss 0.00545
INFO:name:epoch 13 step 4500 loss 0.00543
INFO:name:epoch 13 step 4600 loss 0.00454
INFO:name:epoch 13 step 4700 loss 0.00607
INFO:name:epoch 13 step 4800 loss 0.00638
INFO:name:epoch 13 step 4900 loss 0.00536
INFO:name:epoch 13 step 5000 loss 0.00784
INFO:name:epoch 13 step 5100 loss 0.00627
INFO:name:epoch 13 step 5200 loss 0.00543
INFO:name:epoch 13 step 5300 loss 0.00586
INFO:name:epoch 13 step 5400 loss 0.00566
INFO:name:epoch 13 step 5500 loss 0.00694
INFO:name:epoch 13 step 5600 loss 0.00693
INFO:name:epoch 13 step 5700 loss 0.00611
INFO:name:epoch 13 step 5800 loss 0.00582
INFO:name:epoch 13 step 5900 loss 0.00726
INFO:name:epoch 13 step 6000 loss 0.00478
INFO:name:epoch 13 step 6100 loss 0.00649
INFO:name:epoch 13 step 6200 loss 0.00562
INFO:name:epoch 13 step 6300 loss 0.00741
INFO:name:epoch 13 step 6400 loss 0.00661
INFO:name:epoch 13 step 6500 loss 0.00447
INFO:name:epoch 13 step 6600 loss 0.00477
INFO:name:epoch 13 step 6700 loss 0.0066
INFO:name:epoch 13 step 6800 loss 0.00581
INFO:name:epoch 13 step 6900 loss 0.00631
INFO:name:epoch 13 step 7000 loss 0.00448
INFO:name:epoch 13 step 7100 loss 0.00763
INFO:name:epoch 13 step 7200 loss 0.00491
INFO:name:epoch 13 step 7300 loss 0.00548
INFO:name:epoch 13 step 7400 loss 0.00484
INFO:name:epoch 13 step 7500 loss 0.0066
INFO:name:epoch 13 step 7600 loss 0.0079
INFO:name:epoch 13 step 7700 loss 0.00621
INFO:name:epoch 13 step 7800 loss 0.0062
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3854
INFO:name:epoch 14 step 100 loss 0.00547
INFO:name:epoch 14 step 200 loss 0.0056
INFO:name:epoch 14 step 300 loss 0.00592
INFO:name:epoch 14 step 400 loss 0.00613
INFO:name:epoch 14 step 500 loss 0.00441
INFO:name:epoch 14 step 600 loss 0.00723
INFO:name:epoch 14 step 700 loss 0.00579
INFO:name:epoch 14 step 800 loss 0.00379
INFO:name:epoch 14 step 900 loss 0.00478
INFO:name:epoch 14 step 1000 loss 0.00586
INFO:name:epoch 14 step 1100 loss 0.00573
INFO:name:epoch 14 step 1200 loss 0.00439
INFO:name:epoch 14 step 1300 loss 0.00608
INFO:name:epoch 14 step 1400 loss 0.00774
INFO:name:epoch 14 step 1500 loss 0.00654
INFO:name:epoch 14 step 1600 loss 0.00544
INFO:name:epoch 14 step 1700 loss 0.00506
INFO:name:epoch 14 step 1800 loss 0.00441
INFO:name:epoch 14 step 1900 loss 0.00739
INFO:name:epoch 14 step 2000 loss 0.00489
INFO:name:epoch 14 step 2100 loss 0.00605
INFO:name:epoch 14 step 2200 loss 0.00527
INFO:name:epoch 14 step 2300 loss 0.0065
INFO:name:epoch 14 step 2400 loss 0.00624
INFO:name:epoch 14 step 2500 loss 0.00715
INFO:name:epoch 14 step 2600 loss 0.00588
INFO:name:epoch 14 step 2700 loss 0.00549
INFO:name:epoch 14 step 2800 loss 0.00543
INFO:name:epoch 14 step 2900 loss 0.00589
INFO:name:epoch 14 step 3000 loss 0.00545
INFO:name:epoch 14 step 3100 loss 0.00587
INFO:name:epoch 14 step 3200 loss 0.00522
INFO:name:epoch 14 step 3300 loss 0.0061
INFO:name:epoch 14 step 3400 loss 0.00489
INFO:name:epoch 14 step 3500 loss 0.00488
INFO:name:epoch 14 step 3600 loss 0.00649
INFO:name:epoch 14 step 3700 loss 0.00552
INFO:name:epoch 14 step 3800 loss 0.00546
INFO:name:epoch 14 step 3900 loss 0.00784
INFO:name:epoch 14 step 4000 loss 0.00514
INFO:name:epoch 14 step 4100 loss 0.00816
INFO:name:epoch 14 step 4200 loss 0.00476
INFO:name:epoch 14 step 4300 loss 0.00586
INFO:name:epoch 14 step 4400 loss 0.00461
INFO:name:epoch 14 step 4500 loss 0.00497
INFO:name:epoch 14 step 4600 loss 0.0044
INFO:name:epoch 14 step 4700 loss 0.00522
INFO:name:epoch 14 step 4800 loss 0.00552
INFO:name:epoch 14 step 4900 loss 0.00526
INFO:name:epoch 14 step 5000 loss 0.00593
INFO:name:epoch 14 step 5100 loss 0.00571
INFO:name:epoch 14 step 5200 loss 0.00635
INFO:name:epoch 14 step 5300 loss 0.00635
INFO:name:epoch 14 step 5400 loss 0.00713
INFO:name:epoch 14 step 5500 loss 0.00707
INFO:name:epoch 14 step 5600 loss 0.00424
INFO:name:epoch 14 step 5700 loss 0.00559
INFO:name:epoch 14 step 5800 loss 0.00542
INFO:name:epoch 14 step 5900 loss 0.00646
INFO:name:epoch 14 step 6000 loss 0.00632
INFO:name:epoch 14 step 6100 loss 0.0068
INFO:name:epoch 14 step 6200 loss 0.0049
INFO:name:epoch 14 step 6300 loss 0.00569
INFO:name:epoch 14 step 6400 loss 0.00597
INFO:name:epoch 14 step 6500 loss 0.0075
INFO:name:epoch 14 step 6600 loss 0.00564
INFO:name:epoch 14 step 6700 loss 0.00552
INFO:name:epoch 14 step 6800 loss 0.00509
INFO:name:epoch 14 step 6900 loss 0.00594
INFO:name:epoch 14 step 7000 loss 0.00576
INFO:name:epoch 14 step 7100 loss 0.00643
INFO:name:epoch 14 step 7200 loss 0.00484
INFO:name:epoch 14 step 7300 loss 0.00541
INFO:name:epoch 14 step 7400 loss 0.00603
INFO:name:epoch 14 step 7500 loss 0.006
INFO:name:epoch 14 step 7600 loss 0.00623
INFO:name:epoch 14 step 7700 loss 0.00618
INFO:name:epoch 14 step 7800 loss 0.00449
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.382
INFO:name:Saving model checkpoint to ./models/final_model_codeSearch/model.bin
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:[0, 0, 0, {'insert_modules': ('attention.self',), 'bottleneck_dim': (32,), 'non_linearity': 'gelu_new', 'dropout_rate': 0.0, 'normalization': 'layer_norm', 'skip_connection': True}, 0, {'insert_modules': ('attention.output', 'output', 'attention.self'), 'bottleneck_dim': (32, 256, 32), 'non_linearity': 'gelu_new', 'dropout_rate': 0.25, 'normalization': 'layer_norm', 'skip_connection': True}, 0, {'insert_modules': ('attention.self',), 'bottleneck_dim': (16,), 'non_linearity': 'silu', 'dropout_rate': 0.3, 'normalization': None, 'skip_connection': True}, 0, {'insert_modules': ('output', 'attention.output', 'attention.self'), 'bottleneck_dim': (256, 64, 16), 'non_linearity': 'silu', 'dropout_rate': 0.2, 'normalization': 'layer_norm', 'skip_connection': True}, {'insert_modules': ('attention.output', 'intermediate'), 'bottleneck_dim': (32, 128), 'non_linearity': 'relu', 'dropout_rate': 0.3, 'normalization': None, 'skip_connection': True}, 0]
[INFO|(OpenDelta)basemodel:700]2025-01-07 21:46:27,309 >> Trainable Ratio: 1929152/126574784=1.524120%
[INFO|(OpenDelta)basemodel:702]2025-01-07 21:46:27,309 >> Delta Parameter Ratio: 1929152/126574784=1.524120%
[INFO|(OpenDelta)basemodel:704]2025-01-07 21:46:27,310 >> Static Memory 0.98 GB, Max Memory 8.71 GB
INFO:name:2.22
INFO:name:***** Running training *****
INFO:name:  Num examples = 251820
INFO:name:  Num Epochs = 15
INFO:name:  Instantaneous batch size per GPU = 32
INFO:name:  Total train batch size  = 32
INFO:name:  Total optimization steps = 118050
INFO:name:epoch 0 step 100 loss 0.37041
INFO:name:epoch 0 step 200 loss 0.17644
INFO:name:epoch 0 step 300 loss 0.17021
INFO:name:epoch 0 step 400 loss 0.14328
INFO:name:epoch 0 step 500 loss 0.14663
INFO:name:epoch 0 step 600 loss 0.12817
INFO:name:epoch 0 step 700 loss 0.13777
INFO:name:epoch 0 step 800 loss 0.13265
INFO:name:epoch 0 step 900 loss 0.12344
INFO:name:epoch 0 step 1000 loss 0.12096
INFO:name:epoch 0 step 1100 loss 0.11419
INFO:name:epoch 0 step 1200 loss 0.11353
INFO:name:epoch 0 step 1300 loss 0.11967
INFO:name:epoch 0 step 1400 loss 0.1295
INFO:name:epoch 0 step 1500 loss 0.11204
INFO:name:epoch 0 step 1600 loss 0.11878
INFO:name:epoch 0 step 1700 loss 0.11935
INFO:name:epoch 0 step 1800 loss 0.0978
INFO:name:epoch 0 step 1900 loss 0.11838
INFO:name:epoch 0 step 2000 loss 0.10666
INFO:name:epoch 0 step 2100 loss 0.10193
INFO:name:epoch 0 step 2200 loss 0.09491
INFO:name:epoch 0 step 2300 loss 0.1024
INFO:name:epoch 0 step 2400 loss 0.10859
INFO:name:epoch 0 step 2500 loss 0.10209
INFO:name:epoch 0 step 2600 loss 0.11815
INFO:name:epoch 0 step 2700 loss 0.10828
INFO:name:epoch 0 step 2800 loss 0.09696
INFO:name:epoch 0 step 2900 loss 0.10637
INFO:name:epoch 0 step 3000 loss 0.10172
INFO:name:epoch 0 step 3100 loss 0.09583
INFO:name:epoch 0 step 3200 loss 0.10546
INFO:name:epoch 0 step 3300 loss 0.10029
INFO:name:epoch 0 step 3400 loss 0.1086
INFO:name:epoch 0 step 3500 loss 0.10097
INFO:name:epoch 0 step 3600 loss 0.08296
INFO:name:epoch 0 step 3700 loss 0.08994
INFO:name:epoch 0 step 3800 loss 0.09068
INFO:name:epoch 0 step 3900 loss 0.09473
INFO:name:epoch 0 step 4000 loss 0.08817
INFO:name:epoch 0 step 4100 loss 0.10621
INFO:name:epoch 0 step 4200 loss 0.08293
INFO:name:epoch 0 step 4300 loss 0.09212
INFO:name:epoch 0 step 4400 loss 0.10567
INFO:name:epoch 0 step 4500 loss 0.09599
INFO:name:epoch 0 step 4600 loss 0.11462
INFO:name:epoch 0 step 4700 loss 0.10178
INFO:name:epoch 0 step 4800 loss 0.10237
INFO:name:epoch 0 step 4900 loss 0.09588
INFO:name:epoch 0 step 5000 loss 0.09013
INFO:name:epoch 0 step 5100 loss 0.09573
INFO:name:epoch 0 step 5200 loss 0.09661
INFO:name:epoch 0 step 5300 loss 0.10038
INFO:name:epoch 0 step 5400 loss 0.0713
INFO:name:epoch 0 step 5500 loss 0.07809
INFO:name:epoch 0 step 5600 loss 0.09189
INFO:name:epoch 0 step 5700 loss 0.08214
INFO:name:epoch 0 step 5800 loss 0.07467
INFO:name:epoch 0 step 5900 loss 0.10146
INFO:name:epoch 0 step 6000 loss 0.08613
INFO:name:epoch 0 step 6100 loss 0.09201
INFO:name:epoch 0 step 6200 loss 0.08487
INFO:name:epoch 0 step 6300 loss 0.0793
INFO:name:epoch 0 step 6400 loss 0.07409
INFO:name:epoch 0 step 6500 loss 0.09313
INFO:name:epoch 0 step 6600 loss 0.08534
INFO:name:epoch 0 step 6700 loss 0.08306
INFO:name:epoch 0 step 6800 loss 0.08901
INFO:name:epoch 0 step 6900 loss 0.0936
INFO:name:epoch 0 step 7000 loss 0.09108
INFO:name:epoch 0 step 7100 loss 0.09893
INFO:name:epoch 0 step 7200 loss 0.09301
INFO:name:epoch 0 step 7300 loss 0.07415
INFO:name:epoch 0 step 7400 loss 0.07317
INFO:name:epoch 0 step 7500 loss 0.07654
INFO:name:epoch 0 step 7600 loss 0.08489
INFO:name:epoch 0 step 7700 loss 0.08167
INFO:name:epoch 0 step 7800 loss 0.09553
INFO:name:***** Running evaluation *****
INFO:name:  Num queries = 9604
INFO:name:  Num codes = 9604
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.428
INFO:name:  ********************
INFO:name:  Best eval mrr:0.428
INFO:name:  ********************
INFO:name:***** Running Test *****
INFO:name:  Num queries = 19210
INFO:name:  Num codes = 19210
INFO:name:  Batch size = 32
INFO:name:  eval_mrr = 0.3628
INFO:name:Saving model checkpoint to ./models/best_model_codeSearch/model.bin
INFO:name:epoch 1 step 100 loss 0.06579
INFO:name:epoch 1 step 200 loss 0.04262
INFO:name:epoch 1 step 300 loss 0.04707
INFO:name:epoch 1 step 400 loss 0.05217
INFO:name:epoch 1 step 500 loss 0.0424
INFO:name:epoch 1 step 600 loss 0.04887
INFO:name:epoch 1 step 700 loss 0.03919
INFO:name:epoch 1 step 800 loss 0.04959
INFO:name:epoch 1 step 900 loss 0.05053
INFO:name:epoch 1 step 1000 loss 0.05314
INFO:name:epoch 1 step 1100 loss 0.04636
INFO:name:epoch 1 step 1200 loss 0.04885
INFO:name:epoch 1 step 1300 loss 0.05457
INFO:name:epoch 1 step 1400 loss 0.05314
INFO:name:epoch 1 step 1500 loss 0.05759
INFO:name:epoch 1 step 1600 loss 0.05817
INFO:name:epoch 1 step 1700 loss 0.06046
INFO:name:epoch 1 step 1800 loss 0.05334
INFO:name:epoch 1 step 1900 loss 0.04191
INFO:name:epoch 1 step 2000 loss 0.05095
INFO:name:epoch 1 step 2100 loss 0.04887
INFO:name:epoch 1 step 2200 loss 0.0557
INFO:name:epoch 1 step 2300 loss 0.0405
INFO:name:epoch 1 step 2400 loss 0.04269
INFO:name:epoch 1 step 2500 loss 0.04903
INFO:name:epoch 1 step 2600 loss 0.05405
INFO:name:epoch 1 step 2700 loss 0.05145
INFO:name:epoch 1 step 2800 loss 0.04814
INFO:name:epoch 1 step 2900 loss 0.05054
INFO:name:epoch 1 step 3000 loss 0.06484
INFO:name:epoch 1 step 3100 loss 0.06296
INFO:name:epoch 1 step 3200 loss 0.04938
INFO:name:epoch 1 step 3300 loss 0.04253
INFO:name:epoch 1 step 3400 loss 0.05738
INFO:name:epoch 1 step 3500 loss 0.04662
INFO:name:epoch 1 step 3600 loss 0.05947
INFO:name:epoch 1 step 3700 loss 0.05149
INFO:name:epoch 1 step 3800 loss 0.05075
INFO:name:epoch 1 step 3900 loss 0.0531
INFO:name:epoch 1 step 4000 loss 0.04739
INFO:name:epoch 1 step 4100 loss 0.05047
INFO:name:epoch 1 step 4200 loss 0.05663
INFO:name:epoch 1 step 4300 loss 0.05808
INFO:name:epoch 1 step 4400 loss 0.05577
INFO:name:epoch 1 step 4500 loss 0.04802
INFO:name:epoch 1 step 4600 loss 0.05709
INFO:name:epoch 1 step 4700 loss 0.0568
INFO:name:epoch 1 step 4800 loss 0.05039
INFO:name:epoch 1 step 4900 loss 0.05281
INFO:name:epoch 1 step 5000 loss 0.05617
INFO:name:epoch 1 step 5100 loss 0.06329
INFO:name:epoch 1 step 5200 loss 0.05086
INFO:name:epoch 1 step 5300 loss 0.0486
INFO:name:epoch 1 step 5400 loss 0.0469
INFO:name:epoch 1 step 5500 loss 0.05243
INFO:name:epoch 1 step 5600 loss 0.04529
INFO:name:epoch 1 step 5700 loss 0.05294
INFO:name:epoch 1 step 5800 loss 0.04431
INFO:name:epoch 1 step 5900 loss 0.05488
INFO:name:epoch 1 step 6000 loss 0.04647
INFO:name:epoch 1 step 6100 loss 0.05406
INFO:name:epoch 1 step 6200 loss 0.04972
INFO:name:epoch 1 step 6300 loss 0.04667
INFO:name:epoch 1 step 6400 loss 0.04704
INFO:name:epoch 1 step 6500 loss 0.04932
INFO:name:epoch 1 step 6600 loss 0.05766
INFO:name:epoch 1 step 6700 loss 0.0497
INFO:name:epoch 1 step 6800 loss 0.0476
INFO:name:epoch 1 step 6900 loss 0.04778
INFO:name:epoch 1 step 7000 loss 0.046
INFO:name:epoch 1 step 7100 loss 0.04765
INFO:name:epoch 1 step 7200 loss 0.03982
INFO:name:epoch 1 step 7300 loss 0.04827
INFO:name:epoch 1 step 7400 loss 0.0483
INFO:name:epoch 1 step 7500 loss 0.05108
INFO:name:epoch 1 step 7600 loss 0.04457
INFO:name:epoch 1 step 7700 loss 0.04279
INFO:name:epoch 1 step 7800 loss 0.05178
